# üåü **3. Ensambles (Ensemble Methods)** {-}

**Ejemplos:** Random Forest, AdaBoost, XGBoost, LightGBM   
**Cu√°ndo usarlo:**   

* Cuando buscas alto rendimiento en clasificaci√≥n o regresi√≥n tabular.
* Competencias de datos (como Kaggle).

**Ventajas:** Alta precisi√≥n, robustez.   
**Limitaciones:** Dif√≠cil de interpretar; m√°s costosos computacionalmente.

---

## Random Forest  {-}  

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica o Continua",
  "‚úÖ Num√©ricas y categ√≥ricas (requiere codificaci√≥n)",
  "‚úÖ Captura relaciones no lineales e interacciones complejas",
  "‚ùå No requiere",
  "‚úÖ Deseable pero no obligatorio",
  "‚ùå No se asume homoscedasticidad",
  "‚úÖ Robusto a outliers (por agregaci√≥n)",
  "‚úÖ Robusto (selecciona subconjuntos aleatorios)",
  "‚ö†Ô∏è Moderada (dif√≠cil interpretar cientos de √°rboles)",
  "‚ö†Ô∏è Lento con muchos √°rboles o datos grandes",
  "‚úÖ Recomendado usar k-fold",
  "‚ùå Puede sobreajustar si no se ajustan hiperpar√°metros (e.g. profundidad, n√∫mero de √°rboles)"
)

detalles <- c(
  "Ensamble de √°rboles de decisi√≥n, cada uno entrenado en una muestra bootstrap y usando un subconjunto aleatorio de predictores.",
  "En clasificaci√≥n predice la clase mayoritaria entre √°rboles; en regresi√≥n, el promedio de predicciones.",
  "Acepta muchas variables y selecciona autom√°ticamente las m√°s relevantes por importancia.",
  "Al generar m√∫ltiples √°rboles, capta interacciones no lineales sin necesidad de especificarlas.",
  "No hay supuestos sobre la distribuci√≥n de los errores.",
  "Los √°rboles individuales pueden manejar correlaci√≥n leve; el ensamble mitiga la dependencia.",
  "No necesita homogeneidad de varianza en los errores residuales.",
  "Cada √°rbol es poco sensible a outliers, y la agregaci√≥n mejora robustez.",
  "Reduce el problema de colinealidad al seleccionar subconjuntos de variables por √°rbol.",
  "Es dif√≠cil de explicar, aunque se pueden usar m√©tricas de importancia de variables.",
  "Puede volverse lento si se entrenan miles de √°rboles en datasets muy grandes.",
  "Cross-validation ayuda a evitar overfitting y evaluar generalizaci√≥n.",
  "No es ideal si el interpretabilidad es cr√≠tica o el tiempo computacional es limitado."
)

tabla_rf <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_rf %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir random forest",
             subtitle = "Random Forest") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Gradient Boosting Machines (GBM)  {-}  

```{r, echo = FALSE}

criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica o Continua",
  "‚úÖ Num√©ricas y categ√≥ricas (requiere codificaci√≥n)",
  "‚úÖ Captura no linealidades e interacciones complejas v√≠a boosting",
  "‚ùå No requiere",
  "‚úÖ Deseable pero no obligatorio",
  "‚ùå No se asume homoscedasticidad",
  "‚ö†Ô∏è Moderadamente (los outliers pueden influir en √°rboles individuales)",
  "‚úÖ Robusto (los arboles manejan colinealidad localmente)",
  "‚ö†Ô∏è Baja (modelo de tipo caja negra con varios √°rboles secuenciales)",
  "‚ö†Ô∏è Lento con muchos √°rboles, datos grandes o par√°metros altos",
  "‚úÖ Recomendable con k-fold o repeated CV para ajuste de hiperpar√°metros",
  "‚ùå Si se tienen pocos datos, muchas categor√≠as o ruido alto"
)

detalles <- c(
  "Ensamble de √°rboles secuenciales donde cada √°rbol corrige errores del anterior.",
  "En clasificaci√≥n se combinan probabilidades; en regresi√≥n se promedian predicciones.",
  "Funciona con muchas variables y aprende la importancia autom√°ticamente.",
  "Construye √°rboles d√©biles que se enfocan en los errores residuales previos.",
  "No impone supuestos en la distribuci√≥n de los errores.",
  "Los datos deben ser observaciones independientes; sensible a dependencias temporales.",
  "No requiere varianza constante puesto que se basa en √°rboles.",
  "Los outliers pueden exagerar los gradientes y forzar ajustes extremos en √°rboles individuales.",
  "Los √°rboles reducen impacto de colinealidad, pero m√∫ltiples √°rboles pueden still complicarla.",
  "Dif√≠cil de interpretar el conjunto; se pueden usar importance plots o SHAP para explicaci√≥n.",
  "La construcci√≥n secuencial de cientos de √°rboles puede ser costosa en tiempo y memoria.",
  "La validaci√≥n cruzada ayuda a determinar tasa de aprendizaje, n√∫mero de √°rboles y profundidad.",
  "No es ideal cuando se tienen muy pocos datos o categor√≠as con pocos ejemplos."
)

tabla_gbm <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)  

tabla_gbm %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir GBM",
             subtitle = "Gradient Boosting Machines (GBM)") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 

```

## Boosting  {-}  

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica (clasificaci√≥n) o Continua (regresi√≥n)",
  "‚úÖ Num√©ricas y categ√≥ricas (requiere codificaci√≥n para algunas implementaciones)",
  "‚úÖ Captura no linealidades e interacciones complejas mediante aprendizaje secuencial",
  "‚ùå No requiere supuestos de normalidad",
  "‚úÖ Deseable, aunque no obligatorio para muchos algoritmos",
  "‚ùå No se asume homoscedasticidad",
  "‚ö†Ô∏è Moderadamente (puede ajustar demasiado a outliers si no se controla)",
  "‚úÖ Robusto (cada iteraci√≥n utiliza un subconjunto ponderado de datos)",
  "‚ö†Ô∏è Baja (modelo en su conjunto es tipo caja negra)",
  "‚ö†Ô∏è Lento con muchos √°rboles o altas iteraciones",
  "‚úÖ Recomendable con k-fold o repeated CV para ajustar tasa de aprendizaje y n√∫mero de iteraciones",
  "‚ùå Si se tienen pocos datos, alto ruido o target muy desbalanceado sin ajuste"
)

detalles <- c(
  "Ensamble supervisado que combina varios modelos d√©biles (ej. √°rboles peque√±os) de forma secuencial",
  "En clasificaci√≥n se usan votaciones ponderadas; en regresi√≥n se suman predicciones graduadas",
  "Acepta variables mixtas; algunas bibliotecas requieren convertir categ√≥ricas en dummies",
  "Construye modelos d√©biles en cada iteraci√≥n, enfoc√°ndose en muestras mal clasificadas o con alto residuo",
  "No exige distribuci√≥n de errores, ya que se basa en funci√≥n de p√©rdida sin supuestos param√©tricos",
  "Mejor si los ejemplos son independientes; puede usar t√©cnicas especiales para datos correlacionados",
  "No asume varianza constante, usa funci√≥n de p√©rdida directa para optimizar",
  "Los outliers pueden recibir peso excesivo en iteraciones posteriores, por lo que es necesario regularizar o usar robust loss",
  "La selecci√≥n de variables se hace impl√≠citamente, reduciendo el impacto de colinealidad",
  "Dif√≠cil de interpretar directamente; se pueden usar m√©tricas de importancia, SHAP o partial dependence para explicaci√≥n",
  "Cada iteraci√≥n entrena un modelo d√©bil, por lo que puede ser costoso si el n√∫mero de iteraciones es alto",
  "CV ayuda a determinar la tasa de aprendizaje (learning rate), n√∫mero de iteraciones y complejidad de base learners",
  "No es adecuado si hay muy pocos ejemplos, alta dimensionalidad con poco se√±al o target extremadamente desequilibrado"
)

tabla_boosting <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_boosting %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir Boosting",
             subtitle = "Boosting") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Bootstrapped Aggregation (Bagging)  {-}   

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica o Continua",
  "‚úÖ Num√©ricas y categ√≥ricas",
  "‚úÖ Captura relaciones no lineales al promediar m√∫ltiples modelos",
  "‚ùå No requiere",
  "‚úÖ Deseable, pero no obligatorio",
  "‚ùå No se asume homoscedasticidad",
  "‚úÖ Robusto (cada bootstrap reduce el impacto de outliers)",
  "‚úÖ Robusto (la agregaci√≥n mitiga colinealidad)",
  "‚ö†Ô∏è Moderada (dif√≠cil interpretar conjunto de modelos)",
  "‚ö†Ô∏è Moderado (depende del n√∫mero de √°rboles y tama√±o del dataset)",
  "‚úÖ Recomendable usar k-fold",
  "‚ùå No es ideal con muy pocos datos o si los base learners son demasiado simples"
)

detalles <- c(
  "Ensamble supervisado que ajusta varios modelos (usualmente √°rboles) sobre muestras bootstrap y promedia predicciones.",
  "En clasificaci√≥n predice la clase m√°s votada; en regresi√≥n, promedia los valores predichos.",
  "Acepta todo tipo de variables; las categ√≥ricas deben codificarse adecuadamente.",
  "Al promediar m√∫ltiples modelos, reduce varianza y captura no linealidades impl√≠citamente.",
  "No impone supuestos sobre la distribuci√≥n de errores.",
  "Los datos deben ser independientes; funciona peor en datos con fuerte autocorrelaci√≥n sin ajuste.",
  "No requiere varianza constante puesto que se basa en agregaci√≥n de m√∫ltiples predicciones.",
  "Cada muestra bootstrap y √°rbol es menos sensible a valores extremos; la agregaci√≥n aumenta robustez.",
  "La selecci√≥n aleatoria de subconjuntos y bootstrap reduce el efecto de predictores correlacionados.",
  "El modelo final es un conjunto de muchos √°rboles, lo que dificulta su explicaci√≥n directa.",
  "Entrenar cientos de √°rboles toma tiempo, pero es paralelizable; la predicci√≥n es relativamente r√°pida.",
  "CV ayuda a ajustar par√°metros como n√∫mero de √°rboles y profundidad m√°xima de cada √°rbol.",
  "Con pocos ejemplos, los bootstrap no aportan diversidad suficiente; si los base learners son muy simples, no capturan bien patrones complejos."
)

tabla_bagging <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_bagging %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir bagging",
             subtitle = "Bootstrapped Aggregation (Bagging) ") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## AdaBoost  {-}    

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica (clasificaci√≥n) o Continua (regresi√≥n adaptada)",
  "‚úÖ Num√©ricas y categ√≥ricas (requiere codificaci√≥n para algunas implementaciones)",
  "‚úÖ Captura no linealidades e interacciones mediante reponderaci√≥n iterativa",
  "‚ùå No requiere supuestos de normalidad en los residuos",
  "‚úÖ Deseable, aunque no obligatorio (mejor si instancias independientes)",
  "‚ùå No asume homoscedasticidad",
  "‚ö†Ô∏è Moderadamente (outliers pueden obtener demasiado peso durante iteraciones)",
  "‚úÖ Robusto (reduce colinealidad al iterar sobre subconjuntos ponderados)",
  "‚ö†Ô∏è Baja (modelo resultante es especie de ‚Äôcaja negra‚Äô)",
  "‚ö†Ô∏è Lento con muchas iteraciones o datos grandes",
  "‚úÖ Recomendable para ajustar tasa de aprendizaje y n√∫mero de iteraciones",
  "‚ùå No es ideal con datos muy ruidosos o clases extremadamente desbalanceadas sin t√©cnicas adicionales"
)

detalles <- c(
  "Ensamble supervisado que combina varios modelos d√©biles (ej. √°rboles simples) ajustando pesos seg√∫n errores anteriores.",
  "En clasificaci√≥n ajusta pesos para mal clasificados; en regresi√≥n, adapta predicci√≥n por minimizaci√≥n de p√©rdida.",
  "Puede trabajar con datos mixtos; para variables categ√≥ricas suele usar codificaci√≥n de dummies.",
  "Cada iteraci√≥n repondera observaciones dif√≠ciles, enfoc√°ndose en patrones que previos modelos no capturaron.",
  "No impone distribuci√≥n de errores; se basa en funci√≥n de p√©rdida, no en supuestos param√©tricos.",
  "Funciona mejor si cada observaci√≥n es independiente; sensible a dependencias temporales si no se corrige.",
  "No requiere varianza constante, ya que funciona sobre el error iterativo en lugar de residuos tradicionales.",
  "Outliers dif√≠ciles de clasificar tienden a recibir mayor peso, lo que puede sesgar el ensamble si no se controla el learning rate.",
  "La reponderaci√≥n de muestras aten√∫a el efecto de predictores correlacionados, pues cada iteraci√≥n puede focalizarse en subconjuntos distintos.",
  "Es complejo desentra√±ar la contribuci√≥n de cada modelo d√©bil; se pueden usar m√©tricas de importancia o SHAP para interpretaci√≥n.",
  "Cada iteraci√≥n entrena un modelo d√©bil; muchas iteraciones o modelos complejos pueden ralentizar el entrenamiento.",
  "K-fold o repeated CV ayudan a elegir tasa de aprendizaje (learning rate) y n√∫mero de iteraciones (trials).",
  "No conviene con instancias altamente ruidosas: se puede sobreajustar r√°pidamente si la tasa de aprendizaje es alta o no se regula iteraciones."
)

tabla_adaboost <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)  

tabla_adaboost %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir adaboost",
             subtitle = "AdaBoost") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Stacked Generlizaation (Blending)  {-}  

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica o Continua (depende de los modelos base)",
  "‚úÖ Num√©ricas y/o categ√≥ricas (codificaci√≥n seg√∫n modelos base)",
  "‚úÖ Captura relaciones complejas v√≠a combinaci√≥n de modelos base",
  "‚ùå No exige supuestos de normalidad en residuos",
  "‚úÖ Deseable, pero no obligatorio (mejor si observaciones independientes)",
  "‚ùå No se asume homoscedasticidad",
  "‚ö†Ô∏è Moderadamente (outliers afectan modelos base individuales)",
  "‚ö†Ô∏è Puede verse afectado (depende de base learners y correlated features)",
  "‚ö†Ô∏è Baja (modelo meta dif√≠cil de interpretar directamente)",
  "‚ö†Ô∏è Lento en entrenamiento y predicci√≥n, seg√∫n n√∫mero de base learners",
  "‚úÖ Esencial (usar CV anidada para entrenar meta-modelo)",
  "‚ùå Si datos muy escasos o muy ruidosos, riesgo de sobreajuste"
)

detalles <- c(
  "Ensamble supervisado que combina varias predicciones (base learners) mediante un modelo meta.",
  "El meta-modelo acepta la salida de modelos base; puede predecir clases o valores continuos.",
  "Usa predictores originales para los base learners; algunos requieren dummies, otros no.",
  "Aprende patrones no lineales e interacciones complejas a trav√©s de m√∫ltiples capas.",
  "No impone distribuci√≥n normal: cada base learner tiene sus propios supuestos.",
  "Ideal si cada muestra es independiente; sensibles a dependencias en validaciones cruzadas.",
  "No requiere varianza constante, ya que se basa en agregaci√≥n de predicciones.",
  "Modelos base (p. ej. ARBOTS, SVM) pueden verse influenciados por valores extremos;",
  "Modelos base diversificados reducen colinealidad, pero meta-modelo puede verse afectado.",
  "Dif√≠cil atribuir importancia directa; se pueden usar t√©cnicas como SHAP para interpretaci√≥n.",
  "Entrenamiento de m√∫ltiples base learners y meta-modelo incrementa tiempo; predicci√≥n tambi√©n m√°s lenta.",
  "Usar validaci√≥n cruzada anidada: inner folds para entrenar base learners y stacking, outer folds para evaluar.",
  "No recomendable si hay muy pocos datos (stacking requiere dividir en folds) o si los base learners no aportan diversidad."
)

tabla_stacking <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)


tabla_stacking %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir blending",
             subtitle = "Stacked Generlizaation (Blending)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Gradient Boosted Regression Trees (GBRT)  {-}  

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Continua (regresi√≥n)",
  "‚úÖ Num√©ricas y categ√≥ricas (requiere codificaci√≥n para ciertas implementaciones)",
  "‚úÖ Captura no linealidades e interacciones complejas mediante boosting de √°rboles",
  "‚ùå No requiere supuestos de normalidad en residuos",
  "‚úÖ Deseable, aunque no obligatorio (mejor si instancias independientes)",
  "‚ùå No asume homoscedasticidad",
  "‚ö†Ô∏è Moderadamente (outliers pueden influir en √°rboles individuales)",
  "‚úÖ Robusto (los √°rboles reducen el impacto de colinealidad localmente)",
  "‚ö†Ô∏è Baja (modelo en su conjunto es ‚Äúcaja negra‚Äù)",
  "‚ö†Ô∏è Lento con muchos √°rboles o datos extensos",
  "‚úÖ Recomendable usar k-fold o repeated CV para ajuste de hiperpar√°metros",
  "‚ùå No es ideal si hay muy pocos datos o ruido excesivo"
)

detalles <- c(
  "Ensamble de √°rboles de regresi√≥n secuenciales donde cada √°rbol corrige errores del anterior mediante gradiente.",
  "Predice valores continuos sumando las predicciones ponderadas de m√∫ltiples √°rboles d√©biles.",
  "Funciona con variables mixtas; las categ√≥ricas suelen transformarse en dummies.",
  "Cada nuevo √°rbol se enfoca en los residuos del modelo anterior, capturando patrones complejos.",
  "No impone distribuci√≥n normal porque optimiza una funci√≥n de p√©rdida (por ejemplo, MSE) directamente.",
  "Mejor si las observaciones no est√°n correlacionadas en el tiempo; ajustar para series si es necesario.",
  "No requiere varianza constante puesto que se basa en √°rboles, no en un modelo param√©trico de errores.",
  "Los valores extremos pueden provocar ajustes excesivos en √°rboles individuales; usar tasa de aprendizaje baja ayuda a mitigar.",
  "Los √°rboles reducen el impacto de variables correlacionadas, aunque m√∫ltiples iteraciones pueden complicar interpretaciones.",
  "Dif√≠cil de interpretar directamente; se puede usar importancia de variables o herramientas como SHAP para explicaci√≥n.",
  "Cada iteraci√≥n entrena un √°rbol nuevo; muchos √°rboles o gran profundidad de √°rbol incrementan el tiempo de entrenamiento.",
  "CV ayuda a determinar par√°metros como tasa de aprendizaje (`learning_rate`), n√∫mero de √°rboles (`n.trees`) y profundidad m√°xima (`max_depth`).",
  "No es adecuado cuando el dataset es muy peque√±o o extremadamente ruidoso, ya que puede sobreajustar f√°cilmente."
)

tabla_gbrt <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_gbrt %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir GBRT",
             subtitle = "Gradient Boosted Regression Trees (GBRT)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```



## XGBoost  {-}   

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Continua (regresi√≥n) o Categ√≥rica (clasificaci√≥n)",
  "‚úÖ Num√©ricas y categ√≥ricas (requiere codificaci√≥n para dummies o label encoding)",
  "‚úÖ Captura no linealidades e interacciones complejas v√≠a √°rboles en boosting",
  "‚ùå No requiere supuestos de normalidad",
  "‚úÖ Deseable, aunque no obligatorio (mejor si instancias independientes)",
  "‚ùå No asume homoscedasticidad",
  "‚ö†Ô∏è Moderadamente (puede sobreajustar a outliers si no regula)",
  "‚úÖ Robusto (reduce efecto de colinealidad al usar √°rboles secuenciales)",
  "‚ö†Ô∏è Baja (modelo complejo y tipo ‚Äôcaja negra‚Äô)",
  "‚úÖ Muy r√°pido y escalable (implementaci√≥n optimizada, paralelizable)",
  "‚úÖ Recomendable usar k-fold o repeated CV para ajustar hiperpar√°metros",
  "‚ùå No es ideal con datos muy peque√±os, ruido alto o target extremadamente desbalanceado sin ajuste"
)

detalles <- c(
  "Ensamble supervisado que combina m√∫ltiples √°rboles d√©biles optimizados con gradiente descendente acelerado.",
  "En regresi√≥n predice valores continuos; en clasificaci√≥n combina probabilidades o clases mediante log-loss o multiclass objectives.",
  "Acepta variables mixtas; las categ√≥ricas deben convertirse a formatos compatibles (p. ej. factor numerico, one-hot encoding).",
  "Cada iteraci√≥n ajusta un nuevo √°rbol enfoc√°ndose en los residuos del modelo anterior, capturando patrones complejos.",
  "No impone distribuci√≥n param√©trica de errores, ya que optimiza funciones de p√©rdida directamente.",
  "Funciona mejor si cada muestra es independiente; sensible a series de tiempo sin preparaci√≥n apropiada.",
  "No requiere varianza constante, porque basa la optimizaci√≥n en gradientes del loss, no en supuestos de error.",
  "Los outliers dif√≠ciles de predecir pueden recibir demasiado peso en iteraciones sucesivas; usar _learning_rate_ bajo y _max_depth_ peque√±o para regular.",
  "Los √°rboles reducen el impacto de variables altamente correlacionadas, aunque m√∫ltiples iteraciones pueden a√∫n privilegiar caracter√≠sticas correlacionadas.",
  "Dif√≠cil interpretar directamente cada √°rbol; se utilizan m√©tricas de importancia, SHAP values o partial dependence plots para explicaci√≥n.",
  "Implementaci√≥n en C++ altamente optimizada (CPU/GPU), permite entrenamiento muy r√°pido incluso con millones de filas.",
  "Validaci√≥n cruzada anidada o simple ayuda a elegir hiperpar√°metros como `eta` (learning_rate), `nrounds` (n√∫mero de √°rboles), `max_depth`, `subsample`, `colsample_bytree`.",
  "No conviene con datasets muy peque√±os, ya que puede sobreajustar; tampoco si el ruido es muy alto y no se regula bien la complejidad."
)

tabla_xgboost <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_xgboost %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir xgboost",
             subtitle = "XGBoost")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## LightGBM  {-}    

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Continua (regresi√≥n) o Categ√≥rica (clasificaci√≥n)",
  "‚úÖ Num√©ricas y categ√≥ricas (requiere codificaci√≥n apropiada)",
  "‚úÖ Captura no linealidades e interacciones mediante √°rboles en boosting",
  "‚ùå No requiere supuestos de normalidad",
  "‚úÖ Deseable, aunque no obligatorio (mejor si instancias independientes)",
  "‚ùå No asume homoscedasticidad",
  "‚ö†Ô∏è Moderadamente (los outliers pueden influir en pesos de hojas)",
  "‚úÖ Robusto (usa histogram-based split que aten√∫a colinealidad)",
  "‚ö†Ô∏è Baja (modelo complejo tipo ‚Äòcaja negra‚Äô)",
  "‚úÖ Muy r√°pido y escalable (optimized gradient-based)",
  "‚úÖ Recomendable usar k-fold o repeated CV para ajustar hiperpar√°metros",
  "‚ùå No conviene con datos muy peque√±os o muy ruidosos sin regularizaci√≥n"
)

detalles <- c(
  "Ensamble supervisado que entrenan √°rboles de decisi√≥n usando histogram-based gradient boosting.",
  "En regresi√≥n predice valores continuos; en clasificaci√≥n maximiza log-loss u otras funciones objetivo.",
  "Acepta variables mixtas; las categ√≥ricas deben convertirse a formato num√©rico o usar encoding interno.",
  "Cada iteraci√≥n ajusta un √°rbol enfoc√°ndose en los residuos del anterior, capturando patrones complejos.",
  "No impone distribuci√≥n param√©trica de errores; optimiza la funci√≥n de p√©rdida directamente.",
  "Funciona mejor si las muestras son independientes; sensible a series de tiempo sin preparaci√≥n adecuada.",
  "No requiere varianza constante, dado que es un m√©todo basado en √°rbol, no en supuestos de error.",
  "Los valores extremos pueden afectar el c√°lculo de gradientes y splits; usar regularizaci√≥n y par√°metros de manejo de outliers.",
  "La divisi√≥n basada en histogramas reduce el impacto de predictores altamente correlacionados.",
  "Dif√≠cil interpretar cada √°rbol; se utilizan m√©tricas de importancia y herramientas como SHAP para explicaci√≥n.",
  "Implementaci√≥n en C++ altamente optimizada que permite entrenamiento muy r√°pido incluso con grandes vol√∫menes de datos.",
  "CV ayuda a elegir par√°metros como `learning_rate`, `num_leaves`, `max_depth`, `feature_fraction`, `bagging_fraction`.",
  "No es ideal si el dataset es muy peque√±o, pues el boosting puede sobreajustar; tampoco con mucho ruido sin regularizaci√≥n adecuada."
)

tabla_lightgbm <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_lightgbm %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir LightGBM",
             subtitle = "LightGBM")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

