# üîç **1. Regressi√≥n** {-}

**Ejemplos:** Linear Regression, Ridge, Lasso   
**Cu√°ndo usarlo:**

* Predicci√≥n de valores num√©ricos continuos (e.g. precios, temperaturas).  
* Relaciones lineales entre variables. 

**Ventajas:** Simple, interpretable.   
**Limitaciones:** Mal desempe√±o con relaciones no lineales complejas.

## Ordinary Least Squares Regression (`OLSR`) {-} 

**Regresi√≥n de M√≠nimos Cuadrados Ordinarios (OLSR)**: un m√©todo de regresi√≥n lineal para estimar los par√°metros desconocidos mediante la creaci√≥n de un modelo que minimizar√° la suma de los errores cuadrados entre los datos observados y los predichos (valores observados y valores estimados).   

```{r, echo = FALSE}
# Datos de la tabla
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Num√©rica continua",
  "‚úÖ Num√©ricas y/o categ√≥ricas",
  "‚úÖ Lineal (supuesto clave)",
  "‚òëÔ∏è Deseable",
  "‚úÖ Necesaria",
  "‚úÖ Necesaria",
  "‚ö†Ô∏è S√≠",
  "‚ö†Ô∏è Problema com√∫n",
  "‚úÖ Alta",
  "‚úÖ Muy alta",
  "‚úÖ Compatible",
  "‚ùå Relaciones no lineales, outliers severos, colinealidad"
)

detalles <- c(
  "Se entrena con datos X ‚Üí y",
  "Ej. mpg, precio, ingresos",
  "Categor√≠as convertidas a dummies",
  "Se asume una relaci√≥n lineal entre X e Y",
  "Importante para intervalos de confianza v√°lidos",
  "Errores deben ser independientes",
  "Varianza de errores debe ser constante",
  "Outliers pueden influir mucho en el modelo",
  "Usar VIF para detectar problemas",
  "Modelo f√°cil de explicar",
  "R√°pido incluso con datos grandes",
  "Ayuda a prevenir overfitting",
  "Evitar si no hay linealidad o hay muchos outliers"
)

# Crear y mostrar tabla
tabla_olsr <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

require(gt)

tabla_olsr %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir OLSR",
             subtitle = "Regresi√≥n de M√≠nimos Cuadrados Ordinarios (OLSR)") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Linear Regression {-} 

**Regresi√≥n lineal** : se utiliza para estimar valores reales (costo de las casas, n√∫mero de visitas, ventas totales, etc.) basados en variables continuas.  


## Logistic Regression {-} 

**Regresi√≥n log√≠stica** : se utiliza para estimar valores discretos (valores binarios como 0/1, s√≠/no, verdadero/falso) basados en un conjunto dado de variables independientes. 

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica binaria (0/1)",
  "‚úÖ Num√©ricas y categ√≥ricas",
  "‚úÖ Lineal entre log-odds y predictores",
  "‚ùå No es requisito",
  "‚úÖ Necesaria",
  "‚úÖ Deseable",
  "‚ö†Ô∏è S√≠",
  "‚ö†Ô∏è Puede afectar",
  "‚úÖ Alta (coeficientes interpretables)",
  "‚úÖ Alta",
  "‚úÖ Compatible",
  "‚ùå Respuesta no binaria o multiclase sin ajuste"
)

detalles <- c(
  "Clasificaci√≥n binaria",
  "Ej. √©xito/fracaso, s√≠/no",
  "Convertir categ√≥ricas a dummies",
  "Relaci√≥n entre log(p/(1-p)) y X debe ser lineal",
  "No se exige normalidad en errores",
  "Independencia entre observaciones",
  "Idealmente varianza constante",
  "Outliers pueden alterar los coeficientes",
  "Usar VIF y regularizaci√≥n si hay problema",
  "Coeficientes en t√©rminos de odds/log-odds",
  "R√°pido y estable para datasets medianos",
  "K-fold funciona muy bien",
  "Evitar si hay multiclase sin ajuste"
)

tabla_logit <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)  

require(gt)

tabla_logit %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir logit",
             subtitle = "Regresi√≥n log√≠stica") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Locally Estimated Scatterplot Smoothing (`LOESS`) {-} 

**Locally Estimated Scatterplot Smoothing (`LOESS`)**: un m√©todo para ajustar una curva suave entre dos variables o una superficie  entre un resultado y hasta cuatro variables predictoras. La idea es que, si los datos no se distribuyen linealmente, se puede aplicar el concepto de regresi√≥n. Se puede aplicar regresi√≥n, lo que se denomina regresi√≥n ponderada localmente. Se puede aplicar LOESS cuando la relaci√≥n entre las variables independientes y dependientes no es lineal. Hoy en d√≠a, la mayor√≠a de los algoritmos (como las redes neuronales de propagaci√≥n hacia adelante cl√°sicas, las m√°quinas de vectores de soporte, los algoritmos del vecino m√°s cercano, etc.) son sistemas de aprendizaje global que se utilizan para minimizar las funciones de p√©rdida globales (por ejemplo, el error cuadr√°tico medio). Por el contrario, los sistemas de aprendizaje local dividen el problema de aprendizaje global en m√∫ltiples problemas de aprendizaje m√°s peque√±os y simples. Esto generalmente se logra dividiendo la funci√≥n de costo en m√∫ltiples funciones de costo locales independientes. Una de las desventajas de los m√©todos globales es que, a veces, ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena. Pero entonces surge LOESS, una alternativa a la aproximaci√≥n de funciones globales.   


```{r, echo = FALSE} 
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Continua",
  "‚úÖ Num√©ricas (usualmente 1 o 2 predictores)",
  "‚úÖ No lineal y suave",
  "‚ùå No necesaria",
  "‚úÖ Deseable",
  "‚úÖ Deseable",
  "‚ö†Ô∏è Muy sensible",
  "‚ùå No aplica (pocos predictores)",
  "‚úÖ Muy interpretable gr√°ficamente",
  "‚ö†Ô∏è Lento en grandes vol√∫menes de datos",
  "‚úÖ Puede usarse para elegir 'span'",
  "‚ùå Datos grandes o con ruido fuerte"
)

detalles <- c(
  "Modelo no param√©trico local",
  "Regresi√≥n para valores continuos",
  "Generalmente 1 o 2 variables num√©ricas",
  "Ajuste por vecindad, suaviza la curva",
  "No asume distribuci√≥n espec√≠fica",
  "Supuesto deseable si hay dependencias temporales",
  "Ideal si la varianza no cambia mucho localmente",
  "Altamente afectado por outliers locales",
  "No es una t√©cnica multivariable compleja",
  "La curva ajustada se interpreta visualmente",
  "Computacionalmente costoso con datos grandes",
  "Ayuda a seleccionar el mejor 'span'",
  "Poco eficaz en alta dimensi√≥n o datos muy dispersos"
)

tabla_loess <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_loess %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir LOESS",
             subtitle = "Locally Estimated Scatterplot Smoothing (LOESS)") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Multivariate Adaptive Regression Splines (`MARS`) {-} 

**Splines de Regresi√≥n Adaptativa Multivariante (`MARS`)**: un m√©todo de regresi√≥n flexible que busca interacciones y relaciones no lineales que ayudan a maximizar la precisi√≥n predictiva. Este algoritmo es inherentemente no lineal (lo que significa que no es necesario adaptar el modelo a patrones no lineales en el datos agregando manualmente t√©rminos del modelo (squared terms, interaction effects).   

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Continua o categ√≥rica (binaria con extensi√≥n)",
  "‚úÖ Num√©ricas (categ√≥ricas con dummies)",
  "‚úÖ No lineal (autom√°tico)",
  "‚ùå No requerida",
  "‚úÖ Deseable",
  "‚úÖ Deseable",
  "‚ö†Ô∏è S√≠ (aunque algo robusto)",
  "‚ö†Ô∏è Puede afectar",
  "‚ö†Ô∏è Media (modelo tipo caja negra)",
  "‚úÖ Razonable para tama√±os medianos",
  "‚úÖ Recomendado (ej. repeated k-fold)",
  "‚ùå Relaci√≥n puramente lineal o muchos factores irrelevantes"
)

detalles <- c(
  "Regresi√≥n flexible no lineal",
  "Ideal para regresi√≥n continua (tambi√©n clasificaci√≥n con `earth`)",
  "Crea autom√°ticamente 'splines' por variable",
  "Crea funciones por tramos con 'nudos'",
  "No exige distribuci√≥n espec√≠fica de errores",
  "Mejor si los datos no est√°n correlacionados temporalmente",
  "Idealmente errores con varianza constante",
  "Puede ser sensible a valores extremos",
  "Detecta interacciones, pero VIF sigue siendo √∫til",
  "Coeficientes no tan interpretables como OLS",
  "M√°s lento que OLS pero m√°s flexible",
  "CV ayuda a elegir n√∫mero √≥ptimo de t√©rminos",
  "Tiene riesgo de sobreajuste si no se controla bien"
)

tabla_mars <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)  

require(gt)

tabla_mars %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir MARS",
             subtitle = "Splines de Regresi√≥n Adaptativa Multivariante (MARS)") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```



## Stepwise Regression {-} 

**Regresi√≥n por pasos** : a√±ade caracter√≠sticas al modelo una a una hasta encontrar la puntuaci√≥n √≥ptima para tu conjunto de caracter√≠sticas. La selecci√≥n por pasos alterna entre el avance y el retroceso, incorporando y eliminando variables que cumplen los criterios de entrada o eliminaci√≥n, hasta alcanzar un conjunto estable de variables.  


## Support Vector Machine (SVM) {-}  

**Support Vector Machine (SVM)** es un potente m√©todo de **aprendizaje supervisado** utilizado para tareas de **clasificaci√≥n** y **regresi√≥n**, aunque es m√°s conocido y aplicado en problemas de clasificaci√≥n. La idea fundamental detr√°s de SVM es encontrar el **hiperplano √≥ptimo** que mejor separe las clases de datos en un espacio de caracter√≠sticas.

A diferencia de otros algoritmos que podr√≠an intentar ajustar una curva o superficie a todos los datos, SVM se enfoca en los **vectores de soporte**: los puntos de datos que est√°n m√°s cerca del hiperplano de decisi√≥n y que, por lo tanto, son los m√°s dif√≠ciles de clasificar. Estos vectores de soporte son los que definen el margen de separaci√≥n entre las clases. El objetivo de SVM es maximizar este **margen** entre el hiperplano y los vectores de soporte m√°s cercanos, lo que generalmente conduce a una mejor **generalizaci√≥n** y menor riesgo de sobreajuste.

Mientras que algunos algoritmos buscan una aproximaci√≥n de funci√≥n global √∫nica que minimice una funci√≥n de p√©rdida (como el error cuadr√°tico medio), SVM puede ser visto como un sistema de **aprendizaje global** que busca optimizar un criterio global: el margen. Sin embargo, su capacidad para trabajar con **kernels** (como el kernel lineal, polinomial, de base radial (RBF) o sigmoide) le permite mapear los datos a un espacio de dimensiones superiores donde pueden ser linealmente separables, incluso si no lo son en el espacio original. Esta "transformaci√≥n" a trav√©s de la funci√≥n kernel permite a SVM manejar relaciones complejas y no lineales entre las variables independientes y dependientes, lo que lo convierte en una alternativa robusta a la aproximaci√≥n de funciones globales simples. Si los datos no se distribuyen linealmente, el concepto de regresi√≥n (o clasificaci√≥n) se puede aplicar eficazmente utilizando esta capacidad de mapeo para encontrar una separaci√≥n √≥ptima.



```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica o Continua",
  "‚úÖ Num√©ricas (categor√≠as deben codificarse)",
  "‚úÖ Capta relaciones no lineales (kernel)",
  "‚ùå No requiere",
  "‚úÖ Idealmente s√≠",
  "‚ùå No es requisito",
  "‚ö†Ô∏è S√≠, especialmente sin margen amplio",
  "‚úÖ Puede manejarla bien",
  "‚ùå Baja (modelo es una caja negra)",
  "‚ö†Ô∏è Lento con muchos datos o predictores",
  "‚úÖ Esencial para elegir kernel y par√°metros",
  "‚ùå Datos con mucho ruido o solapamiento entre clases"
)

detalles <- c(
  "Modelo supervisado que maximiza el margen entre clases",
  "Clasificaci√≥n binaria, multiclase o regresi√≥n (SVR)",
  "Requiere escalar o estandarizar las variables num√©ricas",
  "Puede usar kernel para resolver problemas no lineales",
  "No requiere supuestos cl√°sicos como normalidad",
  "Mejor si los datos son independientes",
  "Puede usarse aunque haya heterocedasticidad",
  "Los outliers cercanos al margen afectan el modelo",
  "Los kernels pueden reducir el efecto de multicolinealidad",
  "Dif√≠cil de explicar; es un modelo de tipo caja negra",
  "Puede ser costoso computacionalmente con datos grandes",
  "Par√°metros como C y gamma se ajustan v√≠a validaci√≥n cruzada",
  "No es ideal si hay ruido o datos mal etiquetados"
)

tabla_svm <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

require(gt) 

tabla_svm %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir SVM",
             subtitle = "Support Vector Machine (SVM) ") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```




