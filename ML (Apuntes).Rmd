--- 
title: "Machine Learning (Apuntes) "
author: "Diana Villasana Ocampo"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This is a minimal example of using the bookdown package to write a book.
  The HTML output format for this example is bookdown::bs4_book,
  set in the _output.yml file.
biblio-style: apalike
csl: chicago-fullnote-bibliography.csl
---

# url: your book url like https://bookdown.org/yihui/bookdown

Placeholder


## üìå Cuadro {-}

<!--chapter:end:index.Rmd-->


# üîç **1. Regressi√≥n** {.unnumbered}

Placeholder


## Ordinary Least Squares Regression (`OLSR`) {-}   
## Linear Regression {.unnumbered}
## Regresi√≥n Log√≠stica {.unnumbered}
## Locally Estimated Scatterplot Smoothing (`LOESS`) {.unnumbered}
## Multivariate Adaptive Regression Splines (`MARS`) {.unnumbered}
## Stepwise Regression {.unnumbered}
## Support Vector Machine (SVM) {.unnumbered}

<!--chapter:end:01-regression.Rmd-->


# üå≤ **2. √Årboles de Decisi√≥n y Derivados** {-}  

Placeholder


## C4.5  {-}   
## C5.0  {-}  
## Classification and Regression Tree (CART)  {-} 
## Chi-squared Automatic Interaction Detection (CHAID)  {-}    
## Conditional Decision Trees (Conditional Inference Trees - CITs)  {-}   
## Decision Stump  {-}  
## Iterative Dichotomiser 3 (ID3)  {-}    
## M5 (Model Tree) {-}  

<!--chapter:end:02-decision_tree.Rmd-->


# üåü **3. Ensambles (Ensemble Methods)** {-}

Placeholder


## Adaptive Boosting (AdaBoost)  {-}  
## Boosting  {-}   
## Bootstrapped Aggregation (Bagging)  {-}    
## Extreme Gradient Boosting (XGBoost)  {-}    
## Gradient Boosting Machines (GBM)  {-}   
## Gradient Boosted Regression Trees (GBRT)  {-}   
## Light Gradient Boosting Machine (LightGBM)  {-}   
## Random Forest  {-}   
## Stacked Generlization (Blending) {-}   

<!--chapter:end:03-ensemble.Rmd-->


# üß† **4. Redes Neuronales y Deep Learning** {-}  

Placeholder


## Autoenconder  {-}  
## Back - Propagation  {-}  
## Convolutional Neural Network (CNN)  {-}   
## Hopfield Network  {-}   
## Multilayer Perceptron (MP)  {-}     
## Perceptron  {-}     
## Radial Basis Function Network (RBFN)  {-}      
## Recurrent Neural Networks (RNNs) {-}   
## Transformers  {-}  

<!--chapter:end:04-neural-networks.Rmd-->


# üß© **5. Reducci√≥n de Dimensionalidad** {-}   

Placeholder


## Flexible Discriminant Analysis (FDA)  {-}   
## Linear Discriminant Analysis (LDA)  {-}    
## Mixture Discriminant Analysis (MDA)  {-}   
## Multidimensional Scaling (MDS)  {-}    
## Quadratic Discriminant Analysis (QDA) {-}  
## Partial Least Squares Regression (PLSR)  {-}    
## Partial Least Squares Discriminant Analysis (PLSDA)  {-}   
## Principal Component Analysis (PCA)  {-}   
## Principal Component Regression (PCR)  {-}    
## Projection Pursuit (PP)  {-}     
## Sammon Mapping  {-}   
## Regularized Discriminant Analysis (RDA)  {-}    
## Uniform Manifold Approximation and Projection (UMAP) {-}   

<!--chapter:end:05-dimensionality_reduction.Rmd-->


# üß¨ **6. Bayesianos** {-}  

Placeholder


## Averaged One - Dependence Estimators (AODE)  {-}    
## Bayesian Network (BN)  {-}    
## Bayesian Belief Network (BBN)  {-}  
## Gaussian Naive Bayes (GNB) {-}     
## Multinomial Naive Bayes (MNB) {-}   
## Naive Bayes (NB) {-}   

<!--chapter:end:06-bayesian.Rmd-->


# üßÆ **7. Regularizaci√≥n** {-}  

Placeholder


## Elastic Net  {-}   
## Ridge Regression  {-}    
## Least Absolute Shrinkage and Selection Operator (LASSO)  {-}  
## Least Angle Regression (LARS)  {-}   

<!--chapter:end:07-regularization.Rmd-->


# üîç **8. Instance-Based (Basados en Instancias)** {-}  

Placeholder


## k - Nearest Neighbour (kNN)  {-}    
## Learning Vector Quantization (LVQ)  {-}    
## Locally Weighted Learning (LWL)  {-}   
## Self - Organizing Map (SOM)  {-}   

<!--chapter:end:08-instance_based.Rmd-->


# üìè **9. Clustering (No Supervisado)** {-}  

Placeholder


## Density-Based Spatial Clustering of Applications with Noise (DBSCAN)  {-}    
## Expectation Maximization (EM) {-}  
## Hierarchical Clustering (hclust) {-}  
## k-Means  {-}   
## k-Medians  {-}    

<!--chapter:end:09-clustering.Rmd-->

```{r include=FALSE, cache=FALSE}
# example R options set globally
options(width = 80)

# example chunk options set globally
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  message = FALSE,
  warning = FALSE
)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
setwd(here::here())
```
# üìê **10. Sistemas Basados en Reglas (Rule-Based Systems)** {-}

**Ejemplos:** RuleFit, Decision Rules, l√≥gica difusa
**Cu√°ndo usarlo:**

* Interpretabilidad es clave (por ejemplo, decisiones legales o m√©dicas).
* Incorporar conocimiento experto.

**Ventajas:** F√°cil de entender y auditar.   
**Limitaciones:** No tan precisos como otros m√©todos en datos complejos.

---

## Cubist  {-}   

**Cubist** es un algoritmo de **Machine Learning** desarrollado por RuleQuest Research (autores de C4.5 y See5/C5.0), principalmente para tareas de **regresi√≥n**. Es una extensi√≥n de los modelos de **√°rboles de decisi√≥n** que combina la simplicidad de las reglas con la precisi√≥n de los modelos locales, lo que lo hace muy potente para datos complejos con muchas caracter√≠sticas.

En esencia, Cubist construye un **modelo de reglas con un modelo lineal adjunto a cada regla**. Opera en dos fases principales:

1.  **Construcci√≥n del √Årbol de Reglas:**
    * Similar a un √°rbol de decisi√≥n, Cubist construye una estructura de √°rbol dividiendo los datos en subconjuntos basados en los valores de las caracter√≠sticas.
    * Sin embargo, en lugar de hojas que contienen un valor constante (como en los √°rboles de regresi√≥n tradicionales), cada hoja de este √°rbol se transforma en un **conjunto de reglas**.
    * A cada regla se le asocia un **modelo lineal multivariado local** (o un "modelo de comit√©" de reglas, donde varias reglas contribuyen a la predicci√≥n). Este modelo lineal se entrena solo con los datos que satisfacen las condiciones de esa regla.

2.  **Ajuste del Modelo de Reglas y Predicci√≥n:**
    * Para cada nueva instancia de predicci√≥n, Cubist identifica las reglas que se aplican a esa instancia.
    * La predicci√≥n final se calcula combinando las predicciones de los modelos lineales de las reglas que se aplican, y luego se ajusta un poco esa predicci√≥n mediante un **"comit√©" de vecinos** (ajustes locales adicionales basados en ejemplos similares), si est√° configurado para ello. Esta etapa de ajuste lo hace a√∫n m√°s robusto.

Cubist es valorado por su capacidad para manejar **relaciones complejas y no lineales** en los datos. Proporciona un modelo que es m√°s interpretable que una "caja negra" (como una red neuronal profunda) debido a su base en reglas, pero mucho m√°s preciso que los modelos lineales o los √°rboles de regresi√≥n simples, gracias a sus modelos lineales locales y ajustes.


**Aprendizaje Global vs. Local:**

Cubist es un algoritmo que combina de manera muy efectiva aspectos de **aprendizaje global y local**.

* **Aspecto Global (Estructura de Reglas):** La fase de construcci√≥n del √°rbol y la derivaci√≥n de las reglas crean una **estructura global** que divide el espacio de caracter√≠sticas. Este conjunto de reglas abarca todo el dominio de los datos y determina qu√© modelo local se aplicar√° a una instancia. Es una forma de particionar el espacio de caracter√≠sticas de manera jer√°rquica para establecer un marco de predicci√≥n general.

* **Aspecto Local (Modelos Lineales y Ajustes):** Aqu√≠ es donde Cubist brilla en su capacidad de aprendizaje local:
    * **Modelos Lineales Locales:** Cada regla tiene asociado un **modelo lineal que se entrena solo con los datos que caen dentro de esa regla**. Esto permite a Cubist capturar **relaciones locales y no lineales** de manera precisa. En lugar de una √∫nica relaci√≥n lineal global, el modelo se adapta a las particularidades de diferentes subregiones de los datos.
    * **Ajuste Basado en Vecinos:** Si se activa la opci√≥n de "comit√©" o el ajuste basado en vecinos (conocido como `committees` o `neighbors`), el modelo refina a√∫n m√°s su predicci√≥n incorporando la informaci√≥n de los ejemplos de entrenamiento m√°s cercanos al punto de consulta. Esto es una forma de **"regresi√≥n ponderada localmente"**, donde la predicci√≥n final se ajusta en funci√≥n de los patrones observados en el vecindario inmediato del punto de inter√©s.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (regresi√≥n basada en reglas)",
  "‚úÖ Num√©rica (regresi√≥n)",
  "‚úÖ Num√©ricas y categ√≥ricas",
  "‚úÖ Modelo aditivo basado en reglas y ajustes lineales locales",
  "‚ö†Ô∏è Requiere an√°lisis de residuos, no siempre normalidad estricta",
  "‚ö†Ô∏è Asume independencia, como otros modelos supervisados",
  "‚ö†Ô∏è Puede tener heteroscedasticidad",
  "‚ö†Ô∏è Moderadamente sensible a outliers",
  "‚ö†Ô∏è Puede manejar correlaci√≥n, pero multicolinealidad puede afectar interpretabilidad",
  "‚úÖ Moderada: reglas explican el modelo, pero menos transparente que modelos lineales",
  "‚ö†Ô∏è Relativamente r√°pido, pero depende del n√∫mero de reglas",
  "‚úÖ Compatible con validaci√≥n cruzada para evaluar rendimiento",
  "‚ùå No funciona bien con datos muy peque√±os o ruido extremo"
)

detalles <- c(
  "Combina t√©cnicas de √°rboles de decisi√≥n con modelos lineales locales para predicci√≥n precisa.",
  "Predice variables continuas mediante reglas que dividen el espacio y ajustes lineales en cada regi√≥n.",
  "Puede manejar variables predictoras mixtas (num√©ricas y categ√≥ricas).",
  "Modelo flexible que ajusta m√∫ltiples reglas para capturar relaciones no lineales y locales.",
  "Evaluar residuos para verificar supuestos; no es tan r√≠gido como OLS.",
  "Como modelo supervisado, se espera independencia entre observaciones.",
  "Puede tolerar algo de heteroscedasticidad, pero afecta precisi√≥n de intervalos.",
  "Outliers pueden afectar algunas reglas locales y coeficientes.",
  "Multicolinealidad puede dificultar interpretaci√≥n de coeficientes locales.",
  "Las reglas pueden interpretarse, pero el modelo global puede ser complejo.",
  "La velocidad depende del tama√±o del dataset y n√∫mero de reglas generadas.",
  "Se usa validaci√≥n cruzada para seleccionar par√°metros y validar modelo.",
  "No es ideal para datasets muy peque√±os o con mucho ruido no estructurado."
)

tabla_cubist <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_cubist %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir cubist",
             subtitle = "Cubist")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Decision Rules  {-}  

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n o regresi√≥n)",
  "‚úÖ Num√©rica o categ√≥rica",
  "‚úÖ Num√©ricas y categ√≥ricas",
  "‚úÖ Basado en reglas (if-then) que segmentan el espacio predictor",
  "‚ùå No aplica directamente (no es un modelo param√©trico)",
  "‚ö†Ô∏è Asume independencia de observaciones",
  "‚ùå No aplica",
  "‚ö†Ô∏è Moderadamente sensible, outliers pueden crear reglas poco √∫tiles",
  "‚ö†Ô∏è No afecta directamente, pero reglas redundantes pueden complicar modelo",
  "‚úÖ Muy interpretable, reglas claras y simples",
  "‚úÖ R√°pido para datasets peque√±os y medianos",
  "‚úÖ Compatible con validaci√≥n cruzada",
  "‚ùå Puede sobreajustar si hay mucho ruido o datos muy complejos"
)

detalles <- c(
  "Modelos que usan reglas l√≥gicas para realizar predicciones, f√°cilmente entendibles.",
  "Permite predecir tanto clases (clasificaci√≥n) como valores num√©ricos (regresi√≥n).",
  "Acepta tanto variables categ√≥ricas como num√©ricas como predictores.",
  "Segmenta el espacio en regiones mediante reglas que dividen las variables predictoras.",
  "No genera residuos ni supone distribuci√≥n de error como modelos param√©tricos.",
  "Las reglas asumen que las observaciones son independientes.",
  "No aplica homoscedasticidad porque no es un modelo estad√≠stico cl√°sico.",
  "Outliers pueden influir en la generaci√≥n de reglas, creando reglas poco generalizables.",
  "La multicolinealidad no afecta directamente, pero puede generar reglas redundantes.",
  "La fortaleza es la interpretabilidad clara y sencilla de las reglas obtenidas.",
  "Generalmente eficiente, pero depende del n√∫mero de reglas y complejidad del dataset.",
  "Se recomienda validar con m√©todos como k-fold para evitar sobreajuste.",
  "No es ideal para datasets con mucho ruido o cuando la relaci√≥n es muy compleja o sutil."
)

tabla_rules <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_rules %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision rules",
             subtitle = "Decision Rules")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## L√≥gica Difusa (Fuzzy Logic) {-}

La **L√≥gica Difusa (Fuzzy Logic)** no es un algoritmo de Machine Learning en s√≠ mismo, sino un **paradigma de computaci√≥n basado en la noci√≥n de "grado de verdad"** en lugar de los valores binarios "verdadero o falso" (1 o 0) de la l√≥gica booleana cl√°sica. Permite modelar el razonamiento humano, que a menudo involucra informaci√≥n imprecisa, ambigua o vaga. Es un marco para representar y manipular el conocimiento que es inherentemente incierto o subjetivo.

La idea central de la l√≥gica difusa es que un elemento puede **pertenecer a un conjunto en un cierto grado** (entre 0 y 1), en lugar de pertenecer completamente o no pertenecer en absoluto. Por ejemplo, una persona puede ser "alta" en un grado de 0.8 y "mediana" en un grado de 0.2, en lugar de ser estrictamente alta o estrictamente mediana.

Los componentes clave de un sistema de l√≥gica difusa suelen incluir:

1.  **Conjuntos Difusos (Fuzzy Sets):** Definen el grado de pertenencia de un elemento a una categor√≠a. Por ejemplo, un conjunto difuso para "temperatura alta" podr√≠a tener una funci√≥n de pertenencia que asigne un valor de 0 a 10 grados, 0.5 a 20 grados, y 1 a 30 grados.
2.  **Variables Ling√º√≠sticas:** Son variables cuyos valores son palabras o oraciones del lenguaje natural (ej., "temperatura", cuyos valores pueden ser "fr√≠o", "tibio", "caliente").
3.  **Funciones de Pertenencia (Membership Functions):** Gr√°ficos que definen matem√°ticamente el grado de pertenencia de un elemento a un conjunto difuso.
4.  **Reglas Difusas (Fuzzy Rules):** Reglas de tipo "SI-ENTONCES" que utilizan variables ling√º√≠sticas y conjuntos difusos. Por ejemplo: "SI la temperatura es *caliente* Y la humedad es *alta* ENTONCES la velocidad del ventilador es *r√°pida*".
5.  **Fuzificaci√≥n:** Proceso de convertir valores de entrada n√≠tidos (crisp inputs) en grados de pertenencia a conjuntos difusos.
6.  **Motor de Inferencia:** Aplica las reglas difusas para producir una salida difusa.
7.  **Defuzificaci√≥n:** Proceso de convertir la salida difusa en un valor de salida n√≠tido (crisp output) que pueda ser utilizado en el mundo real.

La l√≥gica difusa es ampliamente utilizada en sistemas de control (ej., lavadoras, sistemas de frenos ABS, c√°maras de video), sistemas expertos y en el procesamiento de informaci√≥n imprecisa.

**Aprendizaje Global vs. Local:**

La L√≥gica Difusa, como paradigma, tiene la capacidad de integrar aspectos de **modelado global y local**, dependiendo de c√≥mo se implemente y se "entrene" (o sintonice).

* **Aspecto Local (Granularidad de las Reglas y Conjuntos Difusos):**
    * Las **reglas difusas** operan sobre condiciones locales (ej., "SI la temperatura es *caliente*"). Cada regla cubre una porci√≥n espec√≠fica del espacio de entrada/salida. Los **conjuntos difusos** y sus funciones de pertenencia particionan el espacio de caracter√≠sticas en regiones "borrosas" o traslapadas, lo que permite que el modelo se adapte a las caracter√≠sticas de los datos en vecindarios espec√≠ficos. Es decir, la respuesta del sistema se construye a partir de la activaci√≥n ponderada de varias reglas locales, cada una representando un comportamiento en una regi√≥n del espacio de entrada. Esto es muy similar a una **"regresi√≥n ponderada localmente"**, donde la contribuci√≥n de cada regla (o modelo impl√≠cito) se pondera por el grado en que la entrada actual pertenece a la regi√≥n de esa regla. Esta granularidad y superposici√≥n le permiten manejar **relaciones no lineales y complejas** al aproximarlas con una combinaci√≥n de estas contribuciones locales.

* **Aspecto Global (Coherencia del Sistema y Cobertura):**
    * Aunque las reglas son locales, un sistema de l√≥gica difusa bien dise√±ado cubre todo el espacio de entrada relevante y proporciona una **respuesta global coherente**. El conjunto de todas las reglas y funciones de pertenencia, junto con el motor de inferencia, forma un **sistema global** que puede mapear cualquier entrada a una salida. La defuzificaci√≥n final produce un valor n√≠tido que es el resultado de la combinaci√≥n de todas las activaciones de las reglas.

* **Aprendizaje y Sintonizaci√≥n:** Cuando se combinan con t√©cnicas de Machine Learning (como redes neuronales o algoritmos gen√©ticos), los sistemas difusos pueden "aprender" o "sintonizar" sus funciones de pertenencia y reglas. Este proceso de aprendizaje puede optimizar el rendimiento del sistema a nivel global (minimizando un error general), pero los ajustes siguen afectando las propiedades locales de las reglas y conjuntos difusos.

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado o no supervisado (depende del sistema)",
  "‚úÖ Variables de salida pueden ser continuas o categ√≥ricas (fuzzy sets)",
  "‚úÖ Variables num√©ricas o categ√≥ricas, modeladas como grados de pertenencia",
  "‚úÖ Modela relaciones imprecisas, no binarias, usando l√≥gica difusa",
  "‚ùå No aplica (no modelo estad√≠stico tradicional)",
  "‚ö†Ô∏è Puede asumir independencia pero depende del dise√±o del sistema",
  "‚ùå No aplica",
  "‚ö†Ô∏è Moderadamente sensible, depende de la funci√≥n de membres√≠a",
  "‚ö†Ô∏è No afecta directamente pero variables correlacionadas pueden complicar reglas",
  "‚úÖ Interpretaci√≥n basada en reglas ling√º√≠sticas y grados de verdad",
  "‚ö†Ô∏è Puede ser lento con muchos conjuntos difusos y reglas complejas",
  "‚ö†Ô∏è Validaci√≥n cruzada posible, pero no est√°ndar en l√≥gica difusa",
  "‚ùå No es adecuado si los datos son muy exactos y no presentan incertidumbre"
)

detalles <- c(
  "Sistemas que usan l√≥gica difusa para manejar incertidumbre y aproximaci√≥n en los datos.",
  "Las variables respuesta pueden ser valores continuos o categor√≠as definidas mediante conjuntos difusos.",
  "Los predictores se transforman en grados de pertenencia a conjuntos difusos para evaluar reglas.",
  "Permite modelar relaciones vagamente definidas, imprecisas o con fronteras difusas.",
  "No se basa en supuestos estad√≠sticos cl√°sicos, por eso no aplica normalidad.",
  "La independencia depende de c√≥mo se dise√±en las reglas y sistemas difusos.",
  "No es un modelo param√©trico cl√°sico, por eso homoscedasticidad no aplica.",
  "Outliers pueden afectar las funciones de pertenencia y la l√≥gica aplicada.",
  "Variables altamente correlacionadas pueden hacer que las reglas sean redundantes o complejas.",
  "Los resultados se interpretan mediante reglas tipo 'Si... entonces...' con grados de verdad.",
  "La complejidad crece con n√∫mero de variables y reglas, afectando velocidad.",
  "Validar es menos est√°ndar, se usan m√©todos espec√≠ficos seg√∫n la aplicaci√≥n.",
  "No es √∫til para datos precisos donde no existe incertidumbre o imprecisi√≥n."
)

tabla_fuzzy <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_fuzzy %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision fuzzy rules",
             subtitle = "Fuzzy Rules")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```



## One Rule (OneR)  {-}   

**One Rule (OneR)** es un algoritmo de **clasificaci√≥n supervisada** notable por su **simplicidad y alta interpretabilidad**. Fue propuesto por Robert Holte en 1993 y, a pesar de su sencillez, a menudo logra una precisi√≥n sorprendentemente buena en comparaci√≥n con algoritmos mucho m√°s complejos, sirviendo como una excelente l√≠nea base (benchmark) para el rendimiento del modelo.

La idea central de OneR es construir un clasificador que se base en **una √∫nica regla** para tomar decisiones. Esta regla se deriva de **un solo atributo (caracter√≠stica)** del conjunto de datos que es el m√°s predictivo de la clase de salida.

El funcionamiento del algoritmo OneR es el siguiente:

1.  **Iterar a Trav√©s de Cada Atributo:** Para cada atributo en el conjunto de datos de entrenamiento (se asume que los atributos son categ√≥ricos; si son continuos, primero deben discretizarse):
    * **Crear una Regla para Cada Valor:** Para cada valor √∫nico que puede tomar ese atributo, se construye una regla.
    * **Encontrar la Clase M√°s Frecuente:** Para cada una de estas reglas, se cuenta cu√°ntas veces aparece cada clase de destino cuando el atributo toma ese valor. La clase que ocurre con mayor frecuencia se convierte en la predicci√≥n para esa regla.
    * **Calcular el Error de la Regla:** Se calcula el n√∫mero de errores que comete esta regla (es decir, el n√∫mero de instancias para las cuales la clase predicha no coincide con la clase real).
2.  **Seleccionar el Mejor Atributo:** Una vez que se han generado reglas y calculado los errores para *todos* los atributos, OneR selecciona el atributo (y su conjunto de reglas asociadas) que tiene el **menor error total**. Si hay un empate entre varios atributos, se puede elegir el primero o usar un criterio secundario (como el test de chi-cuadrado).
3.  **El Modelo Final:** El conjunto de reglas derivado de este atributo seleccionado se convierte en el modelo final de clasificaci√≥n.

Por ejemplo, si tenemos un atributo "Clima" con valores "Soleado", "Nublado", "Lluvioso" y una clase "Jugar al Golf" (S√≠/No):
* Si Clima = Soleado: La mayor√≠a juega golf (S√≠). Error: 2 (de 5)
* Si Clima = Nublado: La mayor√≠a juega golf (S√≠). Error: 0 (de 4)
* Si Clima = Lluvioso: La mayor√≠a NO juega golf (No). Error: 1 (de 5)
* Error total para "Clima" = 2 + 0 + 1 = 3.

Este proceso se repetir√≠a para otros atributos como "Temperatura", "Humedad", etc., y el atributo con el menor error total ser√≠a el elegido.

**Aprendizaje Global vs. Local:**

One Rule (OneR) es un modelo de **aprendizaje fundamentalmente global**, aunque la regla que aprende implica una partici√≥n del espacio de caracter√≠sticas.

* **Aspecto Global:** OneR eval√∫a **todos los atributos en su totalidad** y selecciona el **√∫nico atributo que es globalmente el m√°s predictivo** para la tarea de clasificaci√≥n sobre todo el conjunto de datos. La regla elegida y sus condiciones se aplican uniformemente a cualquier nueva instancia en el espacio de caracter√≠sticas. No se construyen modelos separados o locales para diferentes regiones del espacio de caracter√≠sticas. El algoritmo busca la mejor regla √∫nica que resuma el patr√≥n m√°s fuerte en todos los datos.

* **Partici√≥n del Espacio (Reglas):** Aunque el modelo es global, la "regla" que genera s√≠ que particiona el espacio de caracter√≠sticas. Por ejemplo, si el atributo seleccionado es "Color" y tiene valores "Rojo", "Azul", "Verde", el modelo crea una regla para cada uno de estos valores. Esto crea "regiones" en el espacio de datos (instancias donde Color=Rojo, donde Color=Azul, etc.). Sin embargo, la predicci√≥n dentro de cada una de estas regiones es simplemente la clase mayoritaria observada en esa regi√≥n, y el modelo en su conjunto es una √∫nica estructura de decisi√≥n global basada en ese √∫nico atributo. No es un ajuste din√°mico o ponderado localmente de par√°metros como en otros modelos de aprendizaje local.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n)",
  "‚úÖ Variable respuesta categ√≥rica (clases)",
  "‚úÖ Variables predictoras num√©ricas o categ√≥ricas",
  "‚úÖ Relaci√≥n simple basada en una sola regla (una variable predictora)",
  "‚ùå No aplica (no es modelo estad√≠stico param√©trico)",
  "‚ùå No aplica",
  "‚ùå No aplica",
  "‚ö†Ô∏è Puede ser sensible a outliers si afectan la regla",
  "‚ö†Ô∏è No afecta directamente (usa solo una variable para la regla)",
  "‚úÖ Muy interpretable: una regla sencilla basada en un solo predictor",
  "‚úÖ Muy r√°pido y eficiente, especialmente en datasets peque√±os o medianos",
  "‚úÖ Se puede usar validaci√≥n cruzada para evaluar rendimiento",
  "‚ùå No funciona bien si las relaciones son complejas y requieren m√∫ltiples variables"
)

detalles <- c(
  "Modelo supervisado para clasificaci√≥n basado en la regla m√°s simple y efectiva de un solo predictor.",
  "Predice la clase de salida bas√°ndose en el valor de una √∫nica variable predictora.",
  "Acepta variables categ√≥ricas o num√©ricas (estas se discretizan para generar reglas).",
  "Genera una regla simple: 'Si predictor X tiene valor Y, entonces clase Z'.",
  "No es un modelo param√©trico ni estad√≠stico tradicional, no eval√∫a residuos.",
  "No considera errores ni supuestos de independencia.",
  "No aplica el supuesto de homoscedasticidad.",
  "Outliers pueden influir si cambian la regla seleccionada.",
  "Como usa solo un predictor, la multicolinealidad no es un problema.",
  "F√°cil de entender y explicar, ideal para explicar decisiones simples.",
  "Muy r√°pido de entrenar y evaluar, √∫til para benchmarks o como baseline.",
  "Se recomienda evaluar mediante validaci√≥n cruzada para evitar sobreajuste.",
  "No es √∫til para problemas que requieren modelar interacciones complejas entre variables."
)

tabla_oner <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_oner %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision OneR",
             subtitle = "One Rule (OneR)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Repeated Incremental Pruning to Produce Error Reduction (RIPPER)  {-}  

**RIPPER (Repeated Incremental Pruning to Produce Error Reduction)** es un algoritmo de **clasificaci√≥n supervisada** muy conocido, desarrollado por William W. Cohen. Es una extensi√≥n del algoritmo de reglas `IREP` y es especialmente valorado por su capacidad para generar **conjuntos de reglas de clasificaci√≥n precisos y de alta calidad** que son a menudo m√°s simples e interpretables que los modelos de √°rbol de decisi√≥n complejos, al tiempo que es muy eficiente en t√©rminos computacionales, incluso con grandes conjuntos de datos.

RIPPER construye un conjunto de reglas `IF-THEN` para cada clase de forma secuencial. Opera con un enfoque de **"divide y vencer√°s"**, pero con un fuerte √©nfasis en la **poda (pruning)** para evitar el sobreajuste.

El proceso general de RIPPER para construir reglas para una clase espec√≠fica es el siguiente:

1.  **Generaci√≥n de Reglas (Growing):**
    * Comienza con una regla vac√≠a.
    * A√±ade t√©rminos (condiciones) a la regla que maximicen alguna m√©trica de calidad (por ejemplo, el ratio de ganancia de informaci√≥n) hasta que la regla cubre un cierto n√∫mero de ejemplos positivos (ejemplos de la clase actual) y pocos ejemplos negativos.
2.  **Poda de Reglas (Pruning):**
    * Una vez que una regla ha sido generada, se somete a un proceso de poda incremental. Se eliminan t√©rminos de la regla que no mejoran significativamente el error de la regla en un conjunto de validaci√≥n separado (el "conjunto de poda"). Esto ayuda a generalizar la regla y evitar el sobreajuste.
3.  **Adici√≥n de Reglas:**
    * Despu√©s de podar una regla, se a√±ade al conjunto de reglas para la clase actual.
    * Los ejemplos cubiertos por esta nueva regla se eliminan del conjunto de entrenamiento.
    * Se repiten los pasos 1-3 para construir nuevas reglas para la misma clase hasta que no queden suficientes ejemplos de la clase o no se puedan generar m√°s reglas que cumplan ciertos criterios.
4.  **Optimizaci√≥n Global y Re-poda:**
    * Una vez que se ha generado un conjunto inicial de reglas para una clase, RIPPER realiza varias pasadas de optimizaci√≥n.
    * En cada pasada, se intenta reemplazar o modificar reglas para reducir a√∫n m√°s el error total del conjunto de reglas. Esto incluye estrategias como la sustituci√≥n de reglas (reemplazar una regla existente por una mejor), la reversi√≥n de reglas (eliminar una regla), y la combinaci√≥n de reglas.
    * Se utiliza una m√©trica como la **descripci√≥n m√≠nima de la longitud (MDL - Minimum Description Length)** para penalizar la complejidad del modelo.

El proceso se repite para todas las clases, y las reglas se organizan en un orden de prioridad.


**Aprendizaje Global vs. Local:**

RIPPER es un algoritmo que combina de manera muy efectiva aspectos de **aprendizaje global y local**, pero con un fuerte √©nfasis en la generaci√≥n de **reglas locales** que se combinan en un modelo global.

* **Aspecto Local (Generaci√≥n de Reglas Individuales):** Cada regla que RIPPER aprende es esencialmente un **modelo local** que cubre una regi√≥n espec√≠fica del espacio de caracter√≠sticas. Las condiciones de la regla (`IF A AND B THEN Class X`) definen un hiperrect√°ngulo (o una regi√≥n m√°s compleja) en el espacio de caracter√≠sticas. La regla se aprende para predecir correctamente los puntos dentro de esa regi√≥n. La poda de reglas, en particular, se enfoca en optimizar el rendimiento de la regla en su "vecindario" de datos cubiertos, evitando el sobreajuste a puntos de entrenamiento individuales. Las reglas se ajustan a patrones y relaciones **locales** dentro de los datos.

* **Aspecto Global (Conjunto de Reglas y Priorizaci√≥n):** Aunque las reglas individuales son locales, el **conjunto final de reglas** para todas las clases, y su orden de prioridad, forman un **modelo de clasificaci√≥n global** que cubre todo el espacio de caracter√≠sticas. Cuando una nueva instancia necesita ser clasificada, se eval√∫a contra todas las reglas en orden hasta que una se activa, y esa regla dicta la predicci√≥n. La optimizaci√≥n global del conjunto de reglas, mediante la repoda y las fases de reemplazo de reglas, asegura que el modelo final sea coherente y preciso a nivel de todo el conjunto de datos.    


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n)",
  "‚úÖ Variable respuesta categ√≥rica",
  "‚úÖ Variables predictoras num√©ricas o categ√≥ricas",
  "‚úÖ Relaci√≥n no lineal basada en reglas de decisi√≥n",
  "‚ùå No aplica (no es modelo param√©trico)",
  "‚ùå No aplica",
  "‚ùå No aplica",
  "‚ö†Ô∏è Moderadamente sensible a outliers, depende de la calidad de datos",
  "‚ö†Ô∏è No afecta directamente, pero multicolinealidad puede confundir reglas",
  "‚ö†Ô∏è Interpretaci√≥n mediante reglas, m√°s complejas que OneR pero a√∫n legibles",
  "‚ö†Ô∏è Moderada, puede ser lento en datasets muy grandes",
  "‚úÖ Se puede validar con m√©todos de validaci√≥n cruzada",
  "‚ùå No funciona bien si las reglas no separan claramente las clases o en datos muy ruidosos"
)

detalles <- c(
  "Algoritmo supervisado para clasificaci√≥n que genera reglas de decisi√≥n con poda incremental para reducir error.",
  "Predice clases usando conjuntos de reglas de decisi√≥n extra√≠das y podadas iterativamente.",
  "Soporta variables num√©ricas y categ√≥ricas, con discretizaci√≥n interna si es necesario.",
  "Captura relaciones no lineales y complejas mediante reglas combinadas.",
  "No utiliza modelos estad√≠sticos cl√°sicos, por lo que no aplica an√°lisis de residuos.",
  "No asume independencia entre observaciones.",
  "No requiere homoscedasticidad ni otros supuestos de regresi√≥n.",
  "Outliers pueden afectar la calidad y la complejidad de las reglas generadas.",
  "Multicolinealidad no afecta directamente, pero puede inducir reglas redundantes.",
  "Las reglas generadas son m√°s interpretables que √°rboles complejos, pero menos simples que OneR.",
  "El proceso iterativo y poda pueden ser computacionalmente costosos en grandes datasets.",
  "Validaci√≥n cruzada es recomendada para evaluar generalizaci√≥n y evitar sobreajuste.",
  "No es adecuado para datos con ruido elevado o donde no existen reglas claras para separar clases."
)

tabla_ripper <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)


tabla_ripper %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision RIPPER",
             subtitle = "Repeated Incremental Pruning to Produce Error Reduction (RIPPER)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Rule Fit  {-}    

**RuleFit** es un potente y, al mismo tiempo, **interpretable algoritmo de aprendizaje autom√°tico** desarrollado por Jerome H. Friedman y Bogdan Popescu. Est√° dise√±ado para combinar la **precisi√≥n de los m√©todos de ensamblaje (como el *gradient boosting* o los *random forests*)** con la **interpretabilidad de los modelos lineales y las reglas de decisi√≥n**. RuleFit es particularmente √∫til cuando necesita un modelo que funcione bien *y* que le permita comprender el "porqu√©" detr√°s de sus predicciones.

La idea central de RuleFit es aprender un **modelo lineal disperso** que utiliza tanto las **caracter√≠sticas de entrada originales** como un conjunto de **"caracter√≠sticas de regla" reci√©n generadas** como predictores. Estas caracter√≠sticas de regla se derivan de un ensamblaje de √°rboles de decisi√≥n.

As√≠ es como funciona RuleFit:

1.  **Generaci√≥n del Ensamblaje de √Årboles:**
    * Primero, RuleFit entrena un **ensamblaje de √°rboles de decisi√≥n poco profundos** en el conjunto de datos. Esto se puede hacer utilizando algoritmos como *Gradient Boosting Machines* (GBM) o *Random Forests*. Los √°rboles suelen mantenerse poco profundos (por ejemplo, una profundidad m√°xima de 3-5) para producir reglas m√°s simples e interpretables.
    * Estos √°rboles se entrenan para predecir la variable objetivo, lo que significa que sus divisiones son significativas para la tarea.

2.  **Extracci√≥n de Reglas:**
    * Cada **ruta desde la ra√≠z hasta un nodo hoja** en cualquiera de los √°rboles de decisi√≥n generados se extrae y se convierte en una **regla de decisi√≥n binaria**.
    * Por ejemplo, si una ruta en un √°rbol es "si (Caracter√≠stica1 > 10) Y (Caracter√≠stica2 < 5)", esto se convierte en una regla.
    * Cada regla se trata entonces como una **nueva caracter√≠stica binaria** para cada instancia de datos: toma un valor de 1 si la instancia satisface todas las condiciones de la regla, y 0 en caso contrario.

3.  **Ajuste del Modelo Lineal con Regularizaci√≥n:**
    * Las caracter√≠sticas originales del conjunto de datos se combinan con estas caracter√≠sticas de regla binarias reci√©n creadas.
    * Luego, se ajusta un **modelo lineal disperso** (normalmente una **regresi√≥n Lasso**, que utiliza regularizaci√≥n L1) a este conjunto de caracter√≠sticas expandido.
    * La regularizaci√≥n Lasso realiza autom√°ticamente la **selecci√≥n de caracter√≠sticas**, estableciendo los coeficientes de las caracter√≠sticas originales y de las caracter√≠sticas de regla menos importantes en cero. Esto da como resultado un modelo final m√°s simple e interpretable que solo incluye los t√©rminos m√°s relevantes.

El modelo RuleFit final es una ecuaci√≥n lineal:
$\text{predicci√≥n} = \beta_0 + \sum_{j=1}^{p} \beta_j X_j + \sum_{k=1}^{R} \alpha_k r_k(X)$

Donde:
* $\beta_0$ es el intercepto.
* $\beta_j X_j$ son los t√©rminos para las caracter√≠sticas lineales originales $X_j$.
* $\alpha_k r_k(X)$ son los t√©rminos para las caracter√≠sticas de regla binarias $r_k(X)$.

Los coeficientes ($\beta_j$ y $\alpha_k$) indican la importancia y la direcci√≥n del efecto de cada caracter√≠stica original y de cada regla en la predicci√≥n.

**Aprendizaje Global vs. Local:**

RuleFit es un excelente ejemplo de un algoritmo que combina perfectamente las caracter√≠sticas de **aprendizaje global y local**.

* **Aspecto Global (Modelo Lineal Final y Estructura General):**
    * La etapa final de RuleFit consiste en ajustar un **√∫nico modelo lineal global** (con regularizaci√≥n Lasso). Este modelo lineal es un predictor global que combina las caracter√≠sticas originales y todas las caracter√≠sticas de regla generadas. Los coeficientes en este modelo lineal global definen la relaci√≥n general entre las caracter√≠sticas de entrada (originales y basadas en reglas) y la variable objetivo en todo el conjunto de datos.
    * Este modelo lineal proporciona una **comprensi√≥n global** de la importancia de las caracter√≠sticas y de c√≥mo contribuyen colectivamente a la predicci√≥n.

* **Aspecto Local (Caracter√≠sticas de Regla y Efectos de Interacci√≥n):**
    * El poder de RuleFit para manejar relaciones no lineales e interacciones proviene de su **aspecto local**: las **reglas de decisi√≥n**. Cada regla, extra√≠da de una ruta en un √°rbol de decisi√≥n, define una **subregi√≥n espec√≠fica** o "vecindario" del espacio de caracter√≠sticas. Por ejemplo, una regla "SI la edad es > 30 Y el ingreso es < 50k" captura una condici√≥n local muy espec√≠fica.
    * Al incluir estas caracter√≠sticas de regla binarias, el modelo lineal puede aprender efectivamente **diferentes relaciones lineales dentro de diferentes regiones locales** definidas por las reglas. Estas reglas capturan expl√≠citamente los **efectos de interacci√≥n** entre caracter√≠sticas que un modelo lineal est√°ndar pasar√≠a por alto.
    * Esto es similar a tener un **modelo local (impl√≠citamente, una constante o un modelo lineal simple dentro de la regi√≥n de la regla)** que se activa cuando se cumplen sus condiciones, lo que permite que el modelo lineal global adapte sus predicciones bas√°ndose en estos patrones locales.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n y regresi√≥n)",
  "‚úÖ Num√©rica o categ√≥rica seg√∫n el tipo de problema",
  "‚úÖ Variables num√©ricas y categ√≥ricas",
  "‚úÖ Modela relaciones no lineales a trav√©s de reglas y combinaciones lineales",
  "‚ùå No es modelo param√©trico cl√°sico, no se eval√∫a normalidad",
  "‚ùå No aplica directamente",
  "‚ùå No aplica",
  "‚ö†Ô∏è Puede ser sensible a outliers, pero menos que modelos lineales puros",
  "‚ö†Ô∏è Puede verse afectado, se recomienda an√°lisis previo",
  "‚ö†Ô∏è Interpretabilidad moderada: combina reglas f√°ciles con coeficientes lineales",
  "‚ö†Ô∏è Moderado, depende del n√∫mero de reglas generadas",
  "‚úÖ Se puede validar con validaci√≥n cruzada",
  "‚ùå No funciona bien en datasets muy peque√±os o con relaciones altamente complejas sin reglas claras"
)

detalles <- c(
  "Combina √°rboles de decisi√≥n para generar reglas y luego aplica regresi√≥n lineal para asignar pesos a estas reglas.",
  "Puede usarse para problemas de regresi√≥n o clasificaci√≥n.",
  "Admite variables categ√≥ricas y num√©ricas sin grandes restricciones.",
  "Captura tanto efectos lineales como interacciones no lineales v√≠a reglas extra√≠das.",
  "No asume distribuci√≥n normal de errores.",
  "No requiere independencia estricta entre observaciones.",
  "No requiere homoscedasticidad.",
  "Puede mitigar el impacto de outliers mediante regularizaci√≥n.",
  "Multicolinealidad puede afectar coeficientes pero el modelo regulariza para evitarlo.",
  "Las reglas extra√≠das facilitan la interpretaci√≥n frente a otros modelos complejos.",
  "La eficiencia depende del n√∫mero de reglas y tama√±o de datos.",
  "Validaci√≥n cruzada ayuda a evitar sobreajuste y seleccionar hiperpar√°metros.",
  "Puede fallar si las reglas generadas no capturan bien la relaci√≥n o en datos ruidosos."
)

tabla_rulefit <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_rulefit %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision rule fit",
             subtitle = "Rule Fit")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Zero Rule (ZeroR)  {-}    


**Zero Rule (ZeroR)** es el algoritmo de **clasificaci√≥n supervisada** m√°s simple imaginable. No utiliza ninguna de las caracter√≠sticas predictoras en el conjunto de datos para hacer sus predicciones. En su lugar, simplemente **predice la clase m√°s frecuente (mayoritaria)** que se observa en el conjunto de datos de entrenamiento.

**C√≥mo funciona ZeroR:**   

1.  **Conteo de Frecuencias:** El algoritmo cuenta las ocurrencias de cada clase en el conjunto de datos de entrenamiento.
2.  **Identificaci√≥n de la Clase Mayoritaria:** Identifica la clase que tiene la mayor frecuencia (es decir, la clase que aparece m√°s veces).
3.  **Predicci√≥n Universal:** Para cualquier nueva instancia, ZeroR simplemente predice esta clase mayoritaria.

**Ejemplo:** Si en un conjunto de datos para predecir si un cliente "comprar√°" o "no comprar√°" un producto, el 70% de los clientes en el conjunto de entrenamiento "no compraron" y el 30% "compraron", ZeroR predecir√° "no comprar√°" para *todos* los nuevos clientes. Su precisi√≥n en el conjunto de entrenamiento ser√≠a del 70%.

**¬øPor qu√© es importante ZeroR?**  

Aunque ZeroR no tiene ning√∫n poder predictivo real en el sentido de aprender patrones complejos de los datos, es **fundamentalmente importante en Machine Learning como una l√≠nea base (benchmark)**.

* **Punto de Referencia:** Cualquier algoritmo de clasificaci√≥n m√°s sofisticado debe superar la precisi√≥n de ZeroR para ser considerado √∫til. Si un modelo complejo tiene una precisi√≥n inferior a la de ZeroR, significa que el modelo no est√° aprendiendo nada significativo de los datos, o incluso est√° aprendiendo patrones incorrectos.
* **Detecci√≥n de Sesgos de Clase:** En conjuntos de datos desequilibrados (donde una clase es mucho m√°s frecuente que otras), ZeroR puede lograr una precisi√≥n aparentemente alta. Esto resalta la importancia de usar m√©tricas de evaluaci√≥n m√°s all√° de la simple precisi√≥n en esos casos (como precisi√≥n, recall, F1-score, o AUC-ROC), ya que una alta precisi√≥n de ZeroR podr√≠a ser enga√±osa.
* **Simplicidad Extrema:** Sirve como el punto de partida m√°s b√°sico para entender c√≥mo los algoritmos de clasificaci√≥n intentan mejorar sobre una suposici√≥n trivial.

**Aprendizaje Global vs. Local:**

ZeroR es un modelo de **aprendizaje puramente global**.

* **Aspecto Global:** ZeroR calcula una √∫nica estad√≠stica (la clase mayoritaria) a partir de todo el conjunto de datos de entrenamiento y aplica esta predicci√≥n **uniformemente a todas las instancias**, sin importar sus caracter√≠sticas individuales o su ubicaci√≥n en el espacio de datos. No hay ninguna adaptaci√≥n local o consideraci√≥n de subregiones del espacio de caracter√≠sticas. El modelo es una √∫nica regla global e inmutable.

* **Sin Modelado de Relaciones:** Al ignorar todas las caracter√≠sticas de entrada, ZeroR no modela ninguna relaci√≥n, lineal o no lineal, entre los predictores y la variable objetivo. Su conocimiento se limita a la distribuci√≥n marginal de la clase de salida.

En resumen, ZeroR es el clasificador m√°s simple y sirve como un punto de referencia crucial para evaluar el rendimiento de modelos de Machine Learning m√°s avanzados. Su naturaleza es inherentemente global, ya que aplica una √∫nica decisi√≥n derivada del patr√≥n m√°s frecuente en todo el conjunto de datos.

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n y regresi√≥n)",
  "‚úÖ Categ√≥rica (modo) o num√©rica (media)",
  "‚ùå No utiliza predictores",
  "‚ùå No considera relaciones, predice constante",
  "‚ùå No aplica (no hay residuos de regresi√≥n)",
  "‚ùå No aplica (no hay modelo estructurado)",
  "‚ùå No aplica",
  "‚ùå No aplica (no hay influencia de valores at√≠picos)",
  "‚ùå No aplica (no hay predictores)",
  "‚úÖ Alta, ya que solo predice un valor fijo",
  "‚úÖ Extremadamente r√°pido",
  "‚ö†Ô∏è Se puede usar como baseline en validaci√≥n",
  "‚ùå No debe usarse como modelo final salvo como referencia base"
)

detalles <- c(
  "Modelo supervisado trivial que predice el valor m√°s frecuente (clasificaci√≥n) o promedio (regresi√≥n) de la variable respuesta.",
  "Funciona para variable respuesta categ√≥rica (modo) o continua (media).",
  "No utiliza ninguna variable predictora; solo la respuesta.",
  "No aprende relaciones, √∫til solo como l√≠nea base de comparaci√≥n.",
  "No genera residuos, pues predice una constante.",
  "No hay estructura de error o modelo que se eval√∫e.",
  "No hay dispersi√≥n de errores porque no hay ajuste.",
  "Outliers no afectan porque el modelo predice una constante global.",
  "No existe relaci√≥n entre predictores, as√≠ que no aplica multicolinealidad.",
  "F√°cil de interpretar: siempre predice lo mismo.",
  "Modelo extremadamente simple y r√°pido de calcular.",
  "Sirve como l√≠nea base para comparar modelos m√°s complejos.",
  "In√∫til para hacer predicciones significativas; solo sirve como referencia comparativa."
)

tabla_zeror <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)  

tabla_zeror %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision ZeroR",
             subtitle = "Zero Rule (ZeroR)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```









<!--chapter:end:10-rule_based_systems.Rmd-->

```{r include=FALSE, cache=FALSE}
# example R options set globally
options(width = 80)

# example chunk options set globally
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  message = FALSE,
  warning = FALSE
)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
setwd(here::here())
```
`r if (knitr::is_html_output()) '
# References {-}
'`

Sagi, S. (2019). ML Algorithms: One SD (œÉ). The obvious questions to ask when‚Ä¶ | by Sagi Shaier | Medium. https://medium.com/@Shaier/ml-algorithms-one-sd-%CF%83-74bcb28fafb6 

Kuhn, M. (2019). The caret Package. https://topepo.github.io/caret/index.html

<!--chapter:end:11-references.Rmd-->

