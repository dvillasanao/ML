--- 
title: "Machine Learning (Apuntes) "
author: "Diana Villasana Ocampo"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This is a minimal example of using the bookdown package to write a book.
  The HTML output format for this example is bookdown::bs4_book,
  set in the _output.yml file.
biblio-style: apalike
csl: chicago-fullnote-bibliography.csl
---
Claro, aquí tienes un resumen claro y práctico de los principales **algoritmos de machine learning**, incluyendo **cuándo usar cada tipo** según el problema que enfrentas:

---


# Machine Learning {-}

## 🔍 **1. Regressión** {-}

**Ejemplos:** Linear Regression, Ridge, Lasso   
**Cuándo usarlo:**

* Predicción de valores numéricos continuos (e.g. precios, temperaturas).  
* Relaciones lineales entre variables. 

**Ventajas:** Simple, interpretable.   
**Limitaciones:** Mal desempeño con relaciones no lineales complejas.

---

## 🌲 **2. Árboles de Decisión y Derivados** {-}  

**Ejemplos:** Decision Tree, Random Forest, Gradient Boosting  
**Cuándo usarlo:**  

* Problemas tabulares con relaciones no lineales y variables categóricas o numéricas.
* Cuando interpretabilidad es importante.

**Ventajas:** Manejan datos heterogéneos, fáciles de interpretar (árboles simples).   
**Limitaciones:** Sobreajuste en árboles simples; menor desempeño en datos muy ruidosos sin ensambles.

---

## 🌟 **3. Ensambles (Ensemble Methods)** {-}

**Ejemplos:** Random Forest, AdaBoost, XGBoost, LightGBM   
**Cuándo usarlo:**   

* Cuando buscas alto rendimiento en clasificación o regresión tabular.
* Competencias de datos (como Kaggle).

**Ventajas:** Alta precisión, robustez.   
**Limitaciones:** Difícil de interpretar; más costosos computacionalmente.

---

## 🧠 **4. Redes Neuronales y Deep Learning** {-}  

**Ejemplos:** MLP, CNN, RNN, Transformers   
**Cuándo usarlo:**   

* Imágenes (CNN), texto y lenguaje natural (Transformers), series temporales (RNN/LSTM).
* Grandes volúmenes de datos no estructurados.

**Ventajas:** Muy poderosos para datos complejos y no estructurados.   
**Limitaciones:** Requieren mucha data y poder computacional. Menor interpretabilidad.

---

## 🧩 **5. Reducción de Dimensionalidad** {-}   

**Ejemplos:** PCA, t-SNE, UMAP   
**Cuándo usarlo:**   

* Visualización de datos de alta dimensión.
* Preprocesamiento para eliminar ruido o multicolinealidad.

**Ventajas:** Mejora desempeño y velocidad de otros modelos.    
**Limitaciones:** Puede perder interpretabilidad; no siempre mejora modelos.

---

## 🧬 **6. Bayesianos** {-}  

**Ejemplos:** Naive Bayes, Bayesian Networks  
**Cuándo usarlo:**   

* Clasificación rápida con supuestos simples.
* Problemas de texto o spam detection.

**Ventajas:** Muy rápidos, bien fundamentados.   
**Limitaciones:** Supone independencia de variables (no siempre cierto).

---

## 🧮 **7. Regularización** {-}  

**Ejemplos:** L1 (Lasso), L2 (Ridge), Elastic Net   
**Cuándo usarlo:**   

* Para evitar sobreajuste en modelos lineales o redes neuronales.
* Cuando tienes muchas variables (alta dimensionalidad).

**Ventajas:** Penaliza modelos complejos.   
**Limitaciones:** Puede eliminar variables útiles si se usa en exceso.

---

## 🔍 **8. Instance-Based (Basados en Instancias)** {-}  

**Ejemplos:** K-Nearest Neighbors (KNN)   
**Cuándo usarlo:**   

* Pocos datos, con patrones locales claros.  
* Cuando la similitud entre casos es importante.

**Ventajas:** Simple y eficaz en problemas de baja dimensión.   
**Limitaciones:** Escala mal con muchos datos; sensible al ruido.

---

## 📏 **9. Clustering (No Supervisado)** {-}  

**Ejemplos:** K-Means, DBSCAN, Hierarchical Clustering  
**Cuándo usarlo:**   

* Agrupar datos sin etiquetas previas.
* Descubrir estructuras ocultas o segmentos de mercado.

**Ventajas:** Útil en exploración y reducción de complejidad.   
**Limitaciones:** Requiere elegir número de grupos (excepto DBSCAN); puede ser sensible a escala.

---

## 📐 **10. Sistemas Basados en Reglas (Rule-Based Systems)** {-}

**Ejemplos:** RuleFit, Decision Rules, lógica difusa
**Cuándo usarlo:**

* Interpretabilidad es clave (por ejemplo, decisiones legales o médicas).
* Incorporar conocimiento experto.

**Ventajas:** Fácil de entender y auditar.   
**Limitaciones:** No tan precisos como otros métodos en datos complejos.

---

## 📌 Cuadro

```{r, echo = FALSE}
algoritmos_ml <- data.frame(
                            Tipo = c(
                              "Regressión",
                              "Árboles / Decision Tree",
                              "Ensambles",
                              "Deep Learning",
                              "Reducción de Dim.",
                              "Bayesianos",
                              "Regularización",
                              "Instance-Based",
                              "Clustering",
                              "Rule-Based"
                            ),
                            Problema_tipico = c(
                              "Valores numéricos",
                              "Clasificación, regresión",
                              "Clasificación, regresión",
                              "Imágenes, texto, audio",
                              "Visualización, preprocesamiento",
                              "Clasificación rápida",
                              "Evitar overfitting",
                              "Clasificación",
                              "Agrupamiento no supervisado",
                              "Interpretabilidad"
                            ),
                            Ventajas = c(
                              "Simplicidad",
                              "Interpretabilidad",
                              "Precisión",
                              "Modelos complejos",
                              "Mejora eficiencia",
                              "Velocidad",
                              "Generalización",
                              "Simple, no requiere entrenamiento",
                              "Descubrir estructuras ocultas",
                              "Lógica clara"
                            ),
                            Cuando_usarlo = c(
                              "Relaciones lineales",
                              "Datos tabulares",
                              "Alto rendimiento, Kaggle",
                              "Datos grandes y no estructurados",
                              "Datos con muchas variables",
                              "Texto, spam detection",
                              "Modelos lineales con muchas variables",
                              "Pocos datos y relaciones claras",
                              "Segmentación sin etiquetas",
                              "Reglas conocidas, decisiones explicables"
                            ),
                            stringsAsFactors = FALSE
                          )

require(gt)

algoritmos_ml %>% 
 gt() %>%
  tab_header(title = "Modelos y cuando usarlos") %>%
   tab_footnote(footnote = "Fuente: Elaboración propia") %>%
     fmt_integer(columns = names(data)[4:22], 
                sep_mark = " ") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Cuando_") ~ px(300),
                   everything() ~ px(200)) %>%
         as_raw_html() 

```



```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```
