<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title> 1. Regressi贸n | Machine Learning (Apuntes)</title>
<meta name="author" content="Diana Villasana Ocampo">
<meta name="description" content="Ejemplos: Linear Regression, Ridge, LassoCu谩ndo usarlo: Predicci贸n de valores num茅ricos continuos (e.g.precios, temperaturas). Relaciones lineales entre variables. Ventajas: Simple,...">
<meta name="generator" content="bookdown 0.42 with bs4_book()">
<meta property="og:title" content=" 1. Regressi贸n | Machine Learning (Apuntes)">
<meta property="og:type" content="book">
<meta property="og:description" content="Ejemplos: Linear Regression, Ridge, LassoCu谩ndo usarlo: Predicci贸n de valores num茅ricos continuos (e.g.precios, temperaturas). Relaciones lineales entre variables. Ventajas: Simple,...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content=" 1. Regressi贸n | Machine Learning (Apuntes)">
<meta name="twitter:description" content="Ejemplos: Linear Regression, Ridge, LassoCu谩ndo usarlo: Predicci贸n de valores num茅ricos continuos (e.g.precios, temperaturas). Relaciones lineales entre variables. Ventajas: Simple,...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.7.0/transition.js"></script><script src="libs/bs3compat-0.7.0/tabs.js"></script><script src="libs/bs3compat-0.7.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Machine Learning (Apuntes)</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Machine Learning</a></li>
<li><a class="active" href="regressi%C3%B3n.html"> 1. Regressi贸n</a></li>
<li><a class="" href="references.html">References</a></li>
<li><a class="" href="references-1.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://dvillasanao.github.io/IME_2010_2020/">View book source <i class="fab fa-gitlab"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="regressi贸n" class="section level1 unnumbered">
<h1> <strong>1. Regressi贸n</strong><a class="anchor" aria-label="anchor" href="#regressi%C3%B3n"><i class="fas fa-link"></i></a>
</h1>
<p><strong>Ejemplos:</strong> Linear Regression, Ridge, Lasso<br><strong>Cu谩ndo usarlo:</strong></p>
<ul>
<li>Predicci贸n de valores num茅ricos continuos (e.g.precios, temperaturas).<br>
</li>
<li>Relaciones lineales entre variables.</li>
</ul>
<p><strong>Ventajas:</strong> Simple, interpretable.<br><strong>Limitaciones:</strong> Mal desempe帽o con relaciones no lineales complejas.</p>
<div id="ordinary-least-squares-regression-olsr" class="section level2 unnumbered">
<h2>Ordinary Least Squares Regression (<code>OLSR</code>)<a class="anchor" aria-label="anchor" href="#ordinary-least-squares-regression-olsr"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Regresi贸n de M铆nimos Cuadrados Ordinarios (OLSR)</strong>: un m茅todo de regresi贸n lineal para estimar los par谩metros desconocidos mediante la creaci贸n de un modelo que minimizar谩 la suma de los errores cuadrados entre los datos observados y los predichos (valores observados y valores estimados).</p>
</div>
<div id="linear-regression" class="section level2 unnumbered">
<h2>Linear Regression<a class="anchor" aria-label="anchor" href="#linear-regression"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Regresi贸n lineal</strong> : se utiliza para estimar valores reales (costo de las casas, n煤mero de visitas, ventas totales, etc.) basados en variables continuas.</p>
</div>
<div id="logistic-regression" class="section level2 unnumbered">
<h2>Logistic Regression<a class="anchor" aria-label="anchor" href="#logistic-regression"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Regresi贸n log铆stica</strong> : se utiliza para estimar valores discretos (valores binarios como 0/1, s铆/no, verdadero/falso) basados en un conjunto dado de variables independientes.</p>
</div>
<div id="stepwise-regression" class="section level2 unnumbered">
<h2>Stepwise Regression<a class="anchor" aria-label="anchor" href="#stepwise-regression"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Regresi贸n por pasos</strong> : a帽ade caracter铆sticas al modelo una a una hasta encontrar la puntuaci贸n 贸ptima para tu conjunto de caracter铆sticas. La selecci贸n por pasos alterna entre el avance y el retroceso, incorporando y eliminando variables que cumplen los criterios de entrada o eliminaci贸n, hasta alcanzar un conjunto estable de variables.</p>
</div>
<div id="multivariate-adaptive-regression-splines-mars" class="section level2 unnumbered">
<h2>Multivariate Adaptive Regression Splines (<code>MARS</code>)<a class="anchor" aria-label="anchor" href="#multivariate-adaptive-regression-splines-mars"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Splines de Regresi贸n Adaptativa Multivariante (<code>MARS</code>)</strong>: un m茅todo de regresi贸n flexible que busca interacciones y relaciones no lineales que ayudan a maximizar la precisi贸n predictiva. Este algoritmo es inherentemente no lineal (lo que significa que no es necesario adaptar el modelo a patrones no lineales en el datos agregando manualmente t茅rminos del modelo (squared terms, interaction effects).</p>
</div>
<div id="locally-estimated-scatterplot-smoothing-loess" class="section level2 unnumbered">
<h2>Locally Estimated Scatterplot Smoothing (<code>LOESS</code>)<a class="anchor" aria-label="anchor" href="#locally-estimated-scatterplot-smoothing-loess"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Locally Estimated Scatterplot Smoothing (<code>LOESS</code>)</strong>: un m茅todo para ajustar una curva suave entre dos variables o una superficie entre un resultado y hasta cuatro variables predictoras. La idea es que, si los datos no se distribuyen linealmente, se puede aplicar el concepto de regresi贸n. Se puede aplicar regresi贸n, lo que se denomina regresi贸n ponderada localmente. Se puede aplicar LOESS cuando la relaci贸n entre las variables independientes y dependientes no es lineal. Hoy en d铆a, la mayor铆a de los algoritmos (como las redes neuronales de propagaci贸n hacia adelante cl谩sicas, las m谩quinas de vectores de soporte, los algoritmos del vecino m谩s cercano, etc.) son sistemas de aprendizaje global que se utilizan para minimizar las funciones de p茅rdida globales (por ejemplo, el error cuadr谩tico medio). Por el contrario, los sistemas de aprendizaje local dividen el problema de aprendizaje global en m煤ltiples problemas de aprendizaje m谩s peque帽os y simples. Esto generalmente se logra dividiendo la funci贸n de costo en m煤ltiples funciones de costo locales independientes. Una de las desventajas de los m茅todos globales es que, a veces, ning煤n valor de par谩metro puede proporcionar una aproximaci贸n suficientemente buena. Pero entonces surge LOESS, una alternativa a la aproximaci贸n de funciones globales.</p>
</div>
<div id="regression-ridge" class="section level2 unnumbered">
<h2>Regression Ridge<a class="anchor" aria-label="anchor" href="#regression-ridge"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Regresi贸n Ridge</strong> es una extensi贸n de la regresi贸n lineal cl谩sica (<code>OLS</code>) que se usa cuando hay problemas de multicolinealidad o riesgo de sobreajuste. Aborda estos problemas introduciendo un t茅rmino de penalizaci贸n a la funci贸n de coste de la regresi贸n lineal ordinaria (m铆nimos cuadrados ordinarios, OLS).</p>
</div>
<div id="least-absolute-shrinkage-and-selection-operator-lasso" class="section level2 unnumbered">
<h2>Least Absolute Shrinkage and Selection Operator (<code>LASSO</code>)<a class="anchor" aria-label="anchor" href="#least-absolute-shrinkage-and-selection-operator-lasso"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Least Absolute Shrinkage and Selection Operator (<code>LASSO</code>)</strong>: es otra t茅cnica de regularizaci贸n utilizada en modelos de regresi贸n lineal, similar a la Regresi贸n Ridge, pero con una diferencia clave en el tipo de penalizaci贸n que aplica en la funci贸n de coste de la regresi贸n lineal ordinaria.</p>
<hr>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="index.html">Machine Learning</a></div>
<div class="next"><a href="references.html">References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#regressi%C3%B3n"> 1. Regressi贸n</a></li>
<li><a class="nav-link" href="#ordinary-least-squares-regression-olsr">Ordinary Least Squares Regression (OLSR)</a></li>
<li><a class="nav-link" href="#linear-regression">Linear Regression</a></li>
<li><a class="nav-link" href="#logistic-regression">Logistic Regression</a></li>
<li><a class="nav-link" href="#stepwise-regression">Stepwise Regression</a></li>
<li><a class="nav-link" href="#multivariate-adaptive-regression-splines-mars">Multivariate Adaptive Regression Splines (MARS)</a></li>
<li><a class="nav-link" href="#locally-estimated-scatterplot-smoothing-loess">Locally Estimated Scatterplot Smoothing (LOESS)</a></li>
<li><a class="nav-link" href="#regression-ridge">Regression Ridge</a></li>
<li><a class="nav-link" href="#least-absolute-shrinkage-and-selection-operator-lasso">Least Absolute Shrinkage and Selection Operator (LASSO)</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://dvillasanao.github.io/IME_2010_2020//blob/master/01-regression.Rmd">View source <i class="fab fa-gitlab"></i></a></li>
          <li><a id="book-edit" href="https://dvillasanao.github.io/IME_2010_2020//edit/master/01-regression.Rmd">Edit this page <i class="fab fa-gitlab"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Machine Learning (Apuntes)</strong>" was written by Diana Villasana Ocampo. It was last built on 2025-06-02.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
