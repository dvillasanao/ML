# üìê 10. Sistemas Basados en Reglas {-}  

**Ejemplos:** RuleFit, √Årboles de Decisi√≥n con reglas, l√≥gica difusa.  
**Uso:** Estos sistemas son ideales cuando la **interpretabilidad es absolutamente crucial**, como en decisiones legales o m√©dicas donde entender el "porqu√©" es tan importante como el "qu√©". Tambi√©n son perfectos para **incorporar conocimiento experto** humano directamente en el modelo.  
**Ventajas:** Son notablemente **f√°ciles de entender y auditar**, lo que los hace transparentes y confiables en entornos regulados.  
**Limitaciones:** Su principal desventaja es que no suelen ser tan **precisos** como otros m√©todos m√°s complejos cuando se enfrentan a datos muy intrincados o patrones no lineales.  

---


## Associative Classification (e.g., CBA, CMAR, FP-Growth based methods) {-}   

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/Associative Classification.png"))
```

```{r, echo = FALSE}
library(gt)

criterios_associative_classification <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica_associative_classification <- c(
  "‚úÖ Supervisado (Reglas de Clasificaci√≥n)",
  "‚úÖ Categ√≥rica",
  "‚úÖ Categ√≥ricas (principalmente)",
  "‚úÖ Compleja (a trav√©s de reglas 'SI-ENTONCES')",
  "‚ùå No es requisito",
  "‚ùå No aplica directamente",
  "‚ùå No es requisito",
  "‚ö†Ô∏è S√≠ (puede generar reglas inusuales)",
  "‚úÖ Maneja bien (identifica patrones de coexistencia)",
  "‚úÖ Muy alta (reglas claras)",
  "‚ö†Ô∏è Baja a Moderada (generaci√≥n de reglas, filtrado)",
  "‚úÖ Compatible y recomendada",
  "‚ùå Datos num√©ricos predominantes o relaciones no asociativas"
)

detalles_associative_classification <- c(
  "Paradigma de clasificaci√≥n supervisado que utiliza **reglas de asociaci√≥n** para construir un clasificador. Primero, genera un conjunto de reglas de asociaci√≥n (ej., usando Apriori) donde el consecuente es la clase objetivo, y luego selecciona y combina estas reglas para formar un modelo de clasificaci√≥n.",
  "La variable dependiente debe ser **categ√≥rica**. El objetivo es predecir la clase o categor√≠a a la que pertenece una instancia de datos.",
  "Las variables predictoras son predominantemente **categ√≥ricas** o discretas. Los datos num√©ricos deben ser discretizados para poder generar reglas de asociaci√≥n.",
  "Establece relaciones complejas y no lineales en forma de reglas 'SI-ENTONCES'. Busca patrones de coexistencia entre los atributos y la clase, identificando las combinaciones de atributos que predicen con mayor confianza una clase espec√≠fica.",
  "No hace suposiciones sobre la normalidad de los residuos ni la distribuci√≥n de los datos, ya que no es un modelo param√©trico de regresi√≥n.",
  "El concepto de independencia de errores no aplica directamente. El modelo se basa en la co-ocurrencia de √≠tems para formar reglas.",
  "No asume homoscedasticidad. La predicci√≥n se basa en la activaci√≥n y ponderaci√≥n de reglas, no en la varianza constante de un error.",
  "S√≠, la clasificaci√≥n asociativa puede ser sensible a los outliers si estos dan lugar a la generaci√≥n de reglas de asociaci√≥n inusuales pero con alta confianza. Sin embargo, los umbrales de soporte y confianza pueden mitigar esto al filtrar reglas poco frecuentes.",
  "Maneja muy bien la multicolinealidad. De hecho, la identifica al encontrar combinaciones de atributos que coexisten frecuentemente y predicen la clase. No sufre de los problemas de inestabilidad que enfrentan los modelos lineales en presencia de multicolinealidad.",
  "La interpretabilidad es **muy alta**. El modelo resultante es un conjunto de reglas 'SI-ENTONCES' que son f√°ciles de entender y explicar. Esto permite a los expertos del dominio revisar y validar el conocimiento extra√≠do.",
  "La velocidad y eficiencia pueden ser bajas a moderadas. La fase de generaci√≥n de reglas de asociaci√≥n puede ser computacionalmente intensiva y consumir mucha memoria, especialmente si el dataset es grande o el n√∫mero de atributos es alto. El filtrado y la combinaci√≥n de reglas tambi√©n a√±aden complejidad.",
  "Es compatible y **recomendada**. La validaci√≥n cruzada es esencial para evaluar la capacidad de generalizaci√≥n del clasificador resultante y para ajustar hiperpar√°metros como el soporte m√≠nimo, la confianza m√≠nima y los criterios de selecci√≥n de reglas.",
  "No funciona bien si: 1) el dataset contiene **predominantemente variables num√©ricas** que no pueden discretizarse bien, 2) las relaciones predictivas son puramente continuas y no se expresan bien como patrones discretos, 3) hay **muy pocas reglas de asociaci√≥n fuertes** para construir un clasificador robusto, o 4) el dataset es **muy grande** y la generaci√≥n de reglas se vuelve inviable."
)

tabla_associative_classification <- data.frame(Criterio = criterios_associative_classification, Aplica = aplica_associative_classification, Detalles = detalles_associative_classification)

tabla_associative_classification %>%
  gt() %>%
  tab_header(
    title = "Gu√≠a r√°pida para elegir la Clasificaci√≥n Asociativa",
    subtitle = "Combinando Reglas de Asociaci√≥n con Clasificaci√≥n"
  ) %>%
  tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
  tab_options(
    heading.title.font.size = 14,
    heading.subtitle.font.size = 12,
    table.font.names = "Century Gothic",
    table.font.size = 10,
    data_row.padding = px(1)
  ) %>%
  tab_style(
    style = list(cell_text(align = "left", weight = 'bold')),
    locations = list(cells_title(groups = c("title")))
  ) %>%
  tab_style(
    style = list(cell_text(align = "left")),
    locations = list(cells_title(groups = c("subtitle")))
  ) %>%
  cols_width(
    starts_with("Detalles") ~ px(500),
    everything() ~ px(200)
  ) %>%
  as_raw_html()
```


## CN2 Algorithm {-}  

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/CN2.png"))
```

```{r, echo = FALSE}
library(gt)

criterios_cn2 <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica_cn2 <- c(
  "‚úÖ Supervisado (Clasificaci√≥n basada en reglas)",
  "‚úÖ Categ√≥rica",
  "‚úÖ Mixtas (num√©ricas y categ√≥ricas)",
  "‚úÖ Compleja (reglas 'SI-ENTONCES')",
  "‚ùå No es requisito",
  "‚ùå No aplica directamente",
  "‚ùå No es requisito",
  "‚úÖ S√≠ (pero maneja el ruido mejor que otros m√©todos de reglas)",
  "‚úÖ Maneja bien (si la m√©trica de evaluaci√≥n es robusta)",
  "‚úÖ Muy alta (reglas claras)",
  "‚ö†Ô∏è Moderada (depende del tama√±o del haz y umbrales)",
  "‚úÖ Compatible y recomendada",
  "‚ùå Datos con relaciones puramente num√©ricas y continuas sin discretizaci√≥n"
)

detalles_cn2 <- c(
  "El algoritmo CN2 es un algoritmo de inducci√≥n de reglas que genera un conjunto de reglas 'SI-ENTONCES' para la clasificaci√≥n. Combina ideas de algoritmos como AQ (que produce reglas) e ID3 (que maneja datos ruidosos), siendo efectivo incluso con datos imperfectos.",
  "La variable dependiente debe ser **categ√≥rica**. El objetivo es asignar una instancia a una clase o categor√≠a espec√≠fica bas√°ndose en las reglas aprendidas.",
  "Las variables predictoras pueden ser **num√©ricas o categ√≥ricas**. Las variables num√©ricas suelen discretizarse para formar las condiciones de las reglas. Es importante un pre-procesamiento adecuado.",
  "Establece relaciones complejas y no lineales mediante la creaci√≥n de reglas que identifican combinaciones espec√≠ficas de atributos que predicen una clase. A diferencia de los √°rboles de decisi√≥n, puede generar conjuntos de reglas m√°s concisos y comprensibles.",
  "No hace suposiciones estad√≠sticas sobre la normalidad de los residuos, ya que es un modelo no param√©trico basado en reglas discretas.",
  "El concepto de independencia de errores no aplica directamente. El algoritmo se enfoca en encontrar patrones de co-ocurrencia que formen reglas predictivas.",
  "No asume homoscedasticidad. La predicci√≥n se basa en la activaci√≥n de reglas y la clase mayoritaria de los ejemplos cubiertos por la regla, no en la varianza constante de un error.",
  "S√≠, el CN2 puede ser sensible a outliers si estos son lo suficientemente frecuentes como para influir en la creaci√≥n de reglas. Sin embargo, una de sus fortalezas es su capacidad para **manejar datos ruidosos** y evitar el sobreajuste mediante el uso de pruebas de significancia estad√≠stica y t√©cnicas de poda, lo que lo hace m√°s robusto que algoritmos de reglas m√°s simples.",
  "Maneja bien la multicolinealidad. Al igual que otros algoritmos basados en reglas, identifica combinaciones de atributos. Si las caracter√≠sticas est√°n correlacionadas, el algoritmo puede aprender reglas que incluyen esas caracter√≠sticas sin sufrir inestabilidad como los modelos lineales.",
  "La interpretabilidad es **muy alta**. Las reglas 'SI-ENTONCES' generadas son intuitivas y f√°ciles de entender por humanos, lo que permite a los expertos del dominio validar la l√≥gica del modelo y obtener informaci√≥n sobre los patrones en los datos.",
  "La velocidad y eficiencia son moderadas. El proceso de b√∫squeda de reglas se realiza utilizando una **b√∫squeda en haz (beam search)**, que es m√°s eficiente que una b√∫squeda exhaustiva. Sin embargo, puede ser lento para conjuntos de datos muy grandes o con un n√∫mero muy elevado de posibles condiciones.",
  "Es compatible y **recomendada**. La validaci√≥n cruzada es fundamental para evaluar la capacidad de generalizaci√≥n de las reglas inducidas y para ajustar hiperpar√°metros como el ancho del haz (beam width) y los umbrales de significancia (alpha) y cobertura m√≠nima de la regla.",
  "No funciona bien si: 1) el dataset contiene **relaciones puramente num√©ricas y continuas** que no pueden discretizarse de manera significativa, 2) las clases no pueden ser discriminadas por conjuntos de reglas concisos, lo que lleva a un n√∫mero excesivo de reglas, o 3) el **tama√±o del dataset es extremadamente grande** haciendo que la b√∫squeda de reglas sea ineficiente incluso con la poda."
)

tabla_cn2 <- data.frame(Criterio = criterios_cn2, Aplica = aplica_cn2, Detalles = detalles_cn2)

tabla_cn2 %>%
  gt() %>%
  tab_header(
    title = "Gu√≠a r√°pida para elegir el Algoritmo CN2",
    subtitle = "Inducci√≥n de Reglas de Clasificaci√≥n con Manejo de Ruido"
  ) %>%
  tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
  tab_options(
    heading.title.font.size = 14,
    heading.subtitle.font.size = 12,
    table.font.names = "Century Gothic",
    table.font.size = 10,
    data_row.padding = px(1)
  ) %>%
  tab_style(
    style = list(cell_text(align = "left", weight = 'bold')),
    locations = list(cells_title(groups = c("title")))
  ) %>%
  tab_style(
    style = list(cell_text(align = "left")),
    locations = list(cells_title(groups = c("subtitle")))
  ) %>%
  cols_width(
    starts_with("Detalles") ~ px(500),
    everything() ~ px(200)
  ) %>%
  as_raw_html()
```


## Decision List/Decision Tree to Rules {-} 

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/Decision Tree to Rules.png"))
```

```{r, echo = FALSE}
library(gt)

criterios_dt_to_rules <- c(
  "Tipo de Modelo (original y resultado)",
  "Variable Respuesta (del modelo original)",
  "Variables Predictoras (del modelo original)",
  "Relaci√≥n entre variables (en las reglas)",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensibilidad a Outliers",
  "Multicolinealidad entre Predictores",
  "Interpretabilidad (del resultado)",
  "Velocidad y eficiencia (del proceso de conversi√≥n y uso)",
  "Validaci√≥n Cruzada (aplicabilidad)",
  "No funciona bien si..."
)

aplica_dt_to_rules <- c(
  "‚úÖ Supervisado (Clasificaci√≥n/Regresi√≥n)",
  "‚úÖ Categ√≥rica o Num√©rica (seg√∫n el √°rbol)",
  "‚úÖ Mixtas (num√©ricas y categ√≥ricas)",
  "‚úÖ Compleja (reglas 'SI-ENTONCES')",
  "‚ùå No es requisito",
  "‚ùå No aplica directamente",
  "‚ùå No es requisito",
  "‚ö†Ô∏è S√≠ (hereda la sensibilidad del √°rbol)",
  "‚úÖ Maneja bien (hereda la capacidad del √°rbol)",
  "‚úÖ Muy alta (reglas claras y concisas)",
  "‚úÖ Muy alta (proceso r√°pido y reglas eficientes)",
  "‚úÖ Compatible y √∫til",
  "‚ùå √Årboles de decisi√≥n excesivamente complejos o sobreajustados"
)

detalles_dt_to_rules <- c(
  "El proceso de convertir un **√Årbol de Decisi√≥n** en un conjunto de reglas 'SI-ENTONCES'. Cada ruta desde la ra√≠z hasta un nodo hoja en el √°rbol se traduce directamente en una regla. Este m√©todo busca mejorar la interpretabilidad y, a veces, la generalizaci√≥n del modelo original.",
  "La variable dependiente es la misma que la del √°rbol de decisi√≥n original, que puede ser **categ√≥rica** (para clasificaci√≥n) o **num√©rica continua** (para regresi√≥n). En el caso de regresi√≥n, la regla predice un valor num√©rico.",
  "Las variables predictoras son las mismas que se usaron para construir el √°rbol de decisi√≥n. Pueden ser **num√©ricas** (con umbrales) o **categ√≥ricas** (con condiciones de igualdad/desigualdad).",
  "La relaci√≥n se expresa a trav√©s de conjunciones l√≥gicas de condiciones (`AND`) que forman las reglas. Las reglas capturan la l√≥gica de ramificaci√≥n del √°rbol, lo que permite modelar relaciones complejas y no lineales entre los predictores y la variable respuesta.",
  "No hace suposiciones sobre la normalidad de los residuos, ya que el proceso de conversi√≥n se basa en la estructura l√≥gica del √°rbol, no en la distribuci√≥n estad√≠stica de los errores.",
  "El concepto de independencia de errores no aplica directamente al proceso de extracci√≥n de reglas. La validez de las reglas depende de la calidad del √°rbol original.",
  "No asume homoscedasticidad. Las reglas representan segmentos del espacio de caracter√≠sticas, y la varianza de la respuesta dentro de esos segmentos no se asume constante.",
  "S√≠, el proceso de conversi√≥n **hereda la sensibilidad a outliers del √°rbol de decisi√≥n original**. Si el √°rbol se sobreajusta a outliers, las reglas resultantes tambi√©n reflejar√°n ese sobreajuste. Sin embargo, si el √°rbol est√° podado, las reglas ser√°n m√°s robustas.",
  "Maneja bien la multicolinealidad, ya que **hereda la capacidad del √°rbol de decisi√≥n** para trabajar con predictores correlacionados. Los √°rboles de decisi√≥n son inherentemente robustos a la multicolinealidad porque eligen la mejor caracter√≠stica para dividir en cada paso, sin requerir independencia entre ellas.",
  "La interpretabilidad es **muy alta**. Las reglas 'SI-ENTONCES' son una de las formas m√°s f√°ciles de entender la l√≥gica de un modelo. Permiten una inspecci√≥n directa del conocimiento extra√≠do y son f√°cilmente comunicables a no expertos.",
  "La velocidad y eficiencia son **muy altas**. El proceso de convertir un √°rbol ya entrenado en reglas es trivial y r√°pido. Las reglas resultantes son muy eficientes para la inferencia, ya que solo implican evaluaciones de condiciones l√≥gicas.",
  "Es compatible y **muy √∫til**. La validaci√≥n cruzada se aplica al modelo de √°rbol de decisi√≥n original para evaluar su rendimiento y prevenir el sobreajuste antes de la extracci√≥n de reglas. Adem√°s, el conjunto de reglas resultante puede evaluarse con validaci√≥n cruzada para confirmar su generalizaci√≥n.",
  "No funciona bien si: 1) el **√°rbol de decisi√≥n original es excesivamente complejo o profundo** (lo que resulta en un n√∫mero muy grande de reglas, cada una muy espec√≠fica, perdiendo interpretabilidad), 2) el √°rbol est√° **sobreajustado** a los datos de entrenamiento, o 3) las relaciones en los datos son tan complejas que incluso un √°rbol profundo no puede capturarlas bien, llevando a reglas d√©biles."
)

tabla_dt_to_rules <- data.frame(Criterio = criterios_dt_to_rules, Aplica = aplica_dt_to_rules, Detalles = detalles_dt_to_rules)

tabla_dt_to_rules %>%
  gt() %>%
  tab_header(
    title = "Gu√≠a r√°pida para la Conversi√≥n de √Årboles de Decisi√≥n a Reglas",
    subtitle = "Extrayendo Conocimiento Expl√≠cito y Simplificado de √Årboles"
  ) %>%
  tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
  tab_options(
    heading.title.font.size = 14,
    heading.subtitle.font.size = 12,
    table.font.names = "Century Gothic",
    table.font.size = 10,
    data_row.padding = px(1)
  ) %>%
  tab_style(
    style = list(cell_text(align = "left", weight = 'bold')),
    locations = list(cells_title(groups = c("title")))
  ) %>%
  tab_style(
    style = list(cell_text(align = "left")),
    locations = list(cells_title(groups = c("subtitle")))
  ) %>%
  cols_width(
    starts_with("Detalles") ~ px(500),
    everything() ~ px(200)
  ) %>%
  as_raw_html()
```


## Decision Rules  {-}   

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/Decision Rules.png"))
```

Las **Reglas de Decisi√≥n** no son un algoritmo de Machine Learning en s√≠ mismas, sino una **forma de representar un modelo predictivo** que es altamente **interpretable y f√°cil de entender**. Son una de las formas m√°s intuitivas de expresar el conocimiento extra√≠do de los datos. Una regla de decisi√≥n t√≠picamente toma la forma de una declaraci√≥n **"SI-ENTONCES" (IF-THEN)**, donde la parte "SI" (antecedente) describe las condiciones que deben cumplirse y la parte "ENTONCES" (consecuente) especifica la predicci√≥n o la acci√≥n a tomar.

**Estructura de una Regla de Decisi√≥n:**

Una regla de decisi√≥n b√°sica tiene la siguiente forma:

**SI** *condici√≥n 1* **Y** *condici√≥n 2* **Y** ... **Y** *condici√≥n N* **ENTONCES** *predicci√≥n / clase / valor*

**Ejemplos:**

* **Para Clasificaci√≥n:**
    * **SI** `Edad` > 30 **Y** `Ingreso` < 50,000 **ENTONCES** `Clase: Riesgo Bajo`
    * **SI** `Clima` = Soleado **Y** `Humedad` > 70% **ENTONCES** `Acci√≥n: No Jugar Tenis`

* **Para Regresi√≥n:**
    * **SI** `Tama√±o_Casa` > 150 m¬≤ **Y** `Num_Habitaciones` = 3 **ENTONCES** `Precio_Estimado: $300,000`

**Caracter√≠sticas Clave:**   

* **Interpretabilidad:** Son inherentemente f√°ciles de entender por los humanos, incluso por aquellos sin conocimientos t√©cnicos profundos.
* **Modularidad:** Un modelo completo puede estar compuesto por un conjunto de reglas. Cada regla es independiente y f√°cil de examinar.
* **No Linealidad:** Aunque cada regla es una declaraci√≥n l√≥gica simple, un conjunto de reglas puede modelar relaciones no lineales complejas en los datos, ya que cada regla cubre una regi√≥n diferente del espacio de caracter√≠sticas.
* **Selecci√≥n de Caracter√≠sticas Impl√≠cita:** Al construir reglas, solo las caracter√≠sticas relevantes para la condici√≥n se incluyen, lo que realiza una selecci√≥n impl√≠cita de caracter√≠sticas.
* **Robustez:** A menudo son bastante robustas a los outliers y a los datos ruidosos si las reglas se derivan y podan correctamente.

**Algoritmos que Generan Reglas de Decisi√≥n:** 

Si bien las reglas de decisi√≥n son la forma de representaci√≥n, varios algoritmos de Machine Learning se especializan en aprender estas reglas a partir de los datos:

* **√Årboles de Decisi√≥n:** Cada ruta desde la ra√≠z hasta una hoja en un √°rbol de decisi√≥n se puede traducir directamente en una regla de decisi√≥n.
* **Algoritmos Basados en Reglas:**
    * **OneR:** Genera una √∫nica regla basada en el atributo m√°s predictivo.
    * **RIPPER:** Produce conjuntos de reglas optimizados para la clasificaci√≥n, con √©nfasis en la poda y la simplicidad.
    * **RuleFit:** Combina reglas extra√≠das de ensamblajes de √°rboles con caracter√≠sticas originales en un modelo lineal regularizado.
* **Sistemas de L√≥gica Difusa:** Utilizan reglas difusas para manejar la incertidumbre y la imprecisi√≥n.


**Aprendizaje Global vs. Local:**

Los modelos basados en **Reglas de Decisi√≥n** combinan de manera muy efectiva **aspectos de aprendizaje global y local**.

* **Aspecto Local (Cada Regla Individual):**
    * Cada regla de decisi√≥n es intr√≠nsecamente **local**. Define una **regi√≥n espec√≠fica** (un subespacio, a menudo un hiperrect√°ngulo) en el espacio de caracter√≠sticas. Dentro de esta regi√≥n, la regla hace una predicci√≥n particular. Por ejemplo, la regla "SI `Edad` > 30 Y `Ingreso` < 50,000" solo se aplica a un subconjunto espec√≠fico de instancias.
    * La naturaleza "local" de cada regla permite al modelo adaptarse a **relaciones no lineales y complejas**. Diferentes reglas pueden activarse en distintas partes del espacio de datos, capturando patrones que var√≠an significativamente de una regi√≥n a otra, similar a una **"regresi√≥n (o clasificaci√≥n) ponderada localmente"** donde cada regla representa un modelo simple para su regi√≥n.

* **Aspecto Global (El Conjunto de Reglas):**
    * Aunque las reglas individuales son locales, el **conjunto completo de reglas** que conforma el modelo se aplica para cubrir **todo el espacio de caracter√≠sticas relevante**. Este conjunto de reglas forma un **modelo predictivo global** que puede clasificar o predecir un valor para cualquier nueva instancia.
    * Los algoritmos que generan estos conjuntos de reglas (como RIPPER) a menudo optimizan la colecci√≥n de reglas para un rendimiento global, buscando un equilibrio entre la precisi√≥n y la complejidad del modelo en su conjunto.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n o regresi√≥n)",
  "‚úÖ Num√©rica o categ√≥rica",
  "‚úÖ Num√©ricas y categ√≥ricas",
  "‚úÖ Basado en reglas (if-then) que segmentan el espacio predictor",
  "‚ùå No aplica directamente (no es un modelo param√©trico)",
  "‚ö†Ô∏è Asume independencia de observaciones",
  "‚ùå No aplica",
  "‚ö†Ô∏è Moderadamente sensible, outliers pueden crear reglas poco √∫tiles",
  "‚ö†Ô∏è No afecta directamente, pero reglas redundantes pueden complicar modelo",
  "‚úÖ Muy interpretable, reglas claras y simples",
  "‚úÖ R√°pido para datasets peque√±os y medianos",
  "‚úÖ Compatible con validaci√≥n cruzada",
  "‚ùå Puede sobreajustar si hay mucho ruido o datos muy complejos"
)

detalles <- c(
  "Modelos que usan reglas l√≥gicas para realizar predicciones, f√°cilmente entendibles.",
  "Permite predecir tanto clases (clasificaci√≥n) como valores num√©ricos (regresi√≥n).",
  "Acepta tanto variables categ√≥ricas como num√©ricas como predictores.",
  "Segmenta el espacio en regiones mediante reglas que dividen las variables predictoras.",
  "No genera residuos ni supone distribuci√≥n de error como modelos param√©tricos.",
  "Las reglas asumen que las observaciones son independientes.",
  "No aplica homoscedasticidad porque no es un modelo estad√≠stico cl√°sico.",
  "Outliers pueden influir en la generaci√≥n de reglas, creando reglas poco generalizables.",
  "La multicolinealidad no afecta directamente, pero puede generar reglas redundantes.",
  "La fortaleza es la interpretabilidad clara y sencilla de las reglas obtenidas.",
  "Generalmente eficiente, pero depende del n√∫mero de reglas y complejidad del dataset.",
  "Se recomienda validar con m√©todos como k-fold para evitar sobreajuste.",
  "No es ideal para datasets con mucho ruido o cuando la relaci√≥n es muy compleja o sutil."
)

tabla_rules <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_rules %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision rules",
             subtitle = "Decision Rules")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## L√≥gica Difusa (Fuzzy Logic) {-}

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/Fuzzy Logic.png"))
```

La **L√≥gica Difusa (Fuzzy Logic)** no es un algoritmo de Machine Learning en s√≠ mismo, sino un **paradigma de computaci√≥n basado en la noci√≥n de "grado de verdad"** en lugar de los valores binarios "verdadero o falso" (1 o 0) de la l√≥gica booleana cl√°sica. Permite modelar el razonamiento humano, que a menudo involucra informaci√≥n imprecisa, ambigua o vaga. Es un marco para representar y manipular el conocimiento que es inherentemente incierto o subjetivo.

La idea central de la l√≥gica difusa es que un elemento puede **pertenecer a un conjunto en un cierto grado** (entre 0 y 1), en lugar de pertenecer completamente o no pertenecer en absoluto. Por ejemplo, una persona puede ser "alta" en un grado de 0.8 y "mediana" en un grado de 0.2, en lugar de ser estrictamente alta o estrictamente mediana.

Los componentes clave de un sistema de l√≥gica difusa suelen incluir:

1.  **Conjuntos Difusos (Fuzzy Sets):** Definen el grado de pertenencia de un elemento a una categor√≠a. Por ejemplo, un conjunto difuso para "temperatura alta" podr√≠a tener una funci√≥n de pertenencia que asigne un valor de 0 a 10 grados, 0.5 a 20 grados, y 1 a 30 grados.
2.  **Variables Ling√º√≠sticas:** Son variables cuyos valores son palabras o oraciones del lenguaje natural (ej., "temperatura", cuyos valores pueden ser "fr√≠o", "tibio", "caliente").
3.  **Funciones de Pertenencia (Membership Functions):** Gr√°ficos que definen matem√°ticamente el grado de pertenencia de un elemento a un conjunto difuso.
4.  **Reglas Difusas (Fuzzy Rules):** Reglas de tipo "SI-ENTONCES" que utilizan variables ling√º√≠sticas y conjuntos difusos. Por ejemplo: "SI la temperatura es *caliente* Y la humedad es *alta* ENTONCES la velocidad del ventilador es *r√°pida*".
5.  **Fuzificaci√≥n:** Proceso de convertir valores de entrada n√≠tidos (crisp inputs) en grados de pertenencia a conjuntos difusos.
6.  **Motor de Inferencia:** Aplica las reglas difusas para producir una salida difusa.
7.  **Defuzificaci√≥n:** Proceso de convertir la salida difusa en un valor de salida n√≠tido (crisp output) que pueda ser utilizado en el mundo real.

La l√≥gica difusa es ampliamente utilizada en sistemas de control (ej., lavadoras, sistemas de frenos ABS, c√°maras de video), sistemas expertos y en el procesamiento de informaci√≥n imprecisa.

**Aprendizaje Global vs. Local:**

La L√≥gica Difusa, como paradigma, tiene la capacidad de integrar aspectos de **modelado global y local**, dependiendo de c√≥mo se implemente y se "entrene" (o sintonice).

* **Aspecto Local (Granularidad de las Reglas y Conjuntos Difusos):**
    * Las **reglas difusas** operan sobre condiciones locales (ej., "SI la temperatura es *caliente*"). Cada regla cubre una porci√≥n espec√≠fica del espacio de entrada/salida. Los **conjuntos difusos** y sus funciones de pertenencia particionan el espacio de caracter√≠sticas en regiones "borrosas" o traslapadas, lo que permite que el modelo se adapte a las caracter√≠sticas de los datos en vecindarios espec√≠ficos. Es decir, la respuesta del sistema se construye a partir de la activaci√≥n ponderada de varias reglas locales, cada una representando un comportamiento en una regi√≥n del espacio de entrada. Esto es muy similar a una **"regresi√≥n ponderada localmente"**, donde la contribuci√≥n de cada regla (o modelo impl√≠cito) se pondera por el grado en que la entrada actual pertenece a la regi√≥n de esa regla. Esta granularidad y superposici√≥n le permiten manejar **relaciones no lineales y complejas** al aproximarlas con una combinaci√≥n de estas contribuciones locales.

* **Aspecto Global (Coherencia del Sistema y Cobertura):**
    * Aunque las reglas son locales, un sistema de l√≥gica difusa bien dise√±ado cubre todo el espacio de entrada relevante y proporciona una **respuesta global coherente**. El conjunto de todas las reglas y funciones de pertenencia, junto con el motor de inferencia, forma un **sistema global** que puede mapear cualquier entrada a una salida. La defuzificaci√≥n final produce un valor n√≠tido que es el resultado de la combinaci√≥n de todas las activaciones de las reglas.

* **Aprendizaje y Sintonizaci√≥n:** Cuando se combinan con t√©cnicas de Machine Learning (como redes neuronales o algoritmos gen√©ticos), los sistemas difusos pueden "aprender" o "sintonizar" sus funciones de pertenencia y reglas. Este proceso de aprendizaje puede optimizar el rendimiento del sistema a nivel global (minimizando un error general), pero los ajustes siguen afectando las propiedades locales de las reglas y conjuntos difusos.

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado o no supervisado (depende del sistema)",
  "‚úÖ Variables de salida pueden ser continuas o categ√≥ricas (fuzzy sets)",
  "‚úÖ Variables num√©ricas o categ√≥ricas, modeladas como grados de pertenencia",
  "‚úÖ Modela relaciones imprecisas, no binarias, usando l√≥gica difusa",
  "‚ùå No aplica (no modelo estad√≠stico tradicional)",
  "‚ö†Ô∏è Puede asumir independencia pero depende del dise√±o del sistema",
  "‚ùå No aplica",
  "‚ö†Ô∏è Moderadamente sensible, depende de la funci√≥n de membres√≠a",
  "‚ö†Ô∏è No afecta directamente pero variables correlacionadas pueden complicar reglas",
  "‚úÖ Interpretaci√≥n basada en reglas ling√º√≠sticas y grados de verdad",
  "‚ö†Ô∏è Puede ser lento con muchos conjuntos difusos y reglas complejas",
  "‚ö†Ô∏è Validaci√≥n cruzada posible, pero no est√°ndar en l√≥gica difusa",
  "‚ùå No es adecuado si los datos son muy exactos y no presentan incertidumbre"
)

detalles <- c(
  "Sistemas que usan l√≥gica difusa para manejar incertidumbre y aproximaci√≥n en los datos.",
  "Las variables respuesta pueden ser valores continuos o categor√≠as definidas mediante conjuntos difusos.",
  "Los predictores se transforman en grados de pertenencia a conjuntos difusos para evaluar reglas.",
  "Permite modelar relaciones vagamente definidas, imprecisas o con fronteras difusas.",
  "No se basa en supuestos estad√≠sticos cl√°sicos, por eso no aplica normalidad.",
  "La independencia depende de c√≥mo se dise√±en las reglas y sistemas difusos.",
  "No es un modelo param√©trico cl√°sico, por eso homoscedasticidad no aplica.",
  "Outliers pueden afectar las funciones de pertenencia y la l√≥gica aplicada.",
  "Variables altamente correlacionadas pueden hacer que las reglas sean redundantes o complejas.",
  "Los resultados se interpretan mediante reglas tipo 'Si... entonces...' con grados de verdad.",
  "La complejidad crece con n√∫mero de variables y reglas, afectando velocidad.",
  "Validar es menos est√°ndar, se usan m√©todos espec√≠ficos seg√∫n la aplicaci√≥n.",
  "No es √∫til para datos precisos donde no existe incertidumbre o imprecisi√≥n."
)

tabla_fuzzy <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_fuzzy %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision fuzzy rules",
             subtitle = "Fuzzy Rules")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Minsky's Perceptron {-}    

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/Minsky's Perceptron.png"))
```

```{r, echo = FALSE}
library(gt)

criterios_perceptron_minsky <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica_perceptron_minsky <- c(
  "‚úÖ Supervisado (Clasificaci√≥n)",
  "‚úÖ Categ√≥rica binaria (0/1 o -1/1)",
  "‚úÖ Num√©ricas",
  "‚úÖ Linealmente separable",
  "‚ùå No es requisito",
  "‚ùå No aplica directamente",
  "‚ùå No es requisito",
  "‚ö†Ô∏è S√≠ (la convergencia puede verse afectada)",
  "‚úÖ Maneja bien (si la linealidad es el problema)",
  "‚úÖ Alta (pesos directos)",
  "‚úÖ Muy alta (algoritmo simple y r√°pido)",
  "‚úÖ Compatible",
  "‚ùå Datos no linealmente separables"
)

detalles_perceptron_minsky <- c(
  "Un clasificador binario lineal, una de las primeras arquitecturas de red neuronal artificial. Su objetivo es encontrar un hiperplano que separe dos clases de datos.",
  "La variable dependiente debe ser categ√≥rica con solo dos clases, t√≠picamente codificadas como 0/1 o -1/1.",
  "Las variables predictoras deben ser num√©ricas. Las categ√≥ricas necesitan ser codificadas adecuadamente (ej. one-hot encoding).",
  "Asume que las clases en los datos son **linealmente separables**, es decir, que se puede trazar una l√≠nea (o hiperplano en dimensiones superiores) para separar perfectamente las dos clases.",
  "No hace suposiciones sobre la normalidad de los residuos ni la distribuci√≥n de los datos, ya que no es un modelo estad√≠stico param√©trico en ese sentido.",
  "El concepto de independencia de errores no aplica directamente. El algoritmo se entrena iterativamente ajustando pesos basados en ejemplos individuales.",
  "No asume homoscedasticidad. Su objetivo es encontrar un l√≠mite de decisi√≥n, no modelar la varianza.",
  "S√≠, el Perceptr√≥n es sensible a los outliers. Un outlier puede impedir la convergencia si hace que el conjunto de datos se vuelva no linealmente separable, o puede forzar al hiperplano a un lugar sub√≥ptimo.",
  "Maneja bien la multicolinealidad en el sentido de que todav√≠a puede encontrar un hiperplano si existe. Sin embargo, puede hacer que la soluci√≥n no sea √∫nica y que los pesos sean menos estables.",
  "La interpretabilidad es alta. Los pesos asignados a cada predictor indican la importancia y direcci√≥n de la influencia de esa caracter√≠stica en la clasificaci√≥n, de manera similar a los coeficientes en la regresi√≥n lineal.",
  "La velocidad y eficiencia son muy altas. El algoritmo de entrenamiento es simple y converge r√°pidamente a una soluci√≥n si los datos son linealmente separables. Las predicciones son extremadamente r√°pidas.",
  "Es compatible. La validaci√≥n cruzada se puede utilizar para evaluar el rendimiento de generalizaci√≥n del Perceptr√≥n en conjuntos de datos no vistos.",
  "No funciona bien si: 1) los datos **no son linealmente separables** (el problema del XOR es el ejemplo cl√°sico, donde un solo Perceptr√≥n no puede encontrar un l√≠mite de decisi√≥n), 2) los datos tienen **mucho ruido** que afecta la separabilidad lineal, o 3) se requiere una estimaci√≥n de probabilidad de pertenencia a la clase (ya que produce una salida binaria dura)."
)

tabla_perceptron_minsky <- data.frame(Criterio = criterios_perceptron_minsky, Aplica = aplica_perceptron_minsky, Detalles = detalles_perceptron_minsky)

tabla_perceptron_minsky %>%
  gt() %>%
  tab_header(
    title = "Gu√≠a r√°pida sobre el Perceptr√≥n (de Minsky)",
    subtitle = "Clasificador Lineal Binario y sus Limitaciones"
  ) %>%
  tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
  tab_options(
    heading.title.font.size = 14,
    heading.subtitle.font.size = 12,
    table.font.names = "Century Gothic",
    table.font.size = 10,
    data_row.padding = px(1)
  ) %>%
  tab_style(
    style = list(cell_text(align = "left", weight = 'bold')),
    locations = list(cells_title(groups = c("title")))
  ) %>%
  tab_style(
    style = list(cell_text(align = "left")),
    locations = list(cells_title(groups = c("subtitle")))
  ) %>%
  cols_width(
    starts_with("Detalles") ~ px(500),
    everything() ~ px(200)
  ) %>%
  as_raw_html()
```


## One Rule (OneR)  {-}   

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/OneR.png"))
```


**One Rule (OneR)** es un algoritmo de **clasificaci√≥n supervisada** notable por su **simplicidad y alta interpretabilidad**. Fue propuesto por Robert Holte en 1993 y, a pesar de su sencillez, a menudo logra una precisi√≥n sorprendentemente buena en comparaci√≥n con algoritmos mucho m√°s complejos, sirviendo como una excelente l√≠nea base (benchmark) para el rendimiento del modelo.

La idea central de OneR es construir un clasificador que se base en **una √∫nica regla** para tomar decisiones. Esta regla se deriva de **un solo atributo (caracter√≠stica)** del conjunto de datos que es el m√°s predictivo de la clase de salida.

El funcionamiento del algoritmo OneR es el siguiente:

1.  **Iterar a Trav√©s de Cada Atributo:** Para cada atributo en el conjunto de datos de entrenamiento (se asume que los atributos son categ√≥ricos; si son continuos, primero deben discretizarse):
    * **Crear una Regla para Cada Valor:** Para cada valor √∫nico que puede tomar ese atributo, se construye una regla.
    * **Encontrar la Clase M√°s Frecuente:** Para cada una de estas reglas, se cuenta cu√°ntas veces aparece cada clase de destino cuando el atributo toma ese valor. La clase que ocurre con mayor frecuencia se convierte en la predicci√≥n para esa regla.
    * **Calcular el Error de la Regla:** Se calcula el n√∫mero de errores que comete esta regla (es decir, el n√∫mero de instancias para las cuales la clase predicha no coincide con la clase real).
2.  **Seleccionar el Mejor Atributo:** Una vez que se han generado reglas y calculado los errores para *todos* los atributos, OneR selecciona el atributo (y su conjunto de reglas asociadas) que tiene el **menor error total**. Si hay un empate entre varios atributos, se puede elegir el primero o usar un criterio secundario (como el test de chi-cuadrado).
3.  **El Modelo Final:** El conjunto de reglas derivado de este atributo seleccionado se convierte en el modelo final de clasificaci√≥n.

Por ejemplo, si tenemos un atributo "Clima" con valores "Soleado", "Nublado", "Lluvioso" y una clase "Jugar al Golf" (S√≠/No):
* Si Clima = Soleado: La mayor√≠a juega golf (S√≠). Error: 2 (de 5)
* Si Clima = Nublado: La mayor√≠a juega golf (S√≠). Error: 0 (de 4)
* Si Clima = Lluvioso: La mayor√≠a NO juega golf (No). Error: 1 (de 5)
* Error total para "Clima" = 2 + 0 + 1 = 3.

Este proceso se repetir√≠a para otros atributos como "Temperatura", "Humedad", etc., y el atributo con el menor error total ser√≠a el elegido.

**Aprendizaje Global vs. Local:**

One Rule (OneR) es un modelo de **aprendizaje fundamentalmente global**, aunque la regla que aprende implica una partici√≥n del espacio de caracter√≠sticas.

* **Aspecto Global:** OneR eval√∫a **todos los atributos en su totalidad** y selecciona el **√∫nico atributo que es globalmente el m√°s predictivo** para la tarea de clasificaci√≥n sobre todo el conjunto de datos. La regla elegida y sus condiciones se aplican uniformemente a cualquier nueva instancia en el espacio de caracter√≠sticas. No se construyen modelos separados o locales para diferentes regiones del espacio de caracter√≠sticas. El algoritmo busca la mejor regla √∫nica que resuma el patr√≥n m√°s fuerte en todos los datos.

* **Partici√≥n del Espacio (Reglas):** Aunque el modelo es global, la "regla" que genera s√≠ que particiona el espacio de caracter√≠sticas. Por ejemplo, si el atributo seleccionado es "Color" y tiene valores "Rojo", "Azul", "Verde", el modelo crea una regla para cada uno de estos valores. Esto crea "regiones" en el espacio de datos (instancias donde Color=Rojo, donde Color=Azul, etc.). Sin embargo, la predicci√≥n dentro de cada una de estas regiones es simplemente la clase mayoritaria observada en esa regi√≥n, y el modelo en su conjunto es una √∫nica estructura de decisi√≥n global basada en ese √∫nico atributo. No es un ajuste din√°mico o ponderado localmente de par√°metros como en otros modelos de aprendizaje local.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n)",
  "‚úÖ Variable respuesta categ√≥rica (clases)",
  "‚úÖ Variables predictoras num√©ricas o categ√≥ricas",
  "‚úÖ Relaci√≥n simple basada en una sola regla (una variable predictora)",
  "‚ùå No aplica (no es modelo estad√≠stico param√©trico)",
  "‚ùå No aplica",
  "‚ùå No aplica",
  "‚ö†Ô∏è Puede ser sensible a outliers si afectan la regla",
  "‚ö†Ô∏è No afecta directamente (usa solo una variable para la regla)",
  "‚úÖ Muy interpretable: una regla sencilla basada en un solo predictor",
  "‚úÖ Muy r√°pido y eficiente, especialmente en datasets peque√±os o medianos",
  "‚úÖ Se puede usar validaci√≥n cruzada para evaluar rendimiento",
  "‚ùå No funciona bien si las relaciones son complejas y requieren m√∫ltiples variables"
)

detalles <- c(
  "Modelo supervisado para clasificaci√≥n basado en la regla m√°s simple y efectiva de un solo predictor.",
  "Predice la clase de salida bas√°ndose en el valor de una √∫nica variable predictora.",
  "Acepta variables categ√≥ricas o num√©ricas (estas se discretizan para generar reglas).",
  "Genera una regla simple: 'Si predictor X tiene valor Y, entonces clase Z'.",
  "No es un modelo param√©trico ni estad√≠stico tradicional, no eval√∫a residuos.",
  "No considera errores ni supuestos de independencia.",
  "No aplica el supuesto de homoscedasticidad.",
  "Outliers pueden influir si cambian la regla seleccionada.",
  "Como usa solo un predictor, la multicolinealidad no es un problema.",
  "F√°cil de entender y explicar, ideal para explicar decisiones simples.",
  "Muy r√°pido de entrenar y evaluar, √∫til para benchmarks o como baseline.",
  "Se recomienda evaluar mediante validaci√≥n cruzada para evitar sobreajuste.",
  "No es √∫til para problemas que requieren modelar interacciones complejas entre variables."
)

tabla_oner <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_oner %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision OneR",
             subtitle = "One Rule (OneR)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Repeated Incremental Pruning to Produce Error Reduction (RIPPER)  {-}  

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/RIPPER.png"))
```

**RIPPER (Repeated Incremental Pruning to Produce Error Reduction)** es un algoritmo de **clasificaci√≥n supervisada** muy conocido, desarrollado por William W. Cohen. Es una extensi√≥n del algoritmo de reglas `IREP` y es especialmente valorado por su capacidad para generar **conjuntos de reglas de clasificaci√≥n precisos y de alta calidad** que son a menudo m√°s simples e interpretables que los modelos de √°rbol de decisi√≥n complejos, al tiempo que es muy eficiente en t√©rminos computacionales, incluso con grandes conjuntos de datos.

RIPPER construye un conjunto de reglas `IF-THEN` para cada clase de forma secuencial. Opera con un enfoque de **"divide y vencer√°s"**, pero con un fuerte √©nfasis en la **poda (pruning)** para evitar el sobreajuste.

El proceso general de RIPPER para construir reglas para una clase espec√≠fica es el siguiente:

1.  **Generaci√≥n de Reglas (Growing):**
    * Comienza con una regla vac√≠a.
    * A√±ade t√©rminos (condiciones) a la regla que maximicen alguna m√©trica de calidad (por ejemplo, el ratio de ganancia de informaci√≥n) hasta que la regla cubre un cierto n√∫mero de ejemplos positivos (ejemplos de la clase actual) y pocos ejemplos negativos.
2.  **Poda de Reglas (Pruning):**
    * Una vez que una regla ha sido generada, se somete a un proceso de poda incremental. Se eliminan t√©rminos de la regla que no mejoran significativamente el error de la regla en un conjunto de validaci√≥n separado (el "conjunto de poda"). Esto ayuda a generalizar la regla y evitar el sobreajuste.
3.  **Adici√≥n de Reglas:**
    * Despu√©s de podar una regla, se a√±ade al conjunto de reglas para la clase actual.
    * Los ejemplos cubiertos por esta nueva regla se eliminan del conjunto de entrenamiento.
    * Se repiten los pasos 1-3 para construir nuevas reglas para la misma clase hasta que no queden suficientes ejemplos de la clase o no se puedan generar m√°s reglas que cumplan ciertos criterios.
4.  **Optimizaci√≥n Global y Re-poda:**
    * Una vez que se ha generado un conjunto inicial de reglas para una clase, RIPPER realiza varias pasadas de optimizaci√≥n.
    * En cada pasada, se intenta reemplazar o modificar reglas para reducir a√∫n m√°s el error total del conjunto de reglas. Esto incluye estrategias como la sustituci√≥n de reglas (reemplazar una regla existente por una mejor), la reversi√≥n de reglas (eliminar una regla), y la combinaci√≥n de reglas.
    * Se utiliza una m√©trica como la **descripci√≥n m√≠nima de la longitud (MDL - Minimum Description Length)** para penalizar la complejidad del modelo.

El proceso se repite para todas las clases, y las reglas se organizan en un orden de prioridad.


**Aprendizaje Global vs. Local:**

RIPPER es un algoritmo que combina de manera muy efectiva aspectos de **aprendizaje global y local**, pero con un fuerte √©nfasis en la generaci√≥n de **reglas locales** que se combinan en un modelo global.

* **Aspecto Local (Generaci√≥n de Reglas Individuales):** Cada regla que RIPPER aprende es esencialmente un **modelo local** que cubre una regi√≥n espec√≠fica del espacio de caracter√≠sticas. Las condiciones de la regla (`IF A AND B THEN Class X`) definen un hiperrect√°ngulo (o una regi√≥n m√°s compleja) en el espacio de caracter√≠sticas. La regla se aprende para predecir correctamente los puntos dentro de esa regi√≥n. La poda de reglas, en particular, se enfoca en optimizar el rendimiento de la regla en su "vecindario" de datos cubiertos, evitando el sobreajuste a puntos de entrenamiento individuales. Las reglas se ajustan a patrones y relaciones **locales** dentro de los datos.

* **Aspecto Global (Conjunto de Reglas y Priorizaci√≥n):** Aunque las reglas individuales son locales, el **conjunto final de reglas** para todas las clases, y su orden de prioridad, forman un **modelo de clasificaci√≥n global** que cubre todo el espacio de caracter√≠sticas. Cuando una nueva instancia necesita ser clasificada, se eval√∫a contra todas las reglas en orden hasta que una se activa, y esa regla dicta la predicci√≥n. La optimizaci√≥n global del conjunto de reglas, mediante la repoda y las fases de reemplazo de reglas, asegura que el modelo final sea coherente y preciso a nivel de todo el conjunto de datos.    


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n)",
  "‚úÖ Variable respuesta categ√≥rica",
  "‚úÖ Variables predictoras num√©ricas o categ√≥ricas",
  "‚úÖ Relaci√≥n no lineal basada en reglas de decisi√≥n",
  "‚ùå No aplica (no es modelo param√©trico)",
  "‚ùå No aplica",
  "‚ùå No aplica",
  "‚ö†Ô∏è Moderadamente sensible a outliers, depende de la calidad de datos",
  "‚ö†Ô∏è No afecta directamente, pero multicolinealidad puede confundir reglas",
  "‚ö†Ô∏è Interpretaci√≥n mediante reglas, m√°s complejas que OneR pero a√∫n legibles",
  "‚ö†Ô∏è Moderada, puede ser lento en datasets muy grandes",
  "‚úÖ Se puede validar con m√©todos de validaci√≥n cruzada",
  "‚ùå No funciona bien si las reglas no separan claramente las clases o en datos muy ruidosos"
)

detalles <- c(
  "Algoritmo supervisado para clasificaci√≥n que genera reglas de decisi√≥n con poda incremental para reducir error.",
  "Predice clases usando conjuntos de reglas de decisi√≥n extra√≠das y podadas iterativamente.",
  "Soporta variables num√©ricas y categ√≥ricas, con discretizaci√≥n interna si es necesario.",
  "Captura relaciones no lineales y complejas mediante reglas combinadas.",
  "No utiliza modelos estad√≠sticos cl√°sicos, por lo que no aplica an√°lisis de residuos.",
  "No asume independencia entre observaciones.",
  "No requiere homoscedasticidad ni otros supuestos de regresi√≥n.",
  "Outliers pueden afectar la calidad y la complejidad de las reglas generadas.",
  "Multicolinealidad no afecta directamente, pero puede inducir reglas redundantes.",
  "Las reglas generadas son m√°s interpretables que √°rboles complejos, pero menos simples que OneR.",
  "El proceso iterativo y poda pueden ser computacionalmente costosos en grandes datasets.",
  "Validaci√≥n cruzada es recomendada para evaluar generalizaci√≥n y evitar sobreajuste.",
  "No es adecuado para datos con ruido elevado o donde no existen reglas claras para separar clases."
)

tabla_ripper <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)


tabla_ripper %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision RIPPER",
             subtitle = "Repeated Incremental Pruning to Produce Error Reduction (RIPPER)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Rule Fit  {-}    

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/Rule Fit.png"))
```

**RuleFit** es un potente y, al mismo tiempo, **interpretable algoritmo de aprendizaje autom√°tico** desarrollado por Jerome H. Friedman y Bogdan Popescu. Est√° dise√±ado para combinar la **precisi√≥n de los m√©todos de ensamblaje (como el *gradient boosting* o los *random forests*)** con la **interpretabilidad de los modelos lineales y las reglas de decisi√≥n**. RuleFit es particularmente √∫til cuando necesita un modelo que funcione bien *y* que le permita comprender el "porqu√©" detr√°s de sus predicciones.

La idea central de RuleFit es aprender un **modelo lineal disperso** que utiliza tanto las **caracter√≠sticas de entrada originales** como un conjunto de **"caracter√≠sticas de regla" reci√©n generadas** como predictores. Estas caracter√≠sticas de regla se derivan de un ensamblaje de √°rboles de decisi√≥n.

As√≠ es como funciona RuleFit:

1.  **Generaci√≥n del Ensamblaje de √Årboles:**
    * Primero, RuleFit entrena un **ensamblaje de √°rboles de decisi√≥n poco profundos** en el conjunto de datos. Esto se puede hacer utilizando algoritmos como *Gradient Boosting Machines* (GBM) o *Random Forests*. Los √°rboles suelen mantenerse poco profundos (por ejemplo, una profundidad m√°xima de 3-5) para producir reglas m√°s simples e interpretables.
    * Estos √°rboles se entrenan para predecir la variable objetivo, lo que significa que sus divisiones son significativas para la tarea.

2.  **Extracci√≥n de Reglas:**
    * Cada **ruta desde la ra√≠z hasta un nodo hoja** en cualquiera de los √°rboles de decisi√≥n generados se extrae y se convierte en una **regla de decisi√≥n binaria**.
    * Por ejemplo, si una ruta en un √°rbol es "si (Caracter√≠stica1 > 10) Y (Caracter√≠stica2 < 5)", esto se convierte en una regla.
    * Cada regla se trata entonces como una **nueva caracter√≠stica binaria** para cada instancia de datos: toma un valor de 1 si la instancia satisface todas las condiciones de la regla, y 0 en caso contrario.

3.  **Ajuste del Modelo Lineal con Regularizaci√≥n:**
    * Las caracter√≠sticas originales del conjunto de datos se combinan con estas caracter√≠sticas de regla binarias reci√©n creadas.
    * Luego, se ajusta un **modelo lineal disperso** (normalmente una **regresi√≥n Lasso**, que utiliza regularizaci√≥n L1) a este conjunto de caracter√≠sticas expandido.
    * La regularizaci√≥n Lasso realiza autom√°ticamente la **selecci√≥n de caracter√≠sticas**, estableciendo los coeficientes de las caracter√≠sticas originales y de las caracter√≠sticas de regla menos importantes en cero. Esto da como resultado un modelo final m√°s simple e interpretable que solo incluye los t√©rminos m√°s relevantes.

El modelo RuleFit final es una ecuaci√≥n lineal:
$\text{predicci√≥n} = \beta_0 + \sum_{j=1}^{p} \beta_j X_j + \sum_{k=1}^{R} \alpha_k r_k(X)$

Donde:
* $\beta_0$ es el intercepto.
* $\beta_j X_j$ son los t√©rminos para las caracter√≠sticas lineales originales $X_j$.
* $\alpha_k r_k(X)$ son los t√©rminos para las caracter√≠sticas de regla binarias $r_k(X)$.

Los coeficientes ($\beta_j$ y $\alpha_k$) indican la importancia y la direcci√≥n del efecto de cada caracter√≠stica original y de cada regla en la predicci√≥n.

**Aprendizaje Global vs. Local:**

RuleFit es un excelente ejemplo de un algoritmo que combina perfectamente las caracter√≠sticas de **aprendizaje global y local**.

* **Aspecto Global (Modelo Lineal Final y Estructura General):**
    * La etapa final de RuleFit consiste en ajustar un **√∫nico modelo lineal global** (con regularizaci√≥n Lasso). Este modelo lineal es un predictor global que combina las caracter√≠sticas originales y todas las caracter√≠sticas de regla generadas. Los coeficientes en este modelo lineal global definen la relaci√≥n general entre las caracter√≠sticas de entrada (originales y basadas en reglas) y la variable objetivo en todo el conjunto de datos.
    * Este modelo lineal proporciona una **comprensi√≥n global** de la importancia de las caracter√≠sticas y de c√≥mo contribuyen colectivamente a la predicci√≥n.

* **Aspecto Local (Caracter√≠sticas de Regla y Efectos de Interacci√≥n):**
    * El poder de RuleFit para manejar relaciones no lineales e interacciones proviene de su **aspecto local**: las **reglas de decisi√≥n**. Cada regla, extra√≠da de una ruta en un √°rbol de decisi√≥n, define una **subregi√≥n espec√≠fica** o "vecindario" del espacio de caracter√≠sticas. Por ejemplo, una regla "SI la edad es > 30 Y el ingreso es < 50k" captura una condici√≥n local muy espec√≠fica.
    * Al incluir estas caracter√≠sticas de regla binarias, el modelo lineal puede aprender efectivamente **diferentes relaciones lineales dentro de diferentes regiones locales** definidas por las reglas. Estas reglas capturan expl√≠citamente los **efectos de interacci√≥n** entre caracter√≠sticas que un modelo lineal est√°ndar pasar√≠a por alto.
    * Esto es similar a tener un **modelo local (impl√≠citamente, una constante o un modelo lineal simple dentro de la regi√≥n de la regla)** que se activa cuando se cumplen sus condiciones, lo que permite que el modelo lineal global adapte sus predicciones bas√°ndose en estos patrones locales.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n y regresi√≥n)",
  "‚úÖ Num√©rica o categ√≥rica seg√∫n el tipo de problema",
  "‚úÖ Variables num√©ricas y categ√≥ricas",
  "‚úÖ Modela relaciones no lineales a trav√©s de reglas y combinaciones lineales",
  "‚ùå No es modelo param√©trico cl√°sico, no se eval√∫a normalidad",
  "‚ùå No aplica directamente",
  "‚ùå No aplica",
  "‚ö†Ô∏è Puede ser sensible a outliers, pero menos que modelos lineales puros",
  "‚ö†Ô∏è Puede verse afectado, se recomienda an√°lisis previo",
  "‚ö†Ô∏è Interpretabilidad moderada: combina reglas f√°ciles con coeficientes lineales",
  "‚ö†Ô∏è Moderado, depende del n√∫mero de reglas generadas",
  "‚úÖ Se puede validar con validaci√≥n cruzada",
  "‚ùå No funciona bien en datasets muy peque√±os o con relaciones altamente complejas sin reglas claras"
)

detalles <- c(
  "Combina √°rboles de decisi√≥n para generar reglas y luego aplica regresi√≥n lineal para asignar pesos a estas reglas.",
  "Puede usarse para problemas de regresi√≥n o clasificaci√≥n.",
  "Admite variables categ√≥ricas y num√©ricas sin grandes restricciones.",
  "Captura tanto efectos lineales como interacciones no lineales v√≠a reglas extra√≠das.",
  "No asume distribuci√≥n normal de errores.",
  "No requiere independencia estricta entre observaciones.",
  "No requiere homoscedasticidad.",
  "Puede mitigar el impacto de outliers mediante regularizaci√≥n.",
  "Multicolinealidad puede afectar coeficientes pero el modelo regulariza para evitarlo.",
  "Las reglas extra√≠das facilitan la interpretaci√≥n frente a otros modelos complejos.",
  "La eficiencia depende del n√∫mero de reglas y tama√±o de datos.",
  "Validaci√≥n cruzada ayuda a evitar sobreajuste y seleccionar hiperpar√°metros.",
  "Puede fallar si las reglas generadas no capturan bien la relaci√≥n o en datos ruidosos."
)

tabla_rulefit <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_rulefit %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision rule fit",
             subtitle = "Rule Fit")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Zero Rule (ZeroR)  {-}    

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Rule-System/Rule Fit.png"))
```

**Zero Rule (ZeroR)** es el algoritmo de **clasificaci√≥n supervisada** m√°s simple imaginable. No utiliza ninguna de las caracter√≠sticas predictoras en el conjunto de datos para hacer sus predicciones. En su lugar, simplemente **predice la clase m√°s frecuente (mayoritaria)** que se observa en el conjunto de datos de entrenamiento.

**C√≥mo funciona ZeroR:**   

1.  **Conteo de Frecuencias:** El algoritmo cuenta las ocurrencias de cada clase en el conjunto de datos de entrenamiento.
2.  **Identificaci√≥n de la Clase Mayoritaria:** Identifica la clase que tiene la mayor frecuencia (es decir, la clase que aparece m√°s veces).
3.  **Predicci√≥n Universal:** Para cualquier nueva instancia, ZeroR simplemente predice esta clase mayoritaria.

**Ejemplo:** Si en un conjunto de datos para predecir si un cliente "comprar√°" o "no comprar√°" un producto, el 70% de los clientes en el conjunto de entrenamiento "no compraron" y el 30% "compraron", ZeroR predecir√° "no comprar√°" para *todos* los nuevos clientes. Su precisi√≥n en el conjunto de entrenamiento ser√≠a del 70%.

**¬øPor qu√© es importante ZeroR?**  

Aunque ZeroR no tiene ning√∫n poder predictivo real en el sentido de aprender patrones complejos de los datos, es **fundamentalmente importante en Machine Learning como una l√≠nea base (benchmark)**.

* **Punto de Referencia:** Cualquier algoritmo de clasificaci√≥n m√°s sofisticado debe superar la precisi√≥n de ZeroR para ser considerado √∫til. Si un modelo complejo tiene una precisi√≥n inferior a la de ZeroR, significa que el modelo no est√° aprendiendo nada significativo de los datos, o incluso est√° aprendiendo patrones incorrectos.
* **Detecci√≥n de Sesgos de Clase:** En conjuntos de datos desequilibrados (donde una clase es mucho m√°s frecuente que otras), ZeroR puede lograr una precisi√≥n aparentemente alta. Esto resalta la importancia de usar m√©tricas de evaluaci√≥n m√°s all√° de la simple precisi√≥n en esos casos (como precisi√≥n, recall, F1-score, o AUC-ROC), ya que una alta precisi√≥n de ZeroR podr√≠a ser enga√±osa.
* **Simplicidad Extrema:** Sirve como el punto de partida m√°s b√°sico para entender c√≥mo los algoritmos de clasificaci√≥n intentan mejorar sobre una suposici√≥n trivial.

**Aprendizaje Global vs. Local:**

ZeroR es un modelo de **aprendizaje puramente global**.

* **Aspecto Global:** ZeroR calcula una √∫nica estad√≠stica (la clase mayoritaria) a partir de todo el conjunto de datos de entrenamiento y aplica esta predicci√≥n **uniformemente a todas las instancias**, sin importar sus caracter√≠sticas individuales o su ubicaci√≥n en el espacio de datos. No hay ninguna adaptaci√≥n local o consideraci√≥n de subregiones del espacio de caracter√≠sticas. El modelo es una √∫nica regla global e inmutable.

* **Sin Modelado de Relaciones:** Al ignorar todas las caracter√≠sticas de entrada, ZeroR no modela ninguna relaci√≥n, lineal o no lineal, entre los predictores y la variable objetivo. Su conocimiento se limita a la distribuci√≥n marginal de la clase de salida.

En resumen, ZeroR es el clasificador m√°s simple y sirve como un punto de referencia crucial para evaluar el rendimiento de modelos de Machine Learning m√°s avanzados. Su naturaleza es inherentemente global, ya que aplica una √∫nica decisi√≥n derivada del patr√≥n m√°s frecuente en todo el conjunto de datos.

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n y regresi√≥n)",
  "‚úÖ Categ√≥rica (modo) o num√©rica (media)",
  "‚ùå No utiliza predictores",
  "‚ùå No considera relaciones, predice constante",
  "‚ùå No aplica (no hay residuos de regresi√≥n)",
  "‚ùå No aplica (no hay modelo estructurado)",
  "‚ùå No aplica",
  "‚ùå No aplica (no hay influencia de valores at√≠picos)",
  "‚ùå No aplica (no hay predictores)",
  "‚úÖ Alta, ya que solo predice un valor fijo",
  "‚úÖ Extremadamente r√°pido",
  "‚ö†Ô∏è Se puede usar como baseline en validaci√≥n",
  "‚ùå No debe usarse como modelo final salvo como referencia base"
)

detalles <- c(
  "Modelo supervisado trivial que predice el valor m√°s frecuente (clasificaci√≥n) o promedio (regresi√≥n) de la variable respuesta.",
  "Funciona para variable respuesta categ√≥rica (modo) o continua (media).",
  "No utiliza ninguna variable predictora; solo la respuesta.",
  "No aprende relaciones, √∫til solo como l√≠nea base de comparaci√≥n.",
  "No genera residuos, pues predice una constante.",
  "No hay estructura de error o modelo que se eval√∫e.",
  "No hay dispersi√≥n de errores porque no hay ajuste.",
  "Outliers no afectan porque el modelo predice una constante global.",
  "No existe relaci√≥n entre predictores, as√≠ que no aplica multicolinealidad.",
  "F√°cil de interpretar: siempre predice lo mismo.",
  "Modelo extremadamente simple y r√°pido de calcular.",
  "Sirve como l√≠nea base para comparar modelos m√°s complejos.",
  "In√∫til para hacer predicciones significativas; solo sirve como referencia comparativa."
)

tabla_zeror <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)  

tabla_zeror %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir decision ZeroR",
             subtitle = "Zero Rule (ZeroR)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```







