# üß¨ 6. Modelos Bayesianos {-}  

**Ejemplos:** Naive Bayes, Redes Bayesianas.  
**Uso:** Ideales para **clasificaci√≥n r√°pida**, especialmente en escenarios con **supuestos simples** sobre los datos. Son muy populares en tareas de **procesamiento de texto** y **detecci√≥n de spam**.  
**Ventajas:** Son modelos **muy r√°pidos** de entrenar y predecir, y est√°n s√≥lidamente **fundamentados en la teor√≠a de probabilidad**.  
**Limitaciones:** La principal es que **asumen independencia** entre las variables predictoras, lo cual no siempre se cumple en la realidad y puede afectar su precisi√≥n en ciertos problemas.  

---

## Averaged One - Dependence Estimators (AODE)  {-}    

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Bayesian/AODE.png"))
```

**Averaged One-Dependence Estimators (AODE)** es un algoritmo de **clasificaci√≥n supervisada** que pertenece a la familia de los clasificadores basados en **modelos bayesianos**. Es una mejora sobre el cl√°sico **Naive Bayes (NB)**, dise√±ado para superar la limitaci√≥n clave de NB: la **asunci√≥n de independencia condicional** estricta entre las variables predictoras (atributos) dado el valor de la clase. Esta suposici√≥n, aunque simplifica mucho el c√°lculo y permite a Naive Bayes ser muy eficiente, rara vez se cumple en la realidad y puede llevar a una p√©rdida de precisi√≥n.

AODE relaja parcialmente la suposici√≥n de independencia de Naive Bayes al considerar que **cada atributo es dependiente, como m√°ximo, de un solo otro atributo** (adem√°s de la variable de clase). En lugar de construir un √∫nico modelo de √°rbol de dependencia (como en el √Årbol de Dependencia de Atributos - ADTree), AODE construye una **colecci√≥n de clasificadores "One-Dependence" (ODE)** y luego **promedia sus predicciones**.

El funcionamiento de AODE se puede resumir as√≠:

1.  **Generaci√≥n de Clasificadores ODE:** Para cada atributo predictivo $A_i$ en el conjunto de datos (que cumpla ciertos criterios, como tener suficientes instancias), AODE construye un clasificador ODE. Este clasificador asume que todos los dem√°s atributos son condicionalmente independientes de $A_i$ dado la clase. En otras palabras, se estima la probabilidad condicional de cada atributo $A_j$ dado la clase $C$ y el atributo $A_i$: $P(A_j | C, A_i)$.
2.  **Ponderaci√≥n y Promedio:** Cuando se hace una predicci√≥n para una nueva instancia, AODE calcula la probabilidad de cada clase para cada uno de los clasificadores ODE generados. Luego, estas probabilidades se combinan (t√≠picamente promediando) para obtener una predicci√≥n final.

Al promediar las predicciones de m√∫ltiples modelos ODE, AODE logra mitigar el sesgo introducido por la suposici√≥n de independencia estricta de Naive Bayes, a menudo obteniendo un mejor rendimiento sin incurrir en una complejidad computacional excesiva.


**Aprendizaje Global vs. Local:**

Averaged One-Dependence Estimators (AODE) es un modelo que se clasifica como de **aprendizaje global**, aunque con una estructura que busca capturar dependencias que tienen una naturaleza m√°s "local" en el contexto de las relaciones entre atributos.

* **Aspecto Global:** AODE construye un conjunto de modelos (los ODEs) que son entrenados sobre la **totalidad del conjunto de datos** para estimar las probabilidades condicionales. La combinaci√≥n de estas probabilidades (el promedio) para llegar a una predicci√≥n final es una regla que se aplica de manera consistente a cualquier nueva observaci√≥n. Los par√°metros de cada clasificador ODE (las probabilidades condicionales) se estiman de manera global a partir de las frecuencias observadas en todo el conjunto de entrenamiento.

* **Matiz (Captura de Dependencias Locales):** Aunque el enfoque general es global, la raz√≥n por la que AODE es m√°s potente que Naive Bayes radica en su capacidad para modelar **dependencias entre atributos**. Cada clasificador ODE considera que un atributo espec√≠fico tiene una dependencia directa de otro atributo, lo que es una forma de capturar una relaci√≥n "local" entre un par de atributos dado el contexto de la clase. Al promediar sobre estos m√∫ltiples modelos que capturan diferentes dependencias de "un solo par", AODE puede adaptarse mejor a las complejidades de los datos donde las relaciones no son puramente independientes y no se distribuyen linealmente, sin la necesidad de dividir el espacio de caracter√≠sticas en regiones discretas como los √°rboles de decisi√≥n. Sin embargo, la soluci√≥n final de promediado es un clasificador global que se aplica a toda la instancia de entrada.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n)",
  "‚úÖ Categ√≥rica",
  "‚úÖ Categ√≥ricas principalmente",
  "‚ö†Ô∏è Modela dependencias limitadas entre atributos (mejora sobre NB)",
  "‚ùå No aplica (no es regresi√≥n)",
  "‚úÖ Requiere independencia entre instancias",
  "‚ùå No aplica",
  "‚ö†Ô∏è Puede verse afectado por outliers si se usan variables num√©ricas sin tratamiento",
  "‚úÖ Menos afectado que Naive Bayes por dependencias entre atributos",
  "‚ö†Ô∏è Moderadamente interpretable (combinaci√≥n de varios modelos NB con 1 dependencia)",
  "‚ö†Ô∏è M√°s costoso que NB, pero a√∫n eficiente",
  "‚úÖ Puede validarse mediante k-fold cross-validation",
  "‚ùå Desempe√±a mal con muchos atributos irrelevantes o con pocos datos por combinaci√≥n de atributos"
)

detalles <- c(
  "Clasificador bayesiano que promedia modelos con una √∫nica dependencia entre pares de atributos para mejorar sobre Naive Bayes.",
  "Dise√±ado para problemas de clasificaci√≥n con clases categ√≥ricas.",
  "Se usa t√≠picamente con variables categ√≥ricas, aunque puede adaptarse a discretizadas.",
  "Relaja el supuesto de independencia total de Naive Bayes permitiendo una √∫nica dependencia por atributo.",
  "No es un modelo de regresi√≥n, por lo que no aplica el supuesto de normalidad de residuos.",
  "Las observaciones deben ser independientes para que las estimaciones sean v√°lidas.",
  "No supone homoscedasticidad debido a su naturaleza probabil√≠stica.",
  "Los valores at√≠picos pueden afectar la calidad de la estimaci√≥n de probabilidades.",
  "Tolera mejor la multicolinealidad al permitir dependencias limitadas entre atributos.",
  "La interpretaci√≥n es m√°s compleja que NB, pero a√∫n comprensible por su estructura promedio.",
  "Requiere m√°s tiempo de c√≥mputo que NB, pero sigue siendo razonablemente eficiente.",
  "La validaci√≥n cruzada es √∫til para evaluar el desempe√±o y generalizaci√≥n del modelo.",
  "El rendimiento cae si hay muchos atributos irrelevantes o datos escasos por combinaci√≥n de atributos."
)

tabla_aode <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_aode %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir AODE",
             subtitle = "Averaged One - Dependence Estimators (AODE)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```




## Bayesian Network (BN)  {-}    

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Bayesian/BN.png"))
```

Una **Red Bayesiana (BN)**, tambi√©n conocida como **Red Bayesiana Causal** o **Modelo Gr√°fico Dirigido Ac√≠clico (DAG)**, es un modelo probabil√≠stico que representa un conjunto de **variables y sus relaciones de dependencia condicional** utilizando un **grafo dirigido ac√≠clico**. En este grafo:

* **Nodos:** Representan las variables aleatorias (pueden ser discretas o continuas).
* **Arcos (flechas):** Representan las dependencias condicionales entre las variables. Una flecha de A a B significa que B depende directamente de A (A es "padre" de B). La ausencia de un arco entre dos nodos indica una independencia condicional.

La estructura del grafo de una Red Bayesiana permite visualizar y comprender las relaciones de causa y efecto (o asociaci√≥n) entre las variables. Junto con la estructura del grafo, una BN tambi√©n especifica las **distribuciones de probabilidad condicional (CPDs)** para cada nodo, dadas las combinaciones de estados de sus nodos padre. Por ejemplo, si un nodo tiene padres, se define la probabilidad de sus valores para cada combinaci√≥n de valores de sus padres.

Las Redes Bayesianas son potentes para:
* **Modelado de Conocimiento:** Codificar el conocimiento experto o aprendido de los datos sobre c√≥mo interact√∫an las variables.
* **Inferencia Probabil√≠stica:** Calcular la probabilidad de que una variable tome un valor espec√≠fico, dadas las observaciones de otras variables (evidencia). Esto puede incluir diagn√≥stico (inferir causas a partir de efectos) o predicci√≥n (inferir efectos a partir de causas).
* **Aprendizaje de Estructura y Par√°metros:** Aprender la estructura del grafo (las dependencias) y las CPDs a partir de datos.

**Aprendizaje Global vs. Local:**

Una Red Bayesiana (BN) es fundamentalmente un modelo de **aprendizaje global** en su estructura general, pero con una fuerte base en el **aprendizaje local** de las dependencias.

* **Aspecto Global:** La **estructura del grafo** y el conjunto de **tablas de probabilidad condicional (CPDs)** forman un **modelo probabil√≠stico coherente y global** de la distribuci√≥n de probabilidad conjunta de todas las variables. Este modelo global puede ser utilizado para realizar inferencias sobre cualquier combinaci√≥n de variables en cualquier parte del espacio de datos. La red define c√≥mo la informaci√≥n fluye y c√≥mo las probabilidades se propagan a trav√©s de todas las variables, dando una visi√≥n hol√≠stica de las interacciones del sistema.

* **Aspecto Local (Dependencias y Parametrizaci√≥n):** Donde la BN tiene un fuerte componente local es en la **definici√≥n de las dependencias y la parametrizaci√≥n de las CPDs**. Cada nodo solo necesita conocer las probabilidades condicionales dadas sus **padres directos**. Esto es un principio de **independencia condicional local**: una variable es independiente de sus no-descendientes dado sus padres. Esto descompone un problema complejo de modelado de la distribuci√≥n conjunta en problemas m√°s peque√±os y manejables de modelar las dependencias locales. Por ejemplo, para estimar $P(X_i | Padres(X_i))$, solo se necesita informaci√≥n local relacionada con $X_i$ y sus padres, no con todas las dem√°s variables en la red. Esta capacidad de modelar dependencias de forma localizada, y luego ensamblarlas en un modelo global, permite a las BNs manejar relaciones no lineales y complejas de una manera estructurada y probabil√≠stica. Si los datos no se distribuyen linealmente, la estructura de la BN puede adaptarse para reflejar las relaciones no lineales entre las variables a trav√©s de sus arcos y CPDs.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado o no supervisado",
  "‚úÖ Categ√≥rica o continua (depende del tipo de red)",
  "‚úÖ Categ√≥ricas y/o continuas",
  "‚úÖ Modela relaciones condicionales entre variables (estructura dirigida)",
  "‚ùå No aplica (no hay residuos t√≠picos)",
  "‚ö†Ô∏è Depende de la estructura de la red",
  "‚ùå No aplica como en regresi√≥n cl√°sica",
  "‚ö†Ô∏è Puede ser sensible si afecta las probabilidades condicionales",
  "‚ö†Ô∏è Puede causar redundancia si no se ajusta bien la estructura",
  "‚úÖ Muy interpretables si se visualiza la red y se conocen las dependencias",
  "‚ö†Ô∏è Aprendizaje de estructura puede ser computacionalmente costoso",
  "‚úÖ Puede usarse validaci√≥n cruzada para evaluar rendimiento predictivo",
  "‚ùå Cuando hay muchas variables y poca informaci√≥n para definir relaciones"
)

detalles <- c(
  "Modelo probabil√≠stico que representa relaciones condicionales entre variables mediante un grafo dirigido ac√≠clico (DAG).",
  "Puede predecir una variable (modo supervisado) o descubrir estructura entre variables (modo no supervisado).",
  "Acepta variables mixtas, aunque muchas implementaciones requieren discretizaci√≥n.",
  "Cada nodo representa una variable y las conexiones modelan dependencias condicionales.",
  "No genera residuos como los modelos de regresi√≥n, por lo que no aplica este supuesto.",
  "Algunas estructuras pueden implicar independencia condicional; otras no.",
  "No se eval√∫a homoscedasticidad, pues no hay predicci√≥n de error num√©rico.",
  "Valores at√≠picos pueden sesgar las probabilidades estimadas si no se controlan.",
  "Si hay variables redundantes o fuertemente correlacionadas, se debe ajustar la estructura de la red para evitar errores.",
  "La red permite interpretar c√≥mo influyen unas variables sobre otras, ideal para razonamiento causal.",
  "El ajuste de par√°metros es eficiente, pero aprender la estructura de la red puede ser lento.",
  "Puede evaluarse el desempe√±o con k-fold o validaci√≥n simple en tareas supervisadas.",
  "Cuando no se tiene informaci√≥n previa o datos suficientes, la red puede no capturar relaciones reales."
)

tabla_bn <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_bn %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir BN",
             subtitle = "Bayesian Network (BN)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```



## Bayesian Belief Network (BBN)  {-} 

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Bayesian/BBN.png"))
```

Una **Red de Creencia Bayesiana (BBN)** es simplemente **otro t√©rmino para una Red Bayesiana (BN)**. No hay una diferencia fundamental entre ambos nombres; ambos se refieren al mismo tipo de modelo probabil√≠stico. La terminolog√≠a "Red de Creencia" a menudo enfatiza la capacidad del modelo para representar y actualizar "creencias" (probabilidades) sobre el estado de variables inciertas a medida que se introduce nueva evidencia.

Como ya se describi√≥, una BBN (o BN) es un **modelo gr√°fico probabil√≠stico dirigido ac√≠clico (DAG)** que representa un conjunto de **variables aleatorias** como **nodos** y sus **relaciones de dependencia condicional** como **arcos (flechas)**. La ausencia de un arco entre dos nodos indica una independencia condicional. Cada nodo est√° asociado con una **distribuci√≥n de probabilidad condicional (CPD)** que cuantifica la relaci√≥n de ese nodo con sus padres.

Las BBNs son herramientas poderosas para:
* **Modelar el conocimiento incierto:** Permiten representar c√≥mo diferentes factores interact√∫an bajo incertidumbre.
* **Inferencia probabil√≠stica:** Dada alguna evidencia (observaciones de algunas variables), la red puede calcular las probabilidades actualizadas de las otras variables. Esto es fundamental para el diagn√≥stico, la predicci√≥n y la toma de decisiones bajo incertidumbre.
* **Aprendizaje a partir de datos:** Las BBNs pueden ser aprendidas tanto en su estructura (c√≥mo se conectan los nodos) como en sus par√°metros (las CPDs) a partir de conjuntos de datos.


**Aprendizaje Global vs. Local:**

Al igual que una Red Bayesiana, una Red de Creencia Bayesiana es fundamentalmente un modelo de **aprendizaje global** en su formulaci√≥n general, pero se basa en la **especificaci√≥n local** de las dependencias probabil√≠sticas.

* **Aspecto Global:** La BBN como un todo representa la **distribuci√≥n de probabilidad conjunta global** de todas las variables en el sistema. Una vez que la estructura y las CPDs est√°n definidas, la red puede usarse para calcular cualquier probabilidad marginal o condicional de inter√©s, proporcionando una visi√≥n probabil√≠stica completa y coherente del dominio. Es una funci√≥n que mapea el espacio de todas las posibles combinaciones de variables a sus probabilidades, y se aplica de manera consistente en todo el espacio.

* **Aspecto Local (Definici√≥n de Dependencias):** La fortaleza y eficiencia de las BBNs radica en el principio de **independencia condicional local**. Cada variable (nodo) solo necesita tener su distribuci√≥n de probabilidad condicionada a sus **padres directos** en el grafo. No es necesario especificar las dependencias con todas las dem√°s variables en la red. Esta factorizaci√≥n de la distribuci√≥n conjunta en componentes locales (las CPDs) es lo que hace que las BBNs sean computacionalmente manejables y permite que el modelo capture **relaciones no lineales y complejas** entre las variables de una manera estructurada. Al modelar estas dependencias "locales" de forma expl√≠cita, la BBN puede representar con precisi√≥n c√≥mo la probabilidad de un evento cambia en funci√≥n de los eventos directamente relacionados, incluso si la relaci√≥n no es lineal.

En resumen, las Redes de Creencia Bayesianas son modelos globales que permiten modelar relaciones probabil√≠sticas complejas y no lineales al especificar dependencias de manera local entre las variables. Son herramientas poderosas para el razonamiento bajo incertidumbre y la toma de decisiones.

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado y no supervisado (estructuras probabil√≠sticas)",
  "‚úÖ Categ√≥rica o continua (depende de implementaci√≥n)",
  "‚úÖ Categ√≥ricas o continuas discretizadas",
  "‚úÖ Modela relaciones condicionales entre variables (gr√°ficamente)",
  "‚ùå No aplica (no es modelo de regresi√≥n lineal)",
  "‚úÖ Requiere independencia condicional entre nodos seg√∫n la red",
  "‚ùå No aplica",
  "‚ö†Ô∏è Puede ser sensible a outliers si se estiman mal las distribuciones",
  "‚úÖ Puede manejar correlaci√≥n entre variables de forma expl√≠cita en la red",
  "‚úÖ Alta interpretabilidad visual con grafos dirigidos ac√≠clicos",
  "‚ö†Ô∏è Costoso computacionalmente en grandes redes o aprendizaje estructural",
  "‚úÖ Validaci√≥n cruzada puede aplicarse en tareas supervisadas (clasificaci√≥n)",
  "‚ùå Mal rendimiento si hay muchas variables irrelevantes o dependencias no detectadas"
)

detalles <- c(
  "Modelo probabil√≠stico gr√°fico que representa relaciones condicionales entre variables mediante una red bayesiana (DAG).",
  "Puede usarse para clasificaci√≥n, predicci√≥n o inferencia probabil√≠stica.",
  "Se adapta a datos categ√≥ricos principalmente, pero tambi√©n se puede usar con discretizaci√≥n de continuas.",
  "Captura relaciones condicionales entre variables expl√≠citamente como conexiones dirigidas.",
  "No genera residuos como los modelos de regresi√≥n, por lo que la normalidad no aplica.",
  "Las dependencias condicionales deben estar bien modeladas en la estructura de la red.",
  "No hay un modelo de varianza/residuos tradicional como para aplicar homoscedasticidad.",
  "Distribuciones err√≥neas o mal estimadas pueden afectar resultados, especialmente con valores extremos.",
  "El modelo representa expl√≠citamente la correlaci√≥n entre variables mediante arcos.",
  "La estructura de la red permite ver c√≥mo interact√∫an las variables entre s√≠.",
  "El aprendizaje estructural y de par√°metros puede ser costoso en t√©rminos computacionales.",
  "Si se usa para clasificaci√≥n, la validaci√≥n cruzada es una forma est√°ndar de evaluaci√≥n.",
  "BBN requiere una buena estructura; datos mal preparados o muy ruidosos deterioran su capacidad explicativa."
)

tabla_bbn <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_bbn %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir BBN",
             subtitle = "Bayesian Belief Network (BBN)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```

## Bayesian Linear Regression {-}   

## Gaussian Naive Bayes (GNB) {-}   

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Bayesian/GNB.png"))
```

**Gaussian Naive Bayes (GNB)** es una variante del popular algoritmo **Naive Bayes (NB)**, utilizado para tareas de **clasificaci√≥n supervisada**. Es particularmente adecuado cuando las **variables predictoras (atributos) son de tipo continuo**. Al igual que todos los clasificadores Naive Bayes, GNB se basa en el **Teorema de Bayes** y, fundamentalmente, en la **suposici√≥n de independencia condicional** entre las variables predictoras, dado el valor de la clase.

La diferencia clave entre GNB y otras variantes de Naive Bayes (como Multinomial Naive Bayes o Bernoulli Naive Bayes) es la forma en que modela la **probabilidad de los atributos continuos**. Espec√≠ficamente:

1.  **Suposici√≥n de Distribuci√≥n Gaussiana:** GNB asume que los valores de cada atributo continuo, *dada una clase espec√≠fica*, siguen una **distribuci√≥n normal (Gaussiana)**. Es decir, para cada clase y cada atributo, se estima la media ($\mu$) y la desviaci√≥n est√°ndar ($\sigma$) de los valores de ese atributo dentro de esa clase.
2.  **C√°lculo de Probabilidades:** Cuando se necesita clasificar una nueva observaci√≥n, GNB utiliza las funciones de densidad de probabilidad (PDF) de estas distribuciones Gaussianas para calcular la probabilidad de observar el valor del atributo para cada clase.
3.  **Aplicaci√≥n del Teorema de Bayes:** Finalmente, utiliza el Teorema de Bayes para calcular la probabilidad posterior de cada clase, dadas las probabilidades de los atributos, y asigna la observaci√≥n a la clase con la probabilidad posterior m√°s alta.

A pesar de su suposici√≥n de independencia (que rara vez se cumple perfectamente en la pr√°ctica), GNB a menudo funciona sorprendentemente bien, especialmente en conjuntos de datos grandes o cuando las caracter√≠sticas son ruidosas. Su simplicidad y eficiencia computacional lo hacen un buen punto de partida para muchos problemas de clasificaci√≥n.

**Aprendizaje Global vs. Local:**

Gaussian Naive Bayes (GNB) es un modelo de **aprendizaje global**.

* **Aspecto Global:** GNB construye un **modelo probabil√≠stico global** de la relaci√≥n entre las caracter√≠sticas y las clases. Las medias y desviaciones est√°ndar de las distribuciones Gaussianas para cada atributo dentro de cada clase se estiman a partir de **todos los datos de entrenamiento**. La regla de clasificaci√≥n final, que asigna una nueva instancia a la clase m√°s probable, se basa en estas distribuciones param√©tricas globales y en el Teorema de Bayes, aplic√°ndose de manera uniforme en todo el espacio de caracter√≠sticas. No se ajustan modelos locales para diferentes vecindarios de datos.

* **Impacto de la Asunci√≥n de Independencia:** La suposici√≥n de independencia condicional (que los atributos son independientes entre s√≠ dado la clase) significa que GNB no intenta capturar interacciones complejas o no lineales entre las variables predictoras. Si bien esto simplifica dr√°sticamente el modelo y lo hace eficiente, tambi√©n implica que su capacidad para modelar relaciones no lineales entre *predictores* es limitada. Si los datos no se distribuyen linealmente y las interacciones entre los predictores son cruciales para la clasificaci√≥n, GNB podr√≠a no ser el modelo m√°s flexible. Sin embargo, su robustez ante la violaci√≥n de suposiciones y su velocidad lo mantienen como una opci√≥n valiosa en muchos escenarios.

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n)",
  "‚úÖ Categ√≥rica (clases)",
  "‚úÖ Num√©ricas (asume distribuci√≥n normal por clase)",
  "‚ùå No modela relaciones entre predictores (independencia asumida)",
  "‚ùå No aplica (no hay residuos como en regresi√≥n)",
  "‚úÖ Asume independencia condicional entre predictores",
  "‚úÖ Cada predictor se modela con varianza homog√©nea por clase",
  "‚ö†Ô∏è Sensible a outliers porque afectan media y varianza de la normal",
  "‚ö†Ô∏è Alta multicolinealidad viola el supuesto de independencia",
  "‚úÖ Altamente interpretable: muestra probabilidades y distribuci√≥n por clase",
  "‚úÖ Muy r√°pido y eficiente, incluso con grandes datasets",
  "‚úÖ Se puede validar f√°cilmente con k-fold o hold-out",
  "‚ùå Si los predictores no son aproximadamente normales por clase, el rendimiento baja"
)

detalles <- c(
  "Clasificador probabil√≠stico que asume que cada predictor sigue una distribuci√≥n normal dentro de cada clase.",
  "Se utiliza para predecir clases categ√≥ricas a partir de predictores continuos.",
  "Cada variable num√©rica se modela con una distribuci√≥n Gaussiana separada por clase.",
  "No considera correlaciones entre predictores; cada uno contribuye de manera independiente.",
  "No genera residuos como un modelo de regresi√≥n, as√≠ que no aplica normalidad de errores.",
  "El supuesto clave es independencia condicional entre predictores dado la clase.",
  "Cada variable tiene su propia media y varianza por clase, sin heterocedasticidad.",
  "Los valores at√≠picos pueden distorsionar los par√°metros estimados de la distribuci√≥n normal.",
  "Altamente correlacionadas violan la independencia condicional asumida y afectan rendimiento.",
  "F√°cil de explicar: se basa en la probabilidad de cada clase dado cada predictor.",
  "Uno de los algoritmos m√°s r√°pidos para clasificaci√≥n supervisada.",
  "Evaluaci√≥n est√°ndar con validaci√≥n cruzada o conjunto de prueba.",
  "Si las variables no tienen forma aproximadamente normal dentro de clases, el modelo puede clasificarlas mal."
)

tabla_gnb <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_gnb %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir GNB",
             subtitle = "Gaussian Naive Bayes (GNB)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Hidden Markov Models (HMMs) {-}   

## Kalman Filter {-}   

## Multinomial Naive Bayes (MNB) {-}   

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Bayesian/MNB.png"))
```

**Multinomial Naive Bayes (MNB)** es una variante del algoritmo **Naive Bayes** dise√±ada espec√≠ficamente para la **clasificaci√≥n de datos discretos**, y es particularmente popular en tareas de **procesamiento de lenguaje natural (NLP)**, como la clasificaci√≥n de texto (ej., spam/no spam, clasificaci√≥n de documentos por tema). Al igual que otras formas de Naive Bayes, se basa en el **Teorema de Bayes** y la **suposici√≥n clave de independencia condicional** entre las caracter√≠sticas, dado el valor de la clase.

La diferencia fundamental de MNB radica en que asume que las caracter√≠sticas (como el recuento de palabras en un documento de texto) provienen de una **distribuci√≥n multinomial**. Esto significa que:

1.  **Caracter√≠sticas de Recuento:** MNB es ideal para caracter√≠sticas que representan **frecuencias o recuentos** (ej., el n√∫mero de veces que aparece una palabra en un documento, el n√∫mero de veces que ocurre un evento).
2.  **Modelado de Probabilidades:** Para cada clase, MNB calcula la probabilidad de observar cada caracter√≠stica (ej., cada palabra del vocabulario) dado que la instancia pertenece a esa clase. Estas probabilidades se estiman a menudo utilizando **suavizado Laplace (o aditivo)** para evitar probabilidades de cero para palabras no vistas durante el entrenamiento.
3.  **Aplicaci√≥n del Teorema de Bayes:** Luego, para clasificar una nueva instancia, multiplica las probabilidades de las caracter√≠sticas (asumiendo independencia) por la probabilidad previa de cada clase, y elige la clase que tiene la probabilidad posterior m√°s alta.

MNB es altamente eficiente, escalable para grandes conjuntos de datos y a menudo sorprendentemente efectivo a pesar de su ingenua suposici√≥n de independencia, lo que lo convierte en una l√≠nea base s√≥lida para muchos problemas de clasificaci√≥n de texto.

**Aprendizaje Global vs. Local:**

Multinomial Naive Bayes (MNB) es un modelo de **aprendizaje global**.

* **Aspecto Global:** MNB construye un **modelo probabil√≠stico global** para la relaci√≥n entre las caracter√≠sticas discretas (como recuentos de palabras) y las clases. Las probabilidades de las caracter√≠sticas dadas las clases (y las probabilidades previas de las clases) se estiman a partir de **todos los datos de entrenamiento**. La regla de clasificaci√≥n final, basada en el Teorema de Bayes, se aplica de manera uniforme a cualquier nueva instancia en el espacio de caracter√≠sticas. No se ajustan modelos locales para diferentes vecindarios de datos; en su lugar, se utilizan las mismas probabilidades estimadas globalmente para todas las predicciones.

* **Impacto de la Asunci√≥n de Independencia:** La suposici√≥n de independencia condicional entre las caracter√≠sticas (ej., que la presencia de una palabra no influye en la probabilidad de otra palabra dada la categor√≠a del documento) es una simplificaci√≥n global. Si bien esta simplicidad permite que MNB sea muy eficiente y robusto a veces, tambi√©n significa que no puede capturar interacciones complejas o dependencias no lineales entre las caracter√≠sticas en el mismo sentido que modelos m√°s avanzados. Sin embargo, en muchas aplicaciones como la clasificaci√≥n de texto, donde la frecuencia individual de las palabras es muy informativa, esta suposici√≥n es lo suficientemente robusta para un buen rendimiento. Es un modelo que asume una estructura de probabilidad global y la aplica consistentemente.

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n)",
  "‚úÖ Categ√≥rica (clases)",
  "‚úÖ Discretas, conteos (ej. frecuencia de palabras)",
  "‚ùå No modela relaciones entre predictores (asume independencia condicional)",
  "‚ùå No aplica (no hay residuos)",
  "‚úÖ Asume independencia condicional entre predictores",
  "‚ùå No aplica (no se modela varianza)",
  "‚ö†Ô∏è Menos sensible a outliers que Gaussian NB, pero a√∫n puede verse afectado",
  "‚ö†Ô∏è Multicolinealidad viola el supuesto de independencia y puede degradar el rendimiento",
  "‚úÖ Muy interpretable: probabilidades por clase y variable",
  "‚úÖ Extremadamente eficiente en problemas de texto y alta dimensi√≥n",
  "‚úÖ Puede usarse k-fold o validaci√≥n simple",
  "‚ùå No es adecuado para variables continuas o datos que no representen conteos"
)

detalles <- c(
  "Clasificador basado en probabilidad que modela la distribuci√≥n multinomial de conteos por clase.",
  "Usado t√≠picamente para clasificaci√≥n de texto, spam detection, y otros problemas con datos categ√≥ricos o de conteo.",
  "Funciona mejor con variables que representan frecuencia (n√∫mero de veces que aparece un t√©rmino).",
  "Asume que los predictores son independientes condicionalmente dados la clase, sin correlaci√≥n entre ellos.",
  "No hay residuos como en modelos de regresi√≥n, por lo tanto no aplica este supuesto.",
  "La independencia condicional de los predictores es un supuesto fundamental del modelo.",
  "Como no se modela la varianza expl√≠citamente, el supuesto de homoscedasticidad no aplica.",
  "Outliers tienen menor efecto porque se espera que los datos est√©n en formato de conteo (discretos).",
  "Predictores altamente correlacionados pueden afectar negativamente la precisi√≥n del modelo.",
  "La probabilidad condicional de cada clase y predictor es f√°cil de interpretar.",
  "Muy r√°pido incluso en datasets grandes con miles de caracter√≠sticas (como texto).",
  "La precisi√≥n puede evaluarse con validaci√≥n cruzada como en otros clasificadores.",
  "Si las variables son continuas o no reflejan bien los conteos, el modelo puede fallar."
)

tabla_mnb <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_mnb %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir MNB",
             subtitle = "Multinomial Naive Bayes (MNB)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```




## Naive Bayes (NB) {-}   

```{r, echo = FALSE,out.width='50%', fig.align='center'}
require(knitr)
knitr::include_graphics(paste0(here::here(), "/img/Bayesian/NB.png"))
```

**Naive Bayes (NB)** es un algoritmo de **clasificaci√≥n supervisada** popular y computacionalmente eficiente, basado en el **Teorema de Bayes** y una **fuerte (o "ingenua") suposici√≥n de independencia condicional** entre las caracter√≠sticas (variables predictoras) dado el valor de la clase. Esta suposici√≥n significa que el modelo asume que la presencia o ausencia de una caracter√≠stica particular no afecta la presencia o ausencia de otra caracter√≠stica, una vez que se conoce la clase.

A pesar de que esta suposici√≥n rara vez se cumple perfectamente en problemas del mundo real, Naive Bayes a menudo ofrece un **rendimiento sorprendentemente bueno**, especialmente en tareas de clasificaci√≥n de texto y con grandes conjuntos de datos. Su simplicidad y velocidad lo convierten en un excelente algoritmo de l√≠nea base.

El funcionamiento b√°sico de Naive Bayes es el siguiente:

1.  **C√°lculo de Probabilidades Previas:** Estima la probabilidad de cada clase en el conjunto de entrenamiento (ej., P(Clase A), P(Clase B)).
2.  **C√°lculo de Probabilidades de Verosimilitud:** Para cada caracter√≠stica y cada clase, calcula la probabilidad de que la caracter√≠stica tome un valor espec√≠fico, dado que la instancia pertenece a esa clase (ej., P(Caracter√≠stica X | Clase A)). Aqu√≠ es donde entran las diferentes variantes de Naive Bayes (Gaussian para caracter√≠sticas continuas, Multinomial para recuentos, Bernoulli para caracter√≠sticas binarias).
3.  **Aplicaci√≥n del Teorema de Bayes:** Para clasificar una nueva instancia, utiliza el Teorema de Bayes para combinar estas probabilidades y calcular la probabilidad posterior de cada clase, dadas las caracter√≠sticas de la nueva instancia. Finalmente, asigna la instancia a la clase con la probabilidad posterior m√°s alta.


**Aprendizaje Global vs. Local:**

Naive Bayes (NB) es un modelo de **aprendizaje puramente global**.

* **Aspecto Global:** Naive Bayes construye un **modelo probabil√≠stico global** que describe la relaci√≥n entre las caracter√≠sticas y las clases para todo el conjunto de datos. Las probabilidades previas de las clases y las probabilidades condicionales de las caracter√≠sticas dadas las clases se estiman a partir de **todos los datos de entrenamiento**. La regla de clasificaci√≥n resultante se aplica de manera uniforme a cualquier nueva instancia en el espacio de caracter√≠sticas, sin ajustar modelos locales para diferentes vecindarios de datos. El modelo aprende una distribuci√≥n de probabilidad que se asume v√°lida para todo el dominio.

* **Impacto de la Suposici√≥n de Independencia:** La "ingenuidad" del modelo, es decir, la suposici√≥n de independencia entre las caracter√≠sticas, es una simplificaci√≥n global. No intenta capturar interacciones complejas o no lineales entre las caracter√≠sticas en s√≠. Si bien esto puede ser una limitaci√≥n cuando las relaciones entre las caracter√≠sticas son muy intrincadas y no lineales, es precisamente esta suposici√≥n la que le otorga su eficiencia y robustez en muchos escenarios pr√°cticos. Es un modelo que asume una estructura de probabilidad global y la aplica de manera consistente.


```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (clasificaci√≥n)",
  "‚úÖ Categ√≥rica (clases)",
  "‚úÖ Categ√≥ricas o num√©ricas (seg√∫n variante del modelo)",
  "‚ùå Asume independencia condicional entre predictores",
  "‚ùå No aplica (no es regresi√≥n)",
  "‚úÖ Observaciones deben ser independientes",
  "‚ùå No se requiere homocedasticidad",
  "‚ö†Ô∏è Puede ser sensible si se usa con predictores num√©ricos y hay valores extremos",
  "‚úÖ No afectado por multicolinealidad debido a suponer independencia",
  "‚úÖ Alta, se pueden interpretar probabilidades y efectos de cada variable",
  "‚úÖ Muy r√°pido incluso con grandes conjuntos de datos",
  "‚úÖ Puede usarse para afinar y evaluar desempe√±o del modelo",
  "‚ùå Bajo rendimiento si los predictores no son realmente independientes o las distribuciones asumidas no se cumplen"
)

detalles <- c(
  "Clasificador probabil√≠stico basado en el teorema de Bayes con asunci√≥n de independencia condicional entre predictores.",
  "Funciona para clasificaci√≥n en m√∫ltiples clases categ√≥ricas.",
  "Puede trabajar con variables categ√≥ricas (Multinomial NB) o num√©ricas (Gaussian NB).",
  "Supone que las variables predictoras son independientes entre s√≠ dentro de cada clase.",
  "No genera residuos en el sentido cl√°sico porque no es un modelo de regresi√≥n.",
  "Las observaciones deben ser independientes para que las probabilidades se combinen correctamente.",
  "No requiere igualdad de varianzas; Gaussian NB asume varianza igual por clase pero se puede ajustar.",
  "Los valores at√≠picos pueden distorsionar la estimaci√≥n de probabilidades si hay predictores num√©ricos.",
  "La independencia entre predictores hace que la multicolinealidad no sea problema.",
  "Los resultados pueden interpretarse en t√©rminos de probabilidades a posteriori por clase.",
  "Muy eficiente para entrenamiento y predicci√≥n, incluso con muchos atributos.",
  "Puede validarse usando k-fold o leave-one-out para asegurar estabilidad del modelo.",
  "El supuesto fuerte de independencia condicional rara vez se cumple completamente, lo que puede afectar la precisi√≥n."
)

tabla_nb <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_nb %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir NB",
             subtitle = "Naive Bayes (NB)")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Particle Filter {-}   
