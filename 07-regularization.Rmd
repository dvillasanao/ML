# üßÆ **7. Regularizaci√≥n** {-}  

**Ejemplos:** L1 (Lasso), L2 (Ridge), Elastic Net   
**Cu√°ndo usarlo:**   

* Para evitar sobreajuste en modelos lineales o redes neuronales.
* Cuando tienes muchas variables (alta dimensionalidad).

**Ventajas:** Penaliza modelos complejos.   
**Limitaciones:** Puede eliminar variables √∫tiles si se usa en exceso.

---

## Ridge Regression  {-}   

```{r, echo = FALSE}
criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado (regresi√≥n)",
  "‚úÖ Num√©rica continua",
  "‚úÖ Num√©ricas (requiere estandarizaci√≥n)",
  "‚úÖ Lineal (como OLS)",
  "‚ö†Ô∏è Supuesto deseable pero no estricto",
  "‚úÖ Supuesto necesario",
  "‚úÖ Supuesto necesario",
  "‚ö†Ô∏è Puede verse afectado, pero menos que OLS",
  "‚úÖ Dise√±ado para mitigarla mediante penalizaci√≥n",
  "‚ö†Ô∏è Menos interpretable que OLS (coeficientes sesgados)",
  "‚úÖ Eficiente incluso con muchas variables",
  "‚úÖ Requiere validaci√≥n para ajustar par√°metro lambda",
  "‚ùå Si la relaci√≥n no es lineal o hay muchas variables irrelevantes"
)

detalles <- c(
  "Extensi√≥n de la regresi√≥n lineal que agrega penalizaci√≥n L2 para reducir sobreajuste y manejar multicolinealidad.",
  "Se utiliza cuando se desea predecir una variable num√©rica continua.",
  "Las variables deben ser num√©ricas y estar estandarizadas para que la penalizaci√≥n tenga sentido.",
  "Asume relaci√≥n lineal entre predictores y variable respuesta, como la regresi√≥n lineal.",
  "La normalidad es deseable para inferencia, pero no indispensable para predicci√≥n.",
  "Se espera independencia entre observaciones para que el modelo sea v√°lido.",
  "Es importante que los errores tengan varianza constante para predicciones fiables.",
  "Reduce varianza, pero valores extremos a√∫n pueden afectar los resultados.",
  "La penalizaci√≥n reduce varianza al achicar coeficientes, √∫til con predictores correlacionados.",
  "Coeficientes penalizados dificultan la interpretaci√≥n directa, pero mejoran estabilidad.",
  "R√°pido y adecuado para problemas con muchas variables; incluso p > n.",
  "Se usa validaci√≥n cruzada para elegir el mejor valor de lambda (par√°metro de regularizaci√≥n).",
  "No se recomienda cuando la relaci√≥n entre variables es no lineal o se requiere interpretaci√≥n clara."
)

tabla_ridge <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)

tabla_ridge %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir ridge",
             subtitle = "Ridge Regression")  %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Least Absolute Shrinkage and Selection Operator (LASSO)  {-}  

```{r, echo = FALSE}

```


## Elastic Net  {-}  

```{r, echo = FALSE}

```


## Least Angle Regression (LARS)  {-}   

```{r, echo = FALSE}

```


