[{"path":"index.html","id":"machine-learning","chapter":"Machine Learning","heading":"Machine Learning","text":"El machine learning ha experimentado un crecimiento significativo durante la √∫ltima d√©cada. Este desarrollo se atribuye tres factores fundamentales: el incremento sustancial en la disponibilidad de datos (Big Data), la evoluci√≥n de las capacidades computacionales y el perfeccionamiento de algoritmos avanzados. En la actualidad, el machine learning constituye un elemento transformador en diversos sectores: desde aplicaciones m√©dicas para el diagn√≥stico de enfermedades, hasta la optimizaci√≥n de estrategias financieras. Su capacidad anal√≠tica y de procesamiento de datos lo posiciona como un recurso esencial para la planificaci√≥n estrat√©gica, la optimizaci√≥n de procesos y el desarrollo de soluciones personalizadas.¬øCu√°ndo Implementar Machine Learning?La implementaci√≥n del machine learning resulta particularmente efectiva en los siguientes contextos:Disponibilidad de datos gran escala: La eficacia del modelo se incrementa proporcionalmente con la cantidad de datos relevantes disponibles.Presencia de relaciones complejas entre variables: En situaciones donde la multiplicidad de variables dificulta la definici√≥n de reglas convencionales.Necesidad de adaptaci√≥n din√°mica: Los sistemas de machine learning permiten una optimizaci√≥n continua mediante la incorporaci√≥n de nueva informaci√≥n.Requerimientos de automatizaci√≥n avanzada: Facilita la ejecuci√≥n de tareas complejas, desde el an√°lisis visual hasta la generaci√≥n de pron√≥sticos predictivos.","code":""},{"path":"index.html","id":"cuadro","chapter":"Machine Learning","heading":"üìå Cuadro","text":"","code":""},{"path":"index.html","id":"modelos-de-machine-learning","chapter":"Machine Learning","heading":"Modelos de Machine Learning","text":"Modelos disponibles en la paqueter√≠a caret en R.Enlace: https://topepo.github.io/caret/model-training--tuning.html","code":""},{"path":"regresi√≥n.html","id":"regresi√≥n","chapter":"üîç 1. Regresi√≥n","heading":"üîç 1. Regresi√≥n","text":"Ejemplos: Regresi√≥n Lineal Simple, Regresi√≥n Ridge, Regresi√≥n Lasso.Uso: Ideal para predecir valores num√©ricos continuos (como precios o temperaturas) y cuando esperas relaciones lineales entre tus variables.Ventajas: Es un modelo simple de entender y altamente interpretable.Limitaciones: Su desempe√±o es bajo cuando las relaciones entre las variables son lineales o muy complejas.","code":""},{"path":"regresi√≥n.html","id":"ordinary-least-squares-regression-olsr","chapter":"üîç 1. Regresi√≥n","heading":"Ordinary Least Squares Regression (OLSR)","text":"Ordinary Least Squares Regression (OLSR) en ROrdinary Least Squares Regression (OLSR) en PythonLa Regresi√≥n por M√≠nimos Cuadrados Ordinarios (OLS) es una t√©cnica fundamental en estad√≠stica y Machine Learning para modelar la relaci√≥n lineal entre una variable dependiente (predecir) y una o m√°s variables independientes. Su objetivo es encontrar la l√≠nea (o hiperplano) que mejor se ajusta los datos, minimizando la suma de los cuadrados de las diferencias entre los valores reales y los predichos por el modelo. Es decir, busca los coeficientes que hacen que la distancia (al cuadrado) de los puntos la l√≠nea sea m√≠nima.Los coeficientes de OLS se pueden calcular directamente con una f√≥rmula matem√°tica, sin necesidad de procesos iterativos complejos, bajo ciertos supuestos como la linealidad de la relaci√≥n y la independencia de los errores.En el contexto del aprendizaje global vs.¬†local, OLS es un ejemplo claro de un modelo de aprendizaje global. OLS busca una √∫nica ecuaci√≥n o un conjunto de coeficientes que describan la relaci√≥n entre las variables para todo el conjunto de datos. La l√≠nea o hiperplano que encuentra es una soluci√≥n global que se aplica de manera uniforme en todo el espacio de caracter√≠sticas. Esto la hace muy interpretable y computacionalmente eficiente, pero limitada si la relaci√≥n real entre las variables es estrictamente lineal en todo el dominio de los datos.","code":""},{"path":"regresi√≥n.html","id":"linear-regression","chapter":"üîç 1. Regresi√≥n","heading":"Linear Regression","text":"La Regresi√≥n Lineal es uno de los algoritmos m√°s fundamentales y ampliamente utilizados en el campo del Machine Learning y la estad√≠stica. Es un modelo supervisado que busca establecer una relaci√≥n lineal entre una variable de respuesta (o dependiente) continua y una o m√°s variables predictoras (o independientes).Concepto y Ecuaci√≥n:La idea central de la regresi√≥n lineal es encontrar la l√≠nea (o hiperplano en m√∫ltiples dimensiones) que mejor se ajusta los datos, de modo que se pueda predecir el valor de la variable dependiente bas√°ndose en los valores de las variables predictoras.Regresi√≥n Lineal Simple: Implica una √∫nica variable predictora. La ecuaci√≥n de la l√≠nea es:\n\\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]Donde:\n* \\(Y\\) es la variable de respuesta.\n* \\(X\\) es la variable predictora.\n* \\(\\beta_0\\) es el intercepto (el valor de \\(Y\\) cuando \\(X\\) es 0).\n* \\(\\beta_1\\) es el coeficiente de la pendiente (cu√°nto cambia \\(Y\\) por cada unidad de cambio en \\(X\\)).\n* \\(\\epsilon\\) es el t√©rmino de error o residual (la parte de \\(Y\\) que el modelo puede explicar).Regresi√≥n Lineal M√∫ltiple: Implica dos o m√°s variables predictoras. La ecuaci√≥n se extiende :\\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p + \\epsilon\\]Donde:\n* \\(X_1, X_2, ..., X_p\\) son las \\(p\\) variables predictoras.\n* \\(\\beta_1, \\beta_2, ..., \\beta_p\\) son los coeficientes de cada variable predictora.C√≥mo Funciona (M√≠nimos Cuadrados Ordinarios - OLS):El m√©todo m√°s com√∫n para estimar los coeficientes (\\(\\beta\\)s) en la regresi√≥n lineal es el de M√≠nimos Cuadrados Ordinarios (OLS). OLS funciona minimizando la suma de los cuadrados de los residuos. Un residuo es la diferencia entre el valor real de \\(Y\\) y el valor predicho por el modelo (\\(\\hat{Y}\\)).\\[\\text{Minimizar: } \\sum_{=1}^{n} (Y_i - \\hat{Y}_i)^2 = \\sum_{=1}^{n} (Y_i - (\\beta_0 + \\beta_1 X_{i1} + ... + \\beta_p X_{ip}))^2\\]Al minimizar esta suma de cuadrados, OLS encuentra los coeficientes que hacen que la l√≠nea de regresi√≥n est√© lo m√°s cerca posible de la mayor√≠a de los puntos de datos.Supuestos Clave:La validez de los resultados de la regresi√≥n lineal tradicional se basa en varios supuestos:Linealidad: La relaci√≥n entre las variables \\(X\\) y \\(Y\\) es lineal.Independencia: Las observaciones son independientes entre s√≠.Normalidad de los Residuos: Los residuos se distribuyen normalmente.Homocedasticidad: La varianza de los residuos es constante lo largo de todos los niveles de las variables predictoras.Multicolinealidad Perfecta: Las variables predictoras deben estar perfectamente correlacionadas entre s√≠.Uso y Limitaciones:La regresi√≥n lineal es popular por su simplicidad, interpretabilidad y por ser un buen punto de partida para muchos problemas de predicci√≥n. Sin embargo, su principal limitaci√≥n es que solo puede modelar relaciones lineales. Si la relaci√≥n subyacente entre las variables es lineal, una regresi√≥n lineal puede capturarla adecuadamente y dar resultados inexactos.Aprendizaje Global vs.¬†Local:La Regresi√≥n Lineal es un modelo de aprendizaje puramente global.Aspecto Global: La Regresi√≥n Lineal aprende un √∫nico conjunto de coeficientes que define una l√≠nea (o hiperplano) global que se aplica todo el espacio de caracter√≠sticas. Esta l√≠nea busca representar la relaci√≥n lineal promedio o general entre las variables predictoras y la variable de respuesta lo largo de todo el rango de los datos. La predicci√≥n para cualquier nueva instancia se realiza utilizando la misma ecuaci√≥n lineal, sin importar en qu√© parte del espacio de caracter√≠sticas se encuentre. hay adaptaciones o modelos separados para diferentes subregiones de los datos; el modelo es una funci√≥n que describe una tendencia general y global.Aspecto Global: La Regresi√≥n Lineal aprende un √∫nico conjunto de coeficientes que define una l√≠nea (o hiperplano) global que se aplica todo el espacio de caracter√≠sticas. Esta l√≠nea busca representar la relaci√≥n lineal promedio o general entre las variables predictoras y la variable de respuesta lo largo de todo el rango de los datos. La predicci√≥n para cualquier nueva instancia se realiza utilizando la misma ecuaci√≥n lineal, sin importar en qu√© parte del espacio de caracter√≠sticas se encuentre. hay adaptaciones o modelos separados para diferentes subregiones de los datos; el modelo es una funci√≥n que describe una tendencia general y global.Rigidez de la Linealidad: Debido su naturaleza global y lineal, la regresi√≥n lineal puede capturar relaciones lineales o interacciones complejas entre las variables predictoras de forma inherente. Si la relaci√≥n real en los datos es lineal, el modelo lineal intentar√° ajustarla con la mejor l√≠nea recta posible, lo que podr√≠a llevar un bajo rendimiento.Rigidez de la Linealidad: Debido su naturaleza global y lineal, la regresi√≥n lineal puede capturar relaciones lineales o interacciones complejas entre las variables predictoras de forma inherente. Si la relaci√≥n real en los datos es lineal, el modelo lineal intentar√° ajustarla con la mejor l√≠nea recta posible, lo que podr√≠a llevar un bajo rendimiento.","code":""},{"path":"regresi√≥n.html","id":"regresi√≥n-log√≠stica-logit","chapter":"üîç 1. Regresi√≥n","heading":"Regresi√≥n Log√≠stica (Logit)","text":"\nFigure 1: Elaboraci√≥n propia\nLa Regresi√≥n Log√≠stica es un modelo estad√≠stico usado principalmente para problemas de clasificaci√≥n binaria, donde el objetivo es predecir la probabilidad de que una instancia pertenezca una de dos clases (por ejemplo, ‚Äús√≠‚Äù o ‚Äú‚Äù, ‚Äú0‚Äù o ‚Äú1‚Äù). pesar de su nombre, predice un valor continuo, sino una probabilidad.Este modelo utiliza una funci√≥n sigmoide (o log√≠stica) para transformar una combinaci√≥n lineal de las variables de entrada en un valor entre 0 y 1, que se interpreta como una probabilidad. Los coeficientes del modelo se aprenden maximizando la verosimilitud de observar los datos, generalmente trav√©s de algoritmos como el descenso de gradiente.En el contexto del aprendizaje global vs.¬†local, la Regresi√≥n Log√≠stica es un modelo de aprendizaje global. Esto significa que busca un √∫nico conjunto de coeficientes que definen una frontera de decisi√≥n (un hiperplano) que se aplica todo el espacio de caracter√≠sticas para separar las clases. Asume una relaci√≥n lineal entre las variables de entrada y el logaritmo de la probabilidad, y una vez entrenado, usa esta relaci√≥n global para hacer predicciones en cualquier parte del espacio de datos. Si bien es eficiente y muy interpretable, su naturaleza global puede limitar su rendimiento en casos donde las fronteras de decisi√≥n son inherentemente lineales o muy complejas.","code":""},{"path":"regresi√≥n.html","id":"locally-estimated-scatterplot-smoothing-loess","chapter":"üîç 1. Regresi√≥n","heading":"Locally Estimated Scatterplot Smoothing (LOESS)","text":"LOESS (Locally Estimated Scatterplot Smoothing), o LOWESS, es una t√©cnica de regresi√≥n param√©trica para crear una curva suave que se ajusta los datos en un diagrama de dispersi√≥n. Su gran ventaja es que asume una forma funcional global espec√≠fica para la relaci√≥n entre las variables, lo que la hace muy flexible para identificar tendencias y patrones lineales.El principio de LOESS es simple: para estimar el valor suavizado en un punto, se seleccionan los puntos de datos cercanos (definido por un par√°metro de ‚Äúspan‚Äù o ancho de banda), se les asignan pesos (dando m√°s peso los puntos m√°s cercanos), y luego se ajusta un polinomio de bajo grado (com√∫nmente lineal o cuadr√°tico) esos puntos usando m√≠nimos cuadrados ponderados. Este proceso se repite para cada punto de inter√©s para construir la curva.En el contexto del aprendizaje global vs.¬†local, LOESS es un modelo de aprendizaje puramente local. Su flexibilidad reside en que ajusta m√∫ltiples modelos simples y locales (regresiones ponderadas) en diferentes vecindarios de los datos. busca una √∫nica ecuaci√≥n global que describa la relaci√≥n en todo el conjunto de datos. Esto le permite adaptarse maravillosamente las variaciones en las relaciones y curvaturas de los datos, lo que es especialmente √∫til cuando los datos se distribuyen linealmente. Sin embargo, su naturaleza local implica que produce una f√≥rmula expl√≠cita del modelo, y puede ser computacionalmente m√°s intensivo para conjuntos de datos muy grandes.","code":""},{"path":"regresi√≥n.html","id":"multivariate-adaptive-regression-splines-mars","chapter":"üîç 1. Regresi√≥n","heading":"Multivariate Adaptive Regression Splines (MARS)","text":"Multivariate Adaptive Regression Splines (MARS) es un algoritmo de regresi√≥n param√©trica que extiende los modelos lineales para manejar relaciones lineales y complejas. Desarrollado por Jerome Friedman, MARS construye su modelo al dividir el espacio de entrada en m√∫ltiples regiones y ajustar una funci√≥n lineal simple (o de orden superior) cada regi√≥n.El proceso de MARS consta de dos fases: una fase de adelante que a√±ade iterativamente funciones base (pares de funciones ‚Äúhinge‚Äù o bisagra) y nudos (puntos de corte) para capturar linealidades e interacciones entre variables, y una fase de atr√°s que poda las funciones base menos significativas utilizando criterios como la Validaci√≥n Cruzada Generalizada (GCV) para prevenir el sobreajuste. Esto permite MARS ser adaptable las particularidades de los datos.En el contexto del aprendizaje global vs.¬†local, MARS se sit√∫a como un modelo de aprendizaje adaptativo que combina aspectos globales y locales. Es ‚Äúlocal‚Äù en el sentido de que sus funciones base y nudos dividen el espacio de datos en regiones, y dentro de cada regi√≥n se aplica una relaci√≥n simple. Sin embargo, es ‚Äúglobal‚Äù porque la suma de todas estas funciones base forma una √∫nica ecuaci√≥n que describe la relaci√≥n en todo el conjunto de datos y se aplica de forma consistente. Esto significa que si los datos se distribuyen linealmente, MARS puede aprender y modelar estas relaciones complejas de forma adaptativa, encontrando autom√°ticamente d√≥nde y c√≥mo las relaciones cambian, ofreciendo una soluci√≥n que es tanto flexible como interpretable.","code":""},{"path":"regresi√≥n.html","id":"stepwise-regression","chapter":"üîç 1. Regresi√≥n","heading":"Stepwise Regression","text":"\nFigure 2: Elaboraci√≥n propia\nLa Regresi√≥n por Pasos (Stepwise Regression) es una t√©cnica para construir un modelo de regresi√≥n lineal (o veces otros modelos lineales generalizados) seleccionando las variables predictoras de forma iterativa y autom√°tica. Su objetivo es encontrar un subconjunto √≥ptimo de variables que mejore la capacidad predictiva del modelo sin incluir variables irrelevantes o redundantes. Esto ayuda simplificar el modelo, mejorar la interpretabilidad y reducir el riesgo de sobreajuste.Existen tres estrategias principales para la regresi√≥n por pasos:Selecci√≥n Hacia Adelante (Forward Selection):\nComienza con un modelo que incluye ninguna variable predictora (solo el intercepto).\nEn cada paso, eval√∫a todas las variables predictoras disponibles que a√∫n est√°n en el modelo.\nA√±ade al modelo la variable que, al ser incluida, produce la mayor mejora estad√≠stica (generalmente medida por un valor p bajo, un R-cuadrado ajustado mayor, o un criterio de informaci√≥n como AIC o BIC).\nEl proceso contin√∫a hasta que ninguna de las variables restantes mejora el modelo por encima de un umbral predefinido.\nComienza con un modelo que incluye ninguna variable predictora (solo el intercepto).En cada paso, eval√∫a todas las variables predictoras disponibles que a√∫n est√°n en el modelo.A√±ade al modelo la variable que, al ser incluida, produce la mayor mejora estad√≠stica (generalmente medida por un valor p bajo, un R-cuadrado ajustado mayor, o un criterio de informaci√≥n como AIC o BIC).El proceso contin√∫a hasta que ninguna de las variables restantes mejora el modelo por encima de un umbral predefinido.Eliminaci√≥n Hacia Atr√°s (Backward Elimination):\nComienza con un modelo que incluye todas las variables predictoras posibles.\nEn cada paso, eval√∫a las variables predictoras que actualmente est√°n en el modelo.\nElimina del modelo la variable que es menos significativa estad√≠sticamente (generalmente medida por un valor p alto, o una reducci√≥n en el R-cuadrado ajustado o un aumento en AIC/BIC).\nEl proceso contin√∫a hasta que la eliminaci√≥n de cualquier variable empeorar√≠a significativamente el modelo.\nComienza con un modelo que incluye todas las variables predictoras posibles.En cada paso, eval√∫a las variables predictoras que actualmente est√°n en el modelo.Elimina del modelo la variable que es menos significativa estad√≠sticamente (generalmente medida por un valor p alto, o una reducci√≥n en el R-cuadrado ajustado o un aumento en AIC/BIC).El proceso contin√∫a hasta que la eliminaci√≥n de cualquier variable empeorar√≠a significativamente el modelo.H√≠brida (Mixed / Bidirectional Stepwise):\nCombina la selecci√≥n hacia adelante y la eliminaci√≥n hacia atr√°s.\nEn cada paso, el algoritmo puede tanto a√±adir una variable si mejora el modelo, como eliminar una variable que ya est√° en el modelo si se vuelve redundante o significativa. Esto permite que el modelo reconsidere variables que fueron a√±adidas o eliminadas en pasos anteriores. Es el enfoque m√°s com√∫n y robusto.\nCombina la selecci√≥n hacia adelante y la eliminaci√≥n hacia atr√°s.En cada paso, el algoritmo puede tanto a√±adir una variable si mejora el modelo, como eliminar una variable que ya est√° en el modelo si se vuelve redundante o significativa. Esto permite que el modelo reconsidere variables que fueron a√±adidas o eliminadas en pasos anteriores. Es el enfoque m√°s com√∫n y robusto.Criterios de Selecci√≥n:La decisi√≥n de a√±adir o eliminar una variable en cada paso se basa en criterios estad√≠sticos, siendo los m√°s comunes:\n* Valores p: Umbrales para la significancia estad√≠stica de los coeficientes.\n* \\(R^2\\) ajustado: Mide la proporci√≥n de varianza explicada por el modelo, penalizando la inclusi√≥n de variables innecesarias.\n* Criterio de Informaci√≥n de Akaike (AIC): Penaliza la complejidad del modelo (n√∫mero de par√°metros) en relaci√≥n con su bondad de ajuste.\n* Criterio de Informaci√≥n Bayesiano (BIC): Similar al AIC, pero con una penalizaci√≥n m√°s fuerte por la complejidad.Ventajas y Desventajas:Ventajas: Puede ayudar construir modelos m√°s parsimoniosos, mejorar la interpretabilidad y reducir la multicolinealidad.Desventajas:\nSobreajuste: Puede llevar sobreajuste si se usa de forma acr√≠tica, ya que el algoritmo se optimiza para los datos de entrenamiento.\nProblemas de Significancia Estad√≠stica: Los valores p y otras m√©tricas pueden ser confiables debido la selecci√≥n de caracter√≠sticas basada en los datos.\nInestabilidad: El conjunto de variables seleccionadas puede ser muy sensible peque√±as perturbaciones en los datos o la elecci√≥n del criterio de selecci√≥n.\nIgnora el Conocimiento del Dominio: Puede seleccionar variables que son estad√≠sticamente significativas pero que carecen de sentido pr√°ctico o causal.\nManeja Interacciones Complejas: Es fundamentalmente un m√©todo para seleccionar variables para un modelo lineal y est√° dise√±ado para descubrir relaciones lineales o interacciones complejas.\nSobreajuste: Puede llevar sobreajuste si se usa de forma acr√≠tica, ya que el algoritmo se optimiza para los datos de entrenamiento.Problemas de Significancia Estad√≠stica: Los valores p y otras m√©tricas pueden ser confiables debido la selecci√≥n de caracter√≠sticas basada en los datos.Inestabilidad: El conjunto de variables seleccionadas puede ser muy sensible peque√±as perturbaciones en los datos o la elecci√≥n del criterio de selecci√≥n.Ignora el Conocimiento del Dominio: Puede seleccionar variables que son estad√≠sticamente significativas pero que carecen de sentido pr√°ctico o causal.Maneja Interacciones Complejas: Es fundamentalmente un m√©todo para seleccionar variables para un modelo lineal y est√° dise√±ado para descubrir relaciones lineales o interacciones complejas.Debido sus desventajas, la regresi√≥n por pasos se utiliza con m√°s cautela hoy en d√≠a. menudo se prefieren m√©todos de regularizaci√≥n (como Lasso o Elastic Net) para la selecci√≥n de caracter√≠sticas, ya que son m√°s estables y realizan la selecci√≥n de forma m√°s robusta.Aprendizaje Global vs.¬†Local:La Regresi√≥n por Pasos es un modelo de aprendizaje global.Aspecto Global: La regresi√≥n por pasos construye un √∫nico modelo de regresi√≥n lineal global que busca explicar la relaci√≥n entre las variables predictoras y la respuesta en todo el conjunto de datos. La selecci√≥n de variables se realiza para optimizar el rendimiento de este modelo global. Los coeficientes finales que se obtienen definen una funci√≥n lineal que se aplica de manera consistente cualquier nueva observaci√≥n, sin importar en qu√© parte del espacio de caracter√≠sticas se encuentre.Aspecto Global: La regresi√≥n por pasos construye un √∫nico modelo de regresi√≥n lineal global que busca explicar la relaci√≥n entre las variables predictoras y la respuesta en todo el conjunto de datos. La selecci√≥n de variables se realiza para optimizar el rendimiento de este modelo global. Los coeficientes finales que se obtienen definen una funci√≥n lineal que se aplica de manera consistente cualquier nueva observaci√≥n, sin importar en qu√© parte del espacio de caracter√≠sticas se encuentre.Proceso de Selecci√≥n (Global): Aunque el proceso es iterativo y a√±ade/elimina variables, la decisi√≥n en cada paso se basa en c√≥mo esa adici√≥n/eliminaci√≥n afecta la bondad de ajuste o la complejidad del modelo en todo el conjunto de datos. se ajustan modelos separados o locales para diferentes regiones.Proceso de Selecci√≥n (Global): Aunque el proceso es iterativo y a√±ade/elimina variables, la decisi√≥n en cada paso se basa en c√≥mo esa adici√≥n/eliminaci√≥n afecta la bondad de ajuste o la complejidad del modelo en todo el conjunto de datos. se ajustan modelos separados o locales para diferentes regiones.","code":""},{"path":"regresi√≥n.html","id":"support-vector-machine-svm","chapter":"üîç 1. Regresi√≥n","heading":"Support Vector Machine (SVM)","text":"Support Vector Machine (SVM) es un potente y vers√°til algoritmo de Machine Learning que se utiliza tanto para tareas de clasificaci√≥n como de regresi√≥n, aunque es m√°s conocido por su aplicaci√≥n en clasificaci√≥n. Su objetivo principal es encontrar el hiperplano √≥ptimo que separe las clases en el espacio de caracter√≠sticas con el margen m√°s grande posible. Los puntos de datos m√°s cercanos este hiperplano se llaman vectores de soporte, y son cruciales para definir la frontera de decisi√≥n.Para manejar datos que son linealmente separables, SVM utiliza el ‚Äútruco del kernel‚Äù. Este truco permite SVM mapear impl√≠citamente los datos un espacio de mayor dimensi√≥n donde las clases podr√≠an ser linealmente separables, sin necesidad de calcular expl√≠citamente las coordenadas. Funciones kernel comunes como el Radial Basis Function (RBF) o Gaussiano permiten SVM modelar fronteras de decisi√≥n lineales complejas en el espacio original de baja dimensi√≥n.En el contexto del aprendizaje global vs.¬†local, SVM se clasifica principalmente como un modelo de aprendizaje global. Esto se debe que busca un √∫nico hiperplano √≥ptimo (o una frontera de decisi√≥n lineal definida por el kernel) que se aplica la totalidad del espacio de caracter√≠sticas. Una vez entrenado, el modelo predice evaluando la posici√≥n de un nuevo punto con respecto esta frontera global. Sin embargo, hay un matiz ‚Äúlocal‚Äù en su funcionamiento: la determinaci√≥n de este hiperplano depende cr√≠ticamente solo de los vectores de soporte, que son los puntos de datos ‚Äúm√°s dif√≠ciles‚Äù cercanos la frontera. Los puntos que est√°n lejos del margen influyen en la definici√≥n del modelo. Aunque la frontera de decisi√≥n es una funci√≥n global que se aplica en todas partes, su construcci√≥n est√° influenciada por estos puntos localmente relevantes, permitiendo SVM adaptar su aproximaci√≥n incluso cuando las relaciones en los datos se distribuyen linealmente, al encontrar la separaci√≥n √≥ptima en un espacio transformado.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"√°rboles-de-decisi√≥n-y-derivados","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","text":"Ejemplos: √Årbol de Decisi√≥n, Random Forest, Gradient Boosting.Uso: Excelentes para datos tabulares con relaciones lineales, incluyendo variables categ√≥ricas y num√©ricas. Son una buena opci√≥n cuando la interpretabilidad es clave.Ventajas: Pueden manejar diversos tipos de datos y, los √°rboles individuales, son f√°ciles de interpretar.Limitaciones: Los √°rboles simples pueden sobreajustarse, y su rendimiento baja con datos muy ruidosos si se usan m√©todos de ensamble.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"c4.5","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"C4.5","text":"C4.5 es una extensi√≥n del algoritmo ID3, tambi√©n desarrollado por Ross Quinlan, y es uno de los algoritmos de √°rboles de decisi√≥n m√°s influyentes y ampliamente utilizados para tareas de clasificaci√≥n. Fue dise√±ado para abordar algunas de las limitaciones de su predecesor, ID3, y se ha convertido en un est√°ndar de facto en el aprendizaje autom√°tico para construir modelos predictivos interpretables.Al igual que ID3, C4.5 construye un √°rbol de clasificaci√≥n seleccionando en cada nodo el atributo que mejor divide el conjunto de datos. Sin embargo, en lugar de usar solo la ganancia de informaci√≥n, C4.5 utiliza la relaci√≥n de ganancia (Gain Ratio). La relaci√≥n de ganancia normaliza la ganancia de informaci√≥n por la entrop√≠a intr√≠nseca del atributo, lo que ayuda mitigar el sesgo de ID3 hacia atributos con muchos valores. Adem√°s, C4.5 introduce varias mejoras significativas:Manejo de atributos continuos: Puede discretizar atributos num√©ricos continuos dividiendo el rango en intervalos.Manejo de valores faltantes: Puede manejar datos con valores ausentes asignando una probabilidad fraccionada cada rama posible.Poda del √°rbol: Implementa una t√©cnica de poda para reducir el sobreajuste, lo que implica eliminar ramas del √°rbol que aportan significativamente la clasificaci√≥n o que representan ruido en los datos.En el contexto del aprendizaje global vs.¬†local, C4.5, al igual que ID3 y CART, opera como un sistema de aprendizaje local. La construcci√≥n del √°rbol se logra trav√©s de decisiones de divisi√≥n que se optimizan localmente en cada nodo, buscando la m√°xima homogeneidad o pureza en los subconjuntos resultantes. Esto le permite C4.5 manejar eficazmente relaciones lineales entre las variables independientes y dependientes. La idea es que, si los datos se distribuyen linealmente, el concepto de regresi√≥n (o clasificaci√≥n) se puede aplicar de forma efectiva mediante esta regresi√≥n ponderada localmente, donde el algoritmo divide el problema de aprendizaje global en m√∫ltiples problemas de aprendizaje m√°s peque√±os y simples. Al centrarse en divisiones √≥ptimas nivel de subconjuntos, C4.5 ofrece una alternativa robusta los m√©todos de aproximaci√≥n de funciones globales, que veces pueden fallar en proporcionar una buena aproximaci√≥n cuando la relaci√≥n entre las variables es lineal.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"c5.0","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"C5.0","text":"C5.0 es la versi√≥n m√°s reciente y avanzada de los algoritmos de √°rboles de decisi√≥n desarrollados por Ross Quinlan, sucediendo ID3 y C4.5. Es un algoritmo propietario (aunque se ofrece una versi√≥n de c√≥digo abierto bajo ciertas licencias) y es ampliamente reconocido por su rapidez, precisi√≥n y eficiencia en la construcci√≥n de √°rboles de decisi√≥n y reglas de clasificaci√≥n para tareas de clasificaci√≥n.Al igual que sus predecesores, C5.0 construye un √°rbol de clasificaci√≥n mediante la divisi√≥n recursiva de los datos en subconjuntos m√°s homog√©neos. Sin embargo, C5.0 incorpora mejoras significativas que lo hacen superior en muchos aspectos:Velocidad y eficiencia: Es notablemente m√°s r√°pido y m√°s eficiente en el uso de memoria que C4.5, lo que le permite manejar conjuntos de datos mucho m√°s grandes.Impulso (Boosting): C5.0 puede usar la t√©cnica de boosting (espec√≠ficamente, una variante de AdaBoost) para crear m√∫ltiples √°rboles de decisi√≥n y combinarlos para producir una predicci√≥n m√°s robusta y precisa. Esto reduce significativamente los errores de clasificaci√≥n y mejora la generalizaci√≥n.Poda mejorada: Ofrece t√©cnicas de poda m√°s sofisticadas para evitar el sobreajuste y producir √°rboles m√°s peque√±os y comprensibles.Manejo de valores faltantes y atributos continuos: Al igual que C4.5, maneja de manera efectiva valores faltantes y atributos num√©ricos continuos.Generaci√≥n de reglas: Adem√°s de √°rboles de decisi√≥n, C5.0 puede generar conjuntos de reglas de clasificaci√≥n concisas, que menudo son m√°s f√°ciles de interpretar que un √°rbol completo.En el contexto de la regresi√≥n localmente ponderada, C5.0, como los dem√°s algoritmos de √°rboles de decisi√≥n, opera bajo la premisa de un aprendizaje local. La construcci√≥n del √°rbol implica tomar decisiones de divisi√≥n √≥ptimas en cada nodo, bas√°ndose en la informaci√≥n local de ese subconjunto de datos. Si los datos se distribuyen linealmente, el concepto de regresi√≥n (o clasificaci√≥n, que es su enfoque principal) se puede aplicar eficazmente al dividir el problema de aprendizaje global en m√∫ltiples problemas de aprendizaje m√°s peque√±os y simples. Cada divisi√≥n en el √°rbol se puede ver como una forma de regresi√≥n ponderada localmente, donde el algoritmo se enfoca en aproximar la relaci√≥n dentro de un subespacio espec√≠fico del conjunto de datos. Esto convierte C5.0 en una potente alternativa los m√©todos de aproximaci√≥n de funciones globales, especialmente cuando la relaci√≥n entre las variables independientes y dependientes es lineal y se busca un modelo interpretable y robusto.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"classification-and-regression-tree-cart","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"Classification and Regression Tree (CART)","text":"Classification Regression Tree (CART) es un m√©todo param√©trico que se utiliza para construir √°rboles de decisi√≥n tanto para problemas de clasificaci√≥n como de regresi√≥n. La idea central es dividir recursivamente el espacio de las caracter√≠sticas en regiones m√°s peque√±as y manejables, creando as√≠ un modelo con forma de √°rbol que es f√°cil de interpretar.diferencia de los modelos lineales o algunos algoritmos de aprendizaje global, CART asume una relaci√≥n lineal entre las variables. En su lugar, el algoritmo identifica los mejores puntos de divisi√≥n en las variables predictoras para maximizar la homogeneidad de las respuestas dentro de cada regi√≥n resultante. Para problemas de clasificaci√≥n, esto se mide com√∫nmente con m√©tricas como la impureza Gini o la ganancia de informaci√≥n, mientras que para la regresi√≥n, se busca minimizar la suma de los cuadrados de los residuos.Mientras que muchos algoritmos (como las redes neuronales cl√°sicas o las m√°quinas de vectores de soporte) son sistemas de aprendizaje global que buscan minimizar una funci√≥n de p√©rdida √∫nica para todo el conjunto de datos, CART se puede considerar m√°s como un sistema de aprendizaje local. Construye el modelo tomando decisiones de divisi√≥n locales en cada nodo del √°rbol, lo que le permite capturar relaciones complejas y lineales en los datos. Esto es particularmente √∫til cuando una aproximaci√≥n de funci√≥n global √∫nica podr√≠a ser suficiente para modelar la relaci√≥n entre las variables. Una de las ventajas de CART es su capacidad para manejar diferentes tipos de datos (num√©ricos y categ√≥ricos) y su interpretabilidad, ya que la ruta desde la ra√≠z hasta una hoja del √°rbol representa un conjunto de reglas de decisi√≥n.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"chi-squared-automatic-interaction-detection-chaid","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"Chi-squared Automatic Interaction Detection (CHAID)","text":"\nFigure 3: https://select-statistics.co.uk/blog/chaid-chi-square-automatic-interaction-detector/\nChi-squared Automatic Interaction Detection (CHAID) es un algoritmo de √°rboles de decisi√≥n utilizado principalmente para tareas de clasificaci√≥n y, en menor medida, para la regresi√≥n (aunque se aplica m√°s com√∫nmente variables dependientes categ√≥ricas). La idea fundamental de CHAID es construir un √°rbol de decisi√≥n al encontrar las mejores divisiones en las variables predictoras que maximicen la significancia estad√≠stica de la relaci√≥n con la variable dependiente.diferencia de ID3, C4.5 o CART, que utilizan medidas de impureza como la entrop√≠a o el √≠ndice Gini, CHAID se basa en pruebas estad√≠sticas de chi-cuadrado (\\(\\chi^2\\)) para identificar las divisiones √≥ptimas. Cuando la variable dependiente es nominal o ordinal, CHAID eval√∫a cada variable predictora para encontrar la combinaci√≥n de categor√≠as que sea m√°s significativamente diferente de otras combinaciones en t√©rminos de la distribuci√≥n de la variable dependiente. El algoritmo fusiona las categor√≠as de una variable predictora si son significativamente diferentes, y luego selecciona la variable predictora y la divisi√≥n que resultan en el valor m√°s bajo de \\(p\\) (es decir, la mayor significancia estad√≠stica) de la prueba \\(\\chi^2\\). Para variables dependientes continuas, se utiliza una prueba F.En el contexto del aprendizaje global vs.¬†local, CHAID opera como un sistema de aprendizaje local. La construcci√≥n del √°rbol es un proceso iterativo y recursivo donde las decisiones de divisi√≥n se toman en cada nodo bas√°ndose en la significancia estad√≠stica local de la interacci√≥n entre las variables predictoras y la variable dependiente. Esto le permite CHAID descubrir relaciones complejas y lineales en los datos. La idea es que, si los datos se distribuyen linealmente, se puede aplicar el concepto de regresi√≥n (o clasificaci√≥n) de manera efectiva mediante lo que se denomina regresi√≥n ponderada localmente. Esto se logra al dividir el problema de aprendizaje global en m√∫ltiples problemas de aprendizaje m√°s peque√±os y simples, donde cada rama del √°rbol representa una regi√≥n del espacio de caracter√≠sticas donde las interacciones son evaluadas y modeladas localmente. Esto hace de CHAID una alternativa robusta los m√©todos de aproximaci√≥n de funciones globales, especialmente cuando se busca un modelo interpretable y se quieren identificar las interacciones entre las variables de una manera estad√≠sticamente rigurosa.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"conditional-decision-trees-conditional-inference-trees---cits","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"Conditional Decision Trees (Conditional Inference Trees - CITs)","text":"Conditional Decision Trees, often referred Conditional Inference Trees (CITs), represent class √°rboles de decisi√≥n que abordan una limitaci√≥n importante de los algoritmos de √°rboles de decisi√≥n tradicionales como CART, ID3, y C4.5: el sesgo en la selecci√≥n de variables. Mientras que los algoritmos tradicionales pueden favorecer variables predictoras con muchas categor√≠as o valores continuos (debido que estas variables tienen m√°s ‚Äúoportunidades‚Äù de generar una divisi√≥n que parezca √≥ptima), los CITs emplean un enfoque basado en pruebas estad√≠sticas para seleccionar la mejor divisi√≥n.La idea fundamental de los Conditional Decision Trees es que cada divisi√≥n en el √°rbol se basa en la significancia estad√≠stica de la asociaci√≥n entre las variables predictoras y la variable de respuesta. En lugar de seleccionar el atributo que maximiza una medida de impureza (como la ganancia de informaci√≥n o la impureza Gini), los CITs realizan una serie de pruebas de inferencia condicional (t√≠picamente pruebas de permutaci√≥n).El algoritmo opera de la siguiente manera:\n1. En cada nodo, se eval√∫a una hip√≥tesis nula de independencia entre cada variable predictora y la variable de respuesta.\n2. Se calcula el valor de \\(p\\) para cada variable predictora.\n3. La variable predictora con el valor de \\(p\\) m√°s peque√±o (es decir, la asociaci√≥n m√°s estad√≠sticamente significativa) es seleccionada para la divisi√≥n, siempre y cuando este valor de \\(p\\) sea menor que un umbral de significancia predefinido.\n4. Una vez seleccionada la variable, se encuentra la mejor divisi√≥n binaria (generalmente) dentro de esa variable para ese nodo.\n5. Este proceso se repite recursivamente hasta que haya m√°s variables significativas para dividir o se alcance un criterio de parada.En el contexto del aprendizaje global vs.¬†local, los Conditional Decision Trees se pueden considerar como un enfoque de aprendizaje local con un fuerte respaldo estad√≠stico. Aunque el √°rbol resultante es un modelo global, cada decisi√≥n de divisi√≥n se toma localmente bas√°ndose en la inferencia estad√≠stica sobre la relaci√≥n entre las variables en ese subconjunto de datos. Esto significa que si los datos se distribuyen linealmente, el concepto de regresi√≥n (o clasificaci√≥n) se aplica de forma efectiva mediante lo que se denomina regresi√≥n ponderada localmente. Al utilizar pruebas de significancia para las divisiones, los CITs evitan el problema de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en una √∫nica aproximaci√≥n global, ya que las divisiones se determinan por la evidencia estad√≠stica local. Esto los convierte en una alternativa robusta que ofrece una selecci√≥n de variables menos sesgada y modelos con una mayor interpretabilidad estad√≠stica.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"decision-stump","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"Decision Stump","text":"Un Decision Stump es el tipo de √°rbol de decisi√≥n m√°s simple y fundamental, compuesto por un √∫nico nodo de decisi√≥n (la ra√≠z) que se conecta directamente los nodos hoja. La idea es que un decision stump toma una decisi√≥n de clasificaci√≥n o regresi√≥n bas√°ndose en una sola caracter√≠stica o atributo de entrada.Aunque parece demasiado simple, la l√≥gica es que, pesar de su simplicidad, un decision stump identifica el mejor umbral o categor√≠a dentro de una √∫nica variable para separar los datos de la manera m√°s efectiva posible. Para problemas de clasificaci√≥n, esto significa encontrar la caracter√≠stica que, por s√≠ sola, maximice alguna medida de pureza (como la ganancia de informaci√≥n, la impureza Gini, o la significancia chi-cuadrado) o minimice el error de clasificaci√≥n. Para regresi√≥n, buscar√° el punto de divisi√≥n en una sola caracter√≠stica que minimice la suma de los cuadrados de los errores.En el contexto del aprendizaje local vs.¬†global, un decision stump es inherentemente un sistema de aprendizaje local. Su ‚Äúaprendizaje‚Äù se limita encontrar la mejor divisi√≥n dentro de una √∫nica variable, lo que es una forma extrema de regresi√≥n ponderada localmente. Si los datos se distribuyen linealmente, un decision stump puede por s√≠ mismo modelar relaciones complejas. Sin embargo, su valor reside en ser un modelo predictivo robusto por s√≠ mismo, sino en ser un ‚Äúclasificador d√©bil‚Äù o ‚Äúregresor d√©bil‚Äù que puede ser combinado en conjuntos de modelos (ensembles) m√°s potentes. Por ejemplo, los decision stumps son los bloques de construcci√≥n m√°s comunes para algoritmos de boosting como AdaBoost. En estos casos, m√∫ltiples decision stumps se entrenan secuencialmente, cada uno enfoc√°ndose en los errores que cometieron los stumps anteriores, sumando sus ‚Äúaprendizajes locales‚Äù para formar un modelo global m√°s preciso. Esto contrarresta la limitaci√≥n de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"iterative-dichotomiser-3-id3","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"Iterative Dichotomiser 3 (ID3)","text":"Iterative Dichotomiser 3 (ID3) es un algoritmo cl√°sico para construir √°rboles de decisi√≥n, dise√±ado principalmente para tareas de clasificaci√≥n. Fue uno de los primeros algoritmos de √°rboles de decisi√≥n desarrollados por Ross Quinlan. La idea central de ID3 es construir un √°rbol de clasificaci√≥n seleccionando en cada nodo del √°rbol el atributo que mejor divide el conjunto de datos en subconjuntos m√°s puros y homog√©neos.ID3 opera de forma iterativa y dicot√≥mica (aunque puede manejar atributos con m√°s de dos categor√≠as), dividiendo el conjunto de datos en cada paso bas√°ndose en el atributo m√°s informativo. La selecci√≥n del ‚Äúmejor‚Äù atributo se basa en m√©tricas de teor√≠a de la informaci√≥n, principalmente la ganancia de informaci√≥n (Information Gain). La ganancia de informaci√≥n mide la reducci√≥n en la entrop√≠a (una medida de la impureza o desorden de un conjunto de datos) que se logra al dividir los datos seg√∫n un atributo particular. El atributo con la mayor ganancia de informaci√≥n es elegido como el nodo de decisi√≥n en cada nivel del √°rbol.diferencia de los sistemas de aprendizaje global que buscan minimizar funciones de p√©rdida globales (como el error cuadr√°tico medio), ID3 es un algoritmo de aprendizaje local en el sentido de que toma decisiones de divisi√≥n √≥ptimas en cada nodo bas√°ndose en la informaci√≥n disponible en ese subconjunto de datos. Aunque la construcci√≥n del √°rbol es un proceso global, cada paso de la divisi√≥n se optimiza localmente para maximizar la pureza de los subconjuntos resultantes. Esto le permite ID3 capturar relaciones lineales entre las variables, ya que asume una distribuci√≥n lineal de los datos. En esencia, si los datos se distribuyen linealmente, se puede aplicar el concepto de regresi√≥n (o clasificaci√≥n, en este caso) de manera ponderada localmente al dividir el espacio de caracter√≠sticas en regiones m√°s manejables. Sin embargo, una desventaja de ID3 es que tiende favorecer atributos con muchos valores y puede ser propenso al sobreajuste.","code":""},{"path":"√°rboles-de-decisi√≥n-y-derivados.html","id":"m5-model-tree","chapter":"üå≤ 2. √Årboles de Decisi√≥n y Derivados","heading":"M5 (Model Tree)","text":"M5, menudo referida como M5‚Äô o M5P (su implementaci√≥n en el software Weka), es un algoritmo de √°rboles de decisi√≥n espec√≠ficamente dise√±ado para tareas de regresi√≥n, es decir, para predecir valores num√©ricos continuos. Desarrollado por Ross Quinlan en 1992 y luego mejorado por Wang y Witten en 1997, M5 se destaca de los √°rboles de regresi√≥n tradicionales (como los de CART que solo tienen valores constantes en las hojas) al incorporar modelos de regresi√≥n lineal en sus nodos hoja.La idea fundamental de M5 es combinar la interpretabilidad de un √°rbol de decisi√≥n con la capacidad predictiva de los modelos de regresi√≥n lineal. Funciona en dos etapas principales:Construcci√≥n del √Årbol: M5 construye un √°rbol de decisi√≥n de forma recursiva, similar otros algoritmos de √°rboles. Sin embargo, en lugar de usar medidas de impureza para clasificaci√≥n, utiliza la reducci√≥n de la desviaci√≥n est√°ndar (SDR) como criterio de divisi√≥n. El algoritmo selecciona el atributo y el punto de divisi√≥n que maximizan la reducci√≥n de la desviaci√≥n est√°ndar del valor objetivo en los subconjuntos resultantes. Este proceso contin√∫a hasta que el n√∫mero de instancias en un nodo es muy peque√±o o la desviaci√≥n est√°ndar es muy baja.Construcci√≥n del √Årbol: M5 construye un √°rbol de decisi√≥n de forma recursiva, similar otros algoritmos de √°rboles. Sin embargo, en lugar de usar medidas de impureza para clasificaci√≥n, utiliza la reducci√≥n de la desviaci√≥n est√°ndar (SDR) como criterio de divisi√≥n. El algoritmo selecciona el atributo y el punto de divisi√≥n que maximizan la reducci√≥n de la desviaci√≥n est√°ndar del valor objetivo en los subconjuntos resultantes. Este proceso contin√∫a hasta que el n√∫mero de instancias en un nodo es muy peque√±o o la desviaci√≥n est√°ndar es muy baja.Poda y Suavizado: Una vez construido el √°rbol inicial, M5 lo poda para evitar el sobreajuste. En lugar de reemplazar los nodos con un valor constante, los nodos hoja (y veces nodos internos) son reemplazados por modelos de regresi√≥n lineal multivariados. Estos modelos lineales se construyen utilizando los atributos relevantes para esa rama del √°rbol. Adem√°s, M5 aplica un proceso de suavizado para compensar las discontinuidades bruscas que podr√≠an surgir entre las predicciones de modelos lineales adyacentes. Este suavizado ajusta el valor predicho en una hoja bas√°ndose en las predicciones de los modelos en los nodos lo largo de la ruta desde la ra√≠z hasta esa hoja.Poda y Suavizado: Una vez construido el √°rbol inicial, M5 lo poda para evitar el sobreajuste. En lugar de reemplazar los nodos con un valor constante, los nodos hoja (y veces nodos internos) son reemplazados por modelos de regresi√≥n lineal multivariados. Estos modelos lineales se construyen utilizando los atributos relevantes para esa rama del √°rbol. Adem√°s, M5 aplica un proceso de suavizado para compensar las discontinuidades bruscas que podr√≠an surgir entre las predicciones de modelos lineales adyacentes. Este suavizado ajusta el valor predicho en una hoja bas√°ndose en las predicciones de los modelos en los nodos lo largo de la ruta desde la ra√≠z hasta esa hoja.En el contexto del aprendizaje global vs.¬†local, M5 es un h√≠brido interesante. Por un lado, la construcci√≥n del √°rbol se basa en decisiones de divisi√≥n locales, buscando la mejor reducci√≥n de la desviaci√≥n est√°ndar en cada nodo. Esto permite M5 modelar relaciones lineales, ya que ‚Äúsi los datos se distribuyen linealmente, se puede aplicar el concepto de regresi√≥n de manera ponderada localmente‚Äù. El √°rbol divide el problema de regresi√≥n global en m√∫ltiples subproblemas m√°s peque√±os. Por otro lado, al tener modelos de regresi√≥n lineal en las hojas, M5 incorpora un componente de aproximaci√≥n de funci√≥n local m√°s sofisticado que un simple valor constante. Estos modelos lineales son ‚Äúlocales‚Äù para la regi√≥n de datos que representa esa hoja, pero internamente son modelos globales para esa subregi√≥n. Esto permite M5 ofrecer una alternativa potente las aproximaciones de funciones puramente globales, especialmente cuando las relaciones entre las variables son complejas y se benefician de una combinaci√≥n de particionamiento del espacio y modelado lineal dentro de esas particiones.","code":""},{"path":"m√©todos-de-ensamble.html","id":"m√©todos-de-ensamble","chapter":"üåü 3. M√©todos de Ensamble","heading":"üåü 3. M√©todos de Ensamble","text":"Ejemplos: Random Forest, Gradient Boosting (XGBoost, LightGBM, AdaBoost).Uso: Excelentes para clasificaci√≥n y regresi√≥n en datos tabulares, especialmente en competencias de datos por su alto rendimiento.Ventajas: Ofrecen alta precisi√≥n y son muy robustos.Limitaciones: Pueden ser dif√≠ciles de interpretar y suelen ser computacionalmente m√°s costosos.","code":""},{"path":"m√©todos-de-ensamble.html","id":"adaptive-boosting-adaboost","chapter":"üåü 3. M√©todos de Ensamble","heading":"Adaptive Boosting (AdaBoost)","text":"AdaBoost (Adaptive Boosting) es uno de los algoritmos de boosting m√°s influyentes y el primero en ser propuesto con √©xito, desarrollado por Yoav Freund y Robert Schapire en 1995. Es una t√©cnica de aprendizaje conjunto (ensemble learning) utilizada principalmente para clasificaci√≥n, aunque sus principios pueden extenderse la regresi√≥n. La idea fundamental de AdaBoost es construir un modelo fuerte combinando secuencialmente las predicciones de m√∫ltiples clasificadores ‚Äúd√©biles‚Äù o ‚Äúbase‚Äù, y lo hace prestando m√°s atenci√≥n los ejemplos que los modelos anteriores clasificaron incorrectamente.El funcionamiento de AdaBoost se basa en un sistema de re-ponderaci√≥n de datos en cada iteraci√≥n:Inicializaci√≥n de Pesos: Se asigna un peso inicial igual cada ejemplo de entrenamiento.Entrenamiento del Clasificador D√©bil: En cada iteraci√≥n, se entrena un clasificador d√©bil (menudo un Decision Stump, que es un √°rbol de decisi√≥n de un solo nivel) en el conjunto de datos actual. Este clasificador se enfoca en minimizar el error ponderado.C√°lculo del Error Ponderado: Se calcula el error del clasificador d√©bil, teniendo en cuenta los pesos de los ejemplos. Los ejemplos mal clasificados tienen un mayor impacto en este error.Actualizaci√≥n de Pesos de Datos: Los pesos de los ejemplos mal clasificados por el clasificador actual son aumentados, mientras que los pesos de los ejemplos correctamente clasificados son disminuidos. Esto asegura que el siguiente clasificador d√©bil se enfoque m√°s en los ejemplos que son dif√≠ciles de clasificar.C√°lculo del Peso del Clasificador: Se asigna un peso (o ‚Äúcontribuci√≥n‚Äù) al clasificador d√©bil actual en funci√≥n de su precisi√≥n. Los clasificadores m√°s precisos reciben un peso mayor en la predicci√≥n final del conjunto.Combinaci√≥n de Predicciones: Las predicciones finales del modelo AdaBoost se obtienen mediante una suma ponderada de las predicciones de todos los clasificadores d√©biles.En el contexto del aprendizaje global vs.¬†local, AdaBoost es un sistema de aprendizaje global que se construye de manera iterativa partir de componentes de aprendizaje local. Cada clasificador d√©bil que se entrena en una iteraci√≥n puede verse como una forma de regresi√≥n ponderada localmente (o, m√°s precisamente, clasificaci√≥n ponderada localmente), ya que ajusta su enfoque bas√°ndose en los ejemplos que el modelo combinado anterior pudo clasificar bien. Al iterar y ajustar los pesos de los datos, AdaBoost se enfoca progresivamente en las regiones del espacio de caracter√≠sticas donde el modelo actual tiene un rendimiento deficiente. Si los datos se distribuyen linealmente, el algoritmo aplica el concepto de clasificaci√≥n (y por extensi√≥n, las ideas de regresi√≥n) de manera altamente adaptativa. La capacidad de AdaBoost para concentrarse en los ‚Äúerrores‚Äù m√°s dif√≠ciles aborda directamente la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo. El resultado es un clasificador global muy preciso y robusto, capaz de modelar relaciones complejas y lineales, que es una combinaci√≥n ponderada de muchas decisiones locales.","code":""},{"path":"m√©todos-de-ensamble.html","id":"boosting","chapter":"üåü 3. M√©todos de Ensamble","heading":"Boosting","text":"Boosting es una t√©cnica de aprendizaje conjunto (ensemble learning) que busca transformar un conjunto de modelos ‚Äúd√©biles‚Äù o ‚Äúbase‚Äù en un modelo ‚Äúfuerte‚Äù o ‚Äúpreciso‚Äù. La idea fundamental es construir modelos de forma secuencial e iterativa, donde cada nuevo modelo se centra en corregir los errores o deficiencias de los modelos construidos en las iteraciones anteriores. diferencia del bagging (como en Random Forest), donde los modelos se entrenan de forma independiente, el boosting es intr√≠nsecamente secuencial y adaptativo.El concepto clave de Boosting radica en la asignaci√≥n de pesos o en el enfoque en los errores residuales:Iteraciones Secuenciales: El proceso comienza con un modelo base inicial (menudo simple, como un decision stump).Enfoque en los Errores: En cada iteraci√≥n subsiguiente, el algoritmo presta m√°s atenci√≥n los ejemplos que fueron clasificados (o predichos) incorrectamente por los modelos anteriores, o los errores residuales explicados. Esto se logra ya sea re-ponderando los datos (dando m√°s peso los ejemplos mal clasificados) o ajustando el nuevo modelo para que prediga los residuos de los modelos anteriores.Combinaci√≥n Ponderada: Las predicciones de todos los modelos d√©biles se combinan, generalmente trav√©s de una suma ponderada, donde los modelos m√°s precisos reciben un mayor peso en la predicci√≥n final.La fuerza del boosting radica en su capacidad para reducir el sesgo y la varianza del modelo final, al construir un modelo complejo partir de componentes simples que se complementan entre s√≠.En el contexto del aprendizaje global vs.¬†local, Boosting es una estrategia de aprendizaje global que opera construyendo una serie de aproximaciones locales. Cada modelo ‚Äúd√©bil‚Äù que se entrena en una iteraci√≥n puede verse como una forma de regresi√≥n ponderada localmente (o clasificaci√≥n ponderada localmente), ya que se enfoca en una parte espec√≠fica del espacio de las caracter√≠sticas o en los datos con mayor error. El proceso iterativo de Boosting busca corregir estos errores localizados. Si los datos se distribuyen linealmente, el boosting permite que el concepto de regresi√≥n (o clasificaci√≥n) se aplique de manera muy flexible y potente. La capacidad de concentrarse en los ‚Äúerrores‚Äù residuales aborda directamente la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo. Al ensamblar muchos modelos d√©biles que se adaptan los errores de los anteriores, Boosting construye un modelo final que es una aproximaci√≥n de funci√≥n global altamente adaptable y precisa. Algoritmos como AdaBoost y Gradient Boosting Machines (GBM) son ejemplos prominentes de esta t√©cnica.","code":""},{"path":"m√©todos-de-ensamble.html","id":"bootstrapped-aggregation-bagging","chapter":"üåü 3. M√©todos de Ensamble","heading":"Bootstrapped Aggregation (Bagging)","text":"Bootstrapped Aggregation (Bagging) es una t√©cnica de aprendizaje conjunto (ensemble learning) dise√±ada para mejorar la estabilidad y precisi√≥n de los algoritmos de aprendizaje autom√°tico, particularmente para reducir la varianza en los modelos. Fue introducida por Leo Breiman en 1996 y es la base de algoritmos muy populares como Random Forest. La idea fundamental de Bagging es entrenar m√∫ltiples versiones de un mismo modelo base en diferentes subconjuntos del conjunto de datos original y luego combinar sus predicciones.El proceso central de Bagging implica dos pasos clave:Muestreo Bootstrap: En lugar de entrenar un √∫nico modelo en todo el conjunto de datos de entrenamiento, Bagging crea m√∫ltiples conjuntos de datos de arranque (bootstrap samples). Cada muestra de arranque se crea seleccionando aleatoriamente, con reemplazo, un n√∫mero de observaciones igual al tama√±o del conjunto de datos original. Esto significa que algunos puntos de datos pueden aparecer varias veces en una muestra de arranque, mientras que otros pueden aparecer en absoluto. Este muestreo aleatorio introduce diversidad entre los conjuntos de entrenamiento para cada modelo.Muestreo Bootstrap: En lugar de entrenar un √∫nico modelo en todo el conjunto de datos de entrenamiento, Bagging crea m√∫ltiples conjuntos de datos de arranque (bootstrap samples). Cada muestra de arranque se crea seleccionando aleatoriamente, con reemplazo, un n√∫mero de observaciones igual al tama√±o del conjunto de datos original. Esto significa que algunos puntos de datos pueden aparecer varias veces en una muestra de arranque, mientras que otros pueden aparecer en absoluto. Este muestreo aleatorio introduce diversidad entre los conjuntos de entrenamiento para cada modelo.Agregaci√≥n (Aggregation): Una vez que se han entrenado m√∫ltiples modelos base independientes (por ejemplo, √°rboles de decisi√≥n) en cada una de estas muestras de arranque, sus predicciones se combinan. Para tareas de clasificaci√≥n, la combinaci√≥n se realiza mediante votaci√≥n por mayor√≠a (la clase m√°s votada). Para tareas de regresi√≥n, las predicciones se promedian. Esta agregaci√≥n de predicciones de modelos diversos reduce la varianza y, por lo tanto, hace que el modelo final sea m√°s robusto y menos propenso al sobreajuste que un solo modelo entrenado en todo el conjunto de datos.Agregaci√≥n (Aggregation): Una vez que se han entrenado m√∫ltiples modelos base independientes (por ejemplo, √°rboles de decisi√≥n) en cada una de estas muestras de arranque, sus predicciones se combinan. Para tareas de clasificaci√≥n, la combinaci√≥n se realiza mediante votaci√≥n por mayor√≠a (la clase m√°s votada). Para tareas de regresi√≥n, las predicciones se promedian. Esta agregaci√≥n de predicciones de modelos diversos reduce la varianza y, por lo tanto, hace que el modelo final sea m√°s robusto y menos propenso al sobreajuste que un solo modelo entrenado en todo el conjunto de datos.En el contexto del aprendizaje global vs.¬†local, Bagging es una estrategia que combina las ventajas de los modelos de aprendizaje local para construir una aproximaci√≥n de funci√≥n global m√°s estable. Cada modelo base (ej. un √°rbol de decisi√≥n) que se entrena en una muestra de arranque puede considerarse un sistema de aprendizaje local, ya que toma decisiones basadas en el subconjunto de datos que le ha sido asignado. Sin embargo, al entrenar estos m√∫ltiples modelos en paralelo y luego agregarlos, Bagging construye un modelo final que es una aproximaci√≥n de funci√≥n global altamente adaptable. La ventaja principal es que, si los datos se distribuyen linealmente, el concepto de regresi√≥n (o clasificaci√≥n) se puede aplicar eficazmente mediante esta forma de regresi√≥n ponderada localmente (donde los ‚Äúpesos‚Äù son impl√≠citos trav√©s de la agregaci√≥n de predicciones de modelos entrenados en subconjuntos aleatorios de datos). Bagging aborda el problema de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo al promediar o votar las predicciones de m√∫ltiples modelos, lo que reduce la varianza y mejora la generalizaci√≥n.","code":""},{"path":"m√©todos-de-ensamble.html","id":"extreme-gradient-boosting-xgboost","chapter":"üåü 3. M√©todos de Ensamble","heading":"Extreme Gradient Boosting (XGBoost)","text":"XGBoost (Extreme Gradient Boosting) es una implementaci√≥n optimizada y altamente eficiente del algoritmo de Gradient Boosting Machines (GBM), ampliamente reconocida por su velocidad, rendimiento y escalabilidad en problemas de clasificaci√≥n y regresi√≥n. Gan√≥ una inmensa popularidad debido su √©xito en numerosas competiciones de machine learning (como Kaggle). Aunque se basa en los principios de GBM, XGBoost introduce varias mejoras clave que lo hacen superior en muchos escenarios.La idea fundamental de XGBoost, al igual que GBM, es construir un modelo aditivo de forma secuencial, donde cada nuevo √°rbol intenta corregir los errores residuales del conjunto de √°rboles previos. Sin embargo, XGBoost optimiza este proceso con las siguientes caracter√≠sticas:Paralelizaci√≥n: Aunque el boosting es inherentemente secuencial, XGBoost permite la paralelizaci√≥n de la construcci√≥n de los √°rboles individuales. Por ejemplo, en el paso de b√∫squeda de la mejor divisi√≥n, puede evaluar las posibles divisiones en paralelo trav√©s de m√∫ltiples n√∫cleos de CPU.Regularizaci√≥n: Incorpora t√©rminos de regularizaci√≥n L1 (Lasso) y L2 (Ridge) en la funci√≥n de costo para controlar la complejidad del modelo y evitar el sobreajuste. Esto es crucial para la generalizaci√≥n.Manejo de Valores Faltantes: Tiene una capacidad incorporada para manejar valores faltantes en los datos, permitiendo al algoritmo aprender la mejor direcci√≥n para los valores ausentes.Poda por Profundidad (Depth-First Search): diferencia de muchos algoritmos de √°rboles que crecen nivel por nivel, XGBoost puede usar un enfoque de poda por profundidad, lo que menudo resulta en √°rboles m√°s eficientes.Cach√©-Aware Computing: Optimiza el acceso la memoria para manejar grandes conjuntos de datos de manera eficiente.Flexibilidad de Funci√≥n de P√©rdida: Permite el uso de funciones de p√©rdida personalizadas, lo que lo hace adaptable una amplia gama de problemas.En el contexto del aprendizaje global vs.¬†local, XGBoost es una poderosa estrategia de aprendizaje global que se construye iterativamente partir de componentes de aprendizaje local. Cada √°rbol de regresi√≥n (o clasificaci√≥n) individual es un ‚Äúaprendiz d√©bil‚Äù que se enfoca en las deficiencias del modelo acumulado. Si los datos se distribuyen linealmente, el algoritmo aplica el concepto de regresi√≥n (o clasificaci√≥n) de manera altamente sofisticada mediante esta regresi√≥n ponderada localmente. Al centrarse en los errores residuales y optimizar el proceso de manera rigurosa, XGBoost aborda de manera excepcional la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo. Su combinaci√≥n de precisi√≥n, velocidad y capacidad para manejar grandes conjuntos de datos lo ha convertido en uno de los algoritmos m√°s populares y efectivos en la pr√°ctica del machine learning.","code":""},{"path":"m√©todos-de-ensamble.html","id":"gradient-boosting-machines-gbm","chapter":"üåü 3. M√©todos de Ensamble","heading":"Gradient Boosting Machines (GBM)","text":"Gradient Boosting Machines (GBM) es un algoritmo de aprendizaje conjunto (ensemble learning) extremadamente potente y vers√°til, utilizado para clasificaci√≥n, regresi√≥n y otras tareas predictivas. diferencia de Random Forest que construye √°rboles de forma independiente en paralelo (bagging), GBM construye los √°rboles de forma secuencial y aditiva. La idea central es que cada nuevo √°rbol en el conjunto intenta corregir los errores residuales (residuos) del conjunto de √°rboles construidos previamente.El concepto fundamental detr√°s de GBM es el impulso (boosting), donde los modelos ‚Äúd√©biles‚Äù (generalmente √°rboles de decisi√≥n, menudo √°rboles poco profundos o ‚Äústumps‚Äù) se combinan para formar un modelo ‚Äúfuerte‚Äù. GBM logra esto de una manera espec√≠fica:Modelo Inicial: Comienza con una predicci√≥n inicial para todos los datos (por ejemplo, el valor promedio para regresi√≥n o la probabilidad logar√≠tmica para clasificaci√≥n).C√°lculo de Residuos (Pseudo-residuos): En cada iteraci√≥n, el algoritmo calcula los residuos (o m√°s precisamente, los ‚Äúpseudo-residuos‚Äù o gradientes negativos de la funci√≥n de p√©rdida) entre los valores reales y las predicciones actuales del modelo. Estos residuos representan los ‚Äúerrores‚Äù que el modelo actual ha podido capturar.Entrenamiento de un Nuevo √Årbol: Se entrena un nuevo √°rbol de decisi√≥n para predecir estos residuos. Este √°rbol es t√≠picamente peque√±o y d√©bil, dise√±ado para centrarse en las √°reas donde el modelo actual tiene los mayores errores.Actualizaci√≥n del Modelo: La predicci√≥n de este nuevo √°rbol se a√±ade la predicci√≥n acumulada del modelo existente, multiplicada por una tasa de aprendizaje (learning rate). Esta tasa de aprendizaje controla el tama√±o del paso de cada √°rbol, evitando que el modelo se sobreajuste r√°pidamente.Iteraci√≥n: Este proceso se repite para un n√∫mero predefinido de iteraciones, o hasta que una m√©trica de rendimiento deje de mejorar. Cada nuevo √°rbol contribuye reducir los errores restantes.En el contexto del aprendizaje global vs.¬†local, GBM es un sistema de aprendizaje global que se construye de manera iterativa partir de componentes de aprendizaje local. Cada √°rbol individual en el proceso de boosting es un sistema de aprendizaje local (como los decision stumps o √°rboles poco profundos) que se enfoca en una parte espec√≠fica del error. Sin embargo, la combinaci√≥n aditiva y secuencial de estos modelos ‚Äúd√©biles‚Äù produce un modelo predictivo global altamente sofisticado y preciso. Si los datos se distribuyen linealmente, GBM aplica el concepto de regresi√≥n (o clasificaci√≥n) mediante una forma incremental y adaptativa de regresi√≥n ponderada localmente. Al centrarse en los errores residuales, GBM aborda directamente la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo. Su capacidad para minimizar la funci√≥n de p√©rdida de forma gradual y dirigida lo hace excepcionalmente eficaz para modelar relaciones complejas y lineales, menudo logrando un rendimiento superior en muchos problemas del mundo real.","code":""},{"path":"m√©todos-de-ensamble.html","id":"gradient-boosted-regression-trees-gbrt","chapter":"üåü 3. M√©todos de Ensamble","heading":"Gradient Boosted Regression Trees (GBRT)","text":"Gradient Boosted Regression Trees (GBRT), menudo conocida como Gradient Boosting Machines (GBM) cuando los modelos base son √°rboles de decisi√≥n de regresi√≥n, es una t√©cnica de aprendizaje conjunto (ensemble learning) extremadamente potente y ampliamente utilizada para tareas de regresi√≥n (predicci√≥n de valores num√©ricos continuos) y tambi√©n puede adaptarse para clasificaci√≥n. Su fortaleza radica en su capacidad para construir un modelo predictivo robusto y preciso mediante la combinaci√≥n secuencial de m√∫ltiples √°rboles de decisi√≥n ‚Äúd√©biles‚Äù.La idea central de GBRT se basa en el principio de boosting, donde cada nuevo √°rbol en el conjunto se entrena para corregir los errores residuales (la diferencia entre los valores reales y las predicciones acumuladas del modelo hasta ese momento) de los √°rboles construidos en las iteraciones anteriores. Este proceso es iterativo y aditivo:Modelo Inicial: El proceso comienza con una predicci√≥n inicial simple para todos los datos, menudo el valor promedio de la variable objetivo.C√°lculo de Pseudo-Residuos: En cada iteraci√≥n, GBRT calcula los ‚Äúpseudo-residuos‚Äù, que son los gradientes negativos de la funci√≥n de p√©rdida con respecto la predicci√≥n actual. Para la p√©rdida cuadr√°tica media (com√∫n en regresi√≥n), estos pseudo-residuos son simplemente los errores tradicionales (valor real - predicci√≥n).Entrenamiento de un √Årbol de Regresi√≥n: Se entrena un nuevo √°rbol de decisi√≥n de regresi√≥n (que es un ‚Äúaprendiz d√©bil‚Äù, menudo un √°rbol poco profundo o un decision stump) para predecir estos pseudo-residuos. El √°rbol busca los mejores puntos de divisi√≥n para reducir estos errores.Actualizaci√≥n del Modelo: La predicci√≥n de este nuevo √°rbol de regresi√≥n se a√±ade la predicci√≥n acumulada del modelo existente, pero se escala por una tasa de aprendizaje (learning rate). Esta tasa de aprendizaje es un hiperpar√°metro crucial que controla la ‚Äúcontribuci√≥n‚Äù de cada nuevo √°rbol y ayuda prevenir el sobreajuste.Iteraci√≥n: Los pasos 2 4 se repiten para un n√∫mero predefinido de iteraciones. Cada nuevo √°rbol se enfoca en las deficiencias del modelo combinado anterior, refinando gradualmente la predicci√≥n.En el contexto del aprendizaje global vs.¬†local, GBRT es un sistema de aprendizaje global que se construye de manera iterativa partir de componentes de aprendizaje local. Cada √°rbol de regresi√≥n individual es un sistema de aprendizaje local que divide el espacio de caracter√≠sticas y aprende patrones en subregiones. Sin embargo, el proceso de boosting, al combinar estos √°rboles secuencialmente para reducir los errores residuales globales, construye una aproximaci√≥n de funci√≥n global altamente flexible y precisa. La clave es que, si los datos se distribuyen linealmente, el algoritmo aplica el concepto de regresi√≥n de manera muy efectiva trav√©s de esta regresi√≥n ponderada localmente. Al centrarse en los errores que el modelo actual puede explicar, GBRT aborda directamente la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo. Es excepcionalmente potente para capturar relaciones complejas y lineales, y es ampliamente utilizado en diversas aplicaciones, desde la predicci√≥n de precios hasta la optimizaci√≥n de rutas.","code":""},{"path":"m√©todos-de-ensamble.html","id":"light-gradient-boosting-machine-lightgbm","chapter":"üåü 3. M√©todos de Ensamble","heading":"Light Gradient Boosting Machine (LightGBM)","text":"LightGBM (Light Gradient Boosting Machine) es otro algoritmo de Gradient Boosting Machines (GBM) de alto rendimiento, desarrollado por Microsoft. Est√° dise√±ado para ser extremadamente r√°pido y eficiente en el uso de memoria, especialmente con grandes conjuntos de datos, sin sacrificar una precisi√≥n significativa. Al igual que XGBoost, ha ganado popularidad en competiciones de machine learning por su velocidad y capacidad para manejar grandes vol√∫menes de datos.La idea fundamental de LightGBM es la misma que la de otros algoritmos de boosting: construir un modelo aditivo de forma secuencial, donde cada nuevo √°rbol intenta corregir los errores residuales del modelo combinado anterior. Sin embargo, LightGBM introduce varias optimizaciones clave para lograr su notable eficiencia:Gradient-based One-Side Sampling (GOSS): diferencia de XGBoost que usa todas las instancias para cada iteraci√≥n, GOSS se enfoca en las instancias que tienen un mayor gradiente (es decir, las que contribuyen m√°s al error). Descarta las instancias con gradientes peque√±os o las muestrea con menos frecuencia, lo que acelera el entrenamiento sin perder demasiada precisi√≥n.Exclusive Feature Bundling (EFB): EFB agrupa caracter√≠sticas mutuamente exclusivas (es decir, caracter√≠sticas que rara vez toman valores distintos de cero al mismo tiempo) en un solo ‚Äúbundle‚Äù. Esto reduce el n√∫mero de caracter√≠sticas y acelera el c√°lculo del histograma sin afectar la precisi√≥n.Histogram-based Algorithm: En lugar de construir √°rboles en una forma de pre-orden que es com√∫n en muchos algoritmos (lo que puede ser lento al enumerar todos los puntos de divisi√≥n), LightGBM utiliza un algoritmo basado en histogramas. Convierte los valores de las caracter√≠sticas continuas en bins discretos. Esto acelera significativamente el proceso de b√∫squeda del mejor punto de divisi√≥n.Leaf-wise (Best-first) Tree Growth: diferencia de la mayor√≠a de los √°rboles de decisi√≥n que crecen nivel por nivel (como en XGBoost), LightGBM crece el √°rbol ‚Äúhoja por hoja‚Äù (leaf-wise). Esto significa que en cada paso, selecciona la hoja con la mayor reducci√≥n de p√©rdida y la divide. Este enfoque puede llevar √°rboles m√°s profundos y asim√©tricos que pueden ser m√°s precisos para el mismo n√∫mero de nodos, aunque puede ser m√°s propenso al sobreajuste (lo cual se mitiga con la regularizaci√≥n).En el contexto del aprendizaje global vs.¬†local, LightGBM, al igual que otros algoritmos de boosting, es una estrategia de aprendizaje global que se construye de manera iterativa partir de componentes de aprendizaje local. Cada √°rbol que se entrena es un ‚Äúaprendiz d√©bil‚Äù que se enfoca en las deficiencias residuales del modelo acumulado. Si los datos se distribuyen linealmente, el algoritmo aplica el concepto de regresi√≥n (o clasificaci√≥n) de manera muy eficiente mediante esta regresi√≥n ponderada localmente. Al centrarse en los errores y optimizar los c√°lculos, LightGBM aborda de manera sobresaliente la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo. Su √©nfasis en la velocidad y la eficiencia lo hace ideal para conjuntos de datos muy grandes o escenarios donde el tiempo de entrenamiento es una preocupaci√≥n cr√≠tica.","code":""},{"path":"m√©todos-de-ensamble.html","id":"random-forest","chapter":"üåü 3. M√©todos de Ensamble","heading":"Random Forest","text":"Random Forest es un algoritmo de aprendizaje conjunto (ensemble learning) altamente popular y potente, utilizado tanto para tareas de clasificaci√≥n como de regresi√≥n. Fue desarrollado por Leo Breiman en 2001 y se basa en la idea de combinar las predicciones de m√∫ltiples √°rboles de decisi√≥n para lograr una mayor precisi√≥n y robustez que un solo √°rbol. La fuerza de Random Forest reside en dos conceptos clave: bagging (bootstrap aggregation) y la aleatoriedad en la selecci√≥n de caracter√≠sticas.La idea fundamental detr√°s de Random Forest es construir un ‚Äúbosque‚Äù de √°rboles de decisi√≥n de una manera espec√≠fica:Bagging (Bootstrap Aggregation): En lugar de entrenar un solo √°rbol en todo el conjunto de datos, Random Forest entrena cada √°rbol en una muestra de arranque (bootstrap sample) diferente. Una muestra de arranque es un subconjunto del conjunto de datos original, muestreado con reemplazo. Esto significa que algunos puntos de datos pueden aparecer varias veces en una muestra, mientras que otros pueden aparecer en absoluto. Este muestreo genera diversidad entre los √°rboles.Bagging (Bootstrap Aggregation): En lugar de entrenar un solo √°rbol en todo el conjunto de datos, Random Forest entrena cada √°rbol en una muestra de arranque (bootstrap sample) diferente. Una muestra de arranque es un subconjunto del conjunto de datos original, muestreado con reemplazo. Esto significa que algunos puntos de datos pueden aparecer varias veces en una muestra, mientras que otros pueden aparecer en absoluto. Este muestreo genera diversidad entre los √°rboles.Aleatoriedad en la Selecci√≥n de Caracter√≠sticas: Cuando cada √°rbol se construye, en cada paso de divisi√≥n (nodo), Random Forest considera todas las caracter√≠sticas disponibles. En cambio, solo considera un subconjunto aleatorio de caracter√≠sticas para encontrar la mejor divisi√≥n. Esta aleatoriedad adicional (adem√°s del muestreo de arranque) descorrelaciona a√∫n m√°s los √°rboles, lo que es crucial para el rendimiento del algoritmo. Si los √°rboles estuvieran altamente correlacionados, el error de un √°rbol promedio se reducir√≠a al promediar.Aleatoriedad en la Selecci√≥n de Caracter√≠sticas: Cuando cada √°rbol se construye, en cada paso de divisi√≥n (nodo), Random Forest considera todas las caracter√≠sticas disponibles. En cambio, solo considera un subconjunto aleatorio de caracter√≠sticas para encontrar la mejor divisi√≥n. Esta aleatoriedad adicional (adem√°s del muestreo de arranque) descorrelaciona a√∫n m√°s los √°rboles, lo que es crucial para el rendimiento del algoritmo. Si los √°rboles estuvieran altamente correlacionados, el error de un √°rbol promedio se reducir√≠a al promediar.Una vez que se han construido numerosos √°rboles (t√≠picamente cientos o miles), las predicciones se combinan: para clasificaci√≥n, se utiliza la votaci√≥n por mayor√≠a (la clase m√°s votada por los √°rboles individuales); para regresi√≥n, se calcula el promedio de las predicciones de todos los √°rboles.En el contexto del aprendizaje global vs.¬†local, Random Forest se puede considerar como un sistema de aprendizaje global que se construye partir de componentes de aprendizaje local. Cada √°rbol individual en el bosque es un sistema de aprendizaje local (como CART, que divide el problema en subproblemas m√°s peque√±os). Sin embargo, al combinar las predicciones de muchos de estos √°rboles, Random Forest logra una aproximaci√≥n de funci√≥n global muy robusta y flexible. La ventaja es que, si los datos se distribuyen linealmente, el algoritmo aplica el concepto de regresi√≥n (o clasificaci√≥n) mediante una forma sofisticada de regresi√≥n ponderada localmente. La combinaci√≥n de √°rboles diversos y descorrelacionados mitiga la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo. Random Forest sobresale en capturar relaciones complejas y lineales, manejar grandes conjuntos de datos con muchas caracter√≠sticas y es menos propenso al sobreajuste que un solo √°rbol de decisi√≥n grande.","code":""},{"path":"m√©todos-de-ensamble.html","id":"stacked-generlization-blending","chapter":"üåü 3. M√©todos de Ensamble","heading":"Stacked Generlization (Blending)","text":"Stacked Generalization, com√∫nmente conocido como Stacking, y su variante Blending, son t√©cnicas avanzadas de aprendizaje conjunto (ensemble learning) que buscan combinar las predicciones de m√∫ltiples modelos de aprendizaje autom√°tico para obtener un rendimiento predictivo superior al de cualquier modelo individual. La idea fundamental es que, en lugar de simplemente promediar o votar las predicciones, se entrena un modelo de segundo nivel (meta-modelo) para aprender combinar √≥ptimamente las predicciones de los modelos de primer nivel (modelos base).El proceso de Stacking generalmente implica dos o m√°s ‚Äúcapas‚Äù de modelos:Modelos Base (Nivel 0): En la primera capa, se entrenan m√∫ltiples modelos de aprendizaje autom√°tico diversos (pueden ser de diferentes tipos, como √°rboles de decisi√≥n, m√°quinas de vectores de soporte, redes neuronales, etc.). Estos modelos base se entrenan sobre el conjunto de datos de entrenamiento original (o en particiones del mismo).Modelos Base (Nivel 0): En la primera capa, se entrenan m√∫ltiples modelos de aprendizaje autom√°tico diversos (pueden ser de diferentes tipos, como √°rboles de decisi√≥n, m√°quinas de vectores de soporte, redes neuronales, etc.). Estos modelos base se entrenan sobre el conjunto de datos de entrenamiento original (o en particiones del mismo).Generaci√≥n de Meta-Caracter√≠sticas: Las predicciones generadas por estos modelos base sobre un conjunto de datos ‚Äúfuera de muestra‚Äù (que se us√≥ para entrenar los modelos base, t√≠picamente trav√©s de validaci√≥n cruzada k-fold) se utilizan como nuevas caracter√≠sticas o ‚Äúmeta-caracter√≠sticas‚Äù. Estas meta-caracter√≠sticas, junto con la variable objetivo original, forman un nuevo conjunto de datos de entrenamiento para el meta-modelo.Generaci√≥n de Meta-Caracter√≠sticas: Las predicciones generadas por estos modelos base sobre un conjunto de datos ‚Äúfuera de muestra‚Äù (que se us√≥ para entrenar los modelos base, t√≠picamente trav√©s de validaci√≥n cruzada k-fold) se utilizan como nuevas caracter√≠sticas o ‚Äúmeta-caracter√≠sticas‚Äù. Estas meta-caracter√≠sticas, junto con la variable objetivo original, forman un nuevo conjunto de datos de entrenamiento para el meta-modelo.Meta-Modelo (Nivel 1): En la segunda capa, se entrena un meta-modelo (menudo un modelo m√°s simple, como regresi√≥n lineal, regresi√≥n log√≠stica o un √°rbol de decisi√≥n poco profundo) utilizando estas meta-caracter√≠sticas como entrada y la variable objetivo original como salida. El meta-modelo aprende la relaci√≥n entre las predicciones de los modelos base y la respuesta verdadera, y por lo tanto, c√≥mo ‚Äúpesar‚Äù o ‚Äúcombinar‚Äù esas predicciones de la mejor manera.Meta-Modelo (Nivel 1): En la segunda capa, se entrena un meta-modelo (menudo un modelo m√°s simple, como regresi√≥n lineal, regresi√≥n log√≠stica o un √°rbol de decisi√≥n poco profundo) utilizando estas meta-caracter√≠sticas como entrada y la variable objetivo original como salida. El meta-modelo aprende la relaci√≥n entre las predicciones de los modelos base y la respuesta verdadera, y por lo tanto, c√≥mo ‚Äúpesar‚Äù o ‚Äúcombinar‚Äù esas predicciones de la mejor manera.Blending es una variaci√≥n m√°s sencilla de Stacking. La principal diferencia es c√≥mo se generan las meta-caracter√≠sticas para el meta-modelo. En Blending, se reserva una subdivisi√≥n de validaci√≥n (holdout set) del conjunto de entrenamiento original. Los modelos base se entrenan en la parte restante del conjunto de entrenamiento, y luego sus predicciones sobre este conjunto de validaci√≥n se utilizan directamente como meta-caracter√≠sticas para entrenar el meta-modelo. Esto simplifica el proceso de validaci√≥n cruzada, pero el meta-modelo se entrena con menos datos.En el contexto del aprendizaje global vs.¬†local, Stacking/Blending es una estrategia de aprendizaje global que explota el poder de m√∫ltiples aproximaciones de funci√≥n local (los modelos base) para construir un modelo final altamente sofisticado. Cada modelo base, dependiendo de su naturaleza, puede ser un sistema de aprendizaje local que descubre patrones en subregiones de datos. Sin embargo, el meta-modelo aprende una funci√≥n de combinaci√≥n global sobre las predicciones de estos modelos base. Si los datos se distribuyen linealmente, Stacking/Blending aplica el concepto de regresi√≥n (o clasificaci√≥n) de una manera muy flexible. Al permitir que un modelo de segundo nivel aprenda combinar las predicciones de diversos modelos, supera la limitaci√≥n de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo. Es particularmente eficaz en competiciones de machine learning donde se busca el m√°ximo rendimiento, ya que aprovecha las fortalezas complementarias de diferentes algoritmos. Sin embargo, puede ser computacionalmente intensivo y m√°s dif√≠cil de interpretar que los modelos individuales.","code":""},{"path":"redes-neuronales.html","id":"redes-neuronales","chapter":"üß† 4. Redes Neuronales","heading":"üß† 4. Redes Neuronales","text":"Ejemplos: MLP, CNN, RNN, Transformers.Uso: Perfectas para im√°genes (CNN), texto (Transformers) y series temporales (RNN/LSTM), especialmente con grandes vol√∫menes de datos estructurados.Ventajas: Muy poderosas para datos complejos.Limitaciones: Requieren mucha data y computaci√≥n, y tienen menor interpretabilidad.","code":""},{"path":"redes-neuronales.html","id":"autoenconder","chapter":"üß† 4. Redes Neuronales","heading":"Autoenconder","text":"Un Autoencoder es un tipo de red neuronal artificial dise√±ado para aprender una representaci√≥n (o codificaci√≥n) eficiente y comprimida de los datos de entrada, sin supervisi√≥n humana. Su objetivo principal es la reducci√≥n de dimensionalidad o el aprendizaje de caracter√≠sticas, lo que lo hace √∫til para tareas como la detecci√≥n de anomal√≠as, la denoising de im√°genes, o la generaci√≥n de datos.La arquitectura b√°sica de un Autoencoder se compone de dos partes principales:Encoder (Codificador): Esta parte de la red toma los datos de entrada y los transforma en una representaci√≥n de menor dimensi√≥n, menudo llamada c√≥digo, representaci√≥n latente, o cuello de botella (bottleneck). Es decir, comprime la informaci√≥n esencial de la entrada.Decoder (Decodificador): Esta parte toma la representaci√≥n comprimida (el c√≥digo) del encoder y la reconstruye de nuevo la dimensi√≥n original de los datos de entrada.El Autoencoder se entrena para minimizar la diferencia entre la entrada original y su reconstrucci√≥n generada por el decoder. Esta diferencia se mide trav√©s de una funci√≥n de p√©rdida de reconstrucci√≥n (como el error cuadr√°tico medio para datos continuos o la entrop√≠a cruzada para datos binarios). Al forzar la red reconstruir su propia entrada partir de una representaci√≥n comprimida, el Autoencoder aprende las caracter√≠sticas m√°s salientes y √∫tiles de los datos de forma supervisada.Existen varias variantes de Autoencoders, como los Autoencoders Denoising (que aprenden reconstruir datos limpios partir de datos con ruido), los Autoencoders Variacionales (VAEs) (que aprenden una distribuci√≥n probabil√≠stica de la representaci√≥n latente, √∫tiles para la generaci√≥n de datos), y los Autoencoders Convolucionales (que usan capas convolucionales, ideales para im√°genes).Aprendizaje Global vs.¬†Local:Un Autoencoder se considera principalmente un modelo de aprendizaje global, aunque con una perspectiva √∫nica debido su naturaleza de compresi√≥n y reconstrucci√≥n.Aspecto Global: Un Autoencoder aprende una transformaci√≥n global de los datos. El encoder aprende mapear todo el espacio de entrada un espacio de representaci√≥n latente, y el decoder aprende mapear ese espacio latente de vuelta al espacio de salida. Las ponderaciones y sesgos de la red se ajustan para encontrar esta transformaci√≥n que funciona de manera √≥ptima para todo el conjunto de datos de entrenamiento, permitiendo la reconstrucci√≥n m√°s fiel posible en general. La funci√≥n de p√©rdida de reconstrucci√≥n se minimiza nivel de todo el conjunto de datos, solo en vecindarios espec√≠ficos.Aspecto Global: Un Autoencoder aprende una transformaci√≥n global de los datos. El encoder aprende mapear todo el espacio de entrada un espacio de representaci√≥n latente, y el decoder aprende mapear ese espacio latente de vuelta al espacio de salida. Las ponderaciones y sesgos de la red se ajustan para encontrar esta transformaci√≥n que funciona de manera √≥ptima para todo el conjunto de datos de entrenamiento, permitiendo la reconstrucci√≥n m√°s fiel posible en general. La funci√≥n de p√©rdida de reconstrucci√≥n se minimiza nivel de todo el conjunto de datos, solo en vecindarios espec√≠ficos.Representaci√≥n Local vs.¬†Reconstrucci√≥n Global: Aunque el objetivo final es una reconstrucci√≥n global de la entrada, la representaci√≥n latente (el c√≥digo) puede verse como una forma de capturar caracter√≠sticas o patrones importantes que, en cierto sentido, resumen la informaci√≥n ‚Äúlocal‚Äù o particular de cada instancia de datos de una manera comprimida. Sin embargo, la forma en que estas caracter√≠sticas se aprenden y se utilizan para la reconstrucci√≥n se rige por un conjunto global de par√°metros de la red. se entrena un modelo separado para cada vecindario de datos, sino una √∫nica red que aprende una funci√≥n de mapeo para todo el dominio.Representaci√≥n Local vs.¬†Reconstrucci√≥n Global: Aunque el objetivo final es una reconstrucci√≥n global de la entrada, la representaci√≥n latente (el c√≥digo) puede verse como una forma de capturar caracter√≠sticas o patrones importantes que, en cierto sentido, resumen la informaci√≥n ‚Äúlocal‚Äù o particular de cada instancia de datos de una manera comprimida. Sin embargo, la forma en que estas caracter√≠sticas se aprenden y se utilizan para la reconstrucci√≥n se rige por un conjunto global de par√°metros de la red. se entrena un modelo separado para cada vecindario de datos, sino una √∫nica red que aprende una funci√≥n de mapeo para todo el dominio.En resumen, el Autoencoder aprende una representaci√≥n eficiente y una capacidad de reconstrucci√≥n que se aplica de manera consistente todos los datos, lo que lo clasifica como un modelo de aprendizaje global que busca una soluci√≥n unificada para el problema de la codificaci√≥n y decodificaci√≥n de datos.","code":""},{"path":"redes-neuronales.html","id":"back---propagation","chapter":"üß† 4. Redes Neuronales","heading":"Back - Propagation","text":"Back-Propagation (Retropropagaci√≥n) es el algoritmo fundamental de entrenamiento utilizado para ajustar los pesos de las redes neuronales artificiales multicapa (MLP). La idea central de Back-Propagation es calcular la contribuci√≥n de cada peso al error global de la red y luego ajustar esos pesos para reducir dicho error, propagando la informaci√≥n del error ‚Äúhacia atr√°s‚Äù desde la capa de salida hasta la capa de entrada.diferencia del Perceptron, que solo puede aprender patrones linealmente separables, Back-Propagation permite entrenar redes neuronales profundas con m√∫ltiples capas ocultas y funciones de activaci√≥n lineales, lo que les permite modelar relaciones complejas y lineales en los datos.El funcionamiento de Back-Propagation se divide en dos fases principales que se repiten iterativamente:Fase de Propagaci√≥n hacia Adelante (Forward Pass):\nLas entradas se pasan trav√©s de la red, desde la capa de entrada, trav√©s de las capas ocultas, hasta la capa de salida.\nEn cada neurona, se calcula la suma ponderada de sus entradas (incluido el sesgo) y se aplica la funci√≥n de activaci√≥n (ej. sigmoide, tanh, ReLU) para producir la salida de esa neurona.\nLa salida final de la red se compara con el valor objetivo real para calcular el error global (o ‚Äúcosto‚Äù) de la red, utilizando una funci√≥n de p√©rdida (ej. error cuadr√°tico medio para regresi√≥n, entrop√≠a cruzada para clasificaci√≥n).\nLas entradas se pasan trav√©s de la red, desde la capa de entrada, trav√©s de las capas ocultas, hasta la capa de salida.En cada neurona, se calcula la suma ponderada de sus entradas (incluido el sesgo) y se aplica la funci√≥n de activaci√≥n (ej. sigmoide, tanh, ReLU) para producir la salida de esa neurona.La salida final de la red se compara con el valor objetivo real para calcular el error global (o ‚Äúcosto‚Äù) de la red, utilizando una funci√≥n de p√©rdida (ej. error cuadr√°tico medio para regresi√≥n, entrop√≠a cruzada para clasificaci√≥n).Fase de Retropropagaci√≥n (Backward Pass):\nEl error global se propaga hacia atr√°s desde la capa de salida, trav√©s de las capas ocultas, hasta la capa de entrada.\nEn cada capa, se calcula el gradiente del error con respecto los pesos de las conexiones de esa capa. Esto implica el uso de la regla de la cadena del c√°lculo diferencial para determinar cu√°nto contribuye cada peso al error final.\nUna vez calculados los gradientes, los pesos de la red se actualizan en la direcci√≥n opuesta al gradiente (es decir, en la direcci√≥n de mayor descenso) para reducir el error. Esta actualizaci√≥n se realiza con una tasa de aprendizaje que controla el tama√±o del paso.\n\\[w_{ij}^{\\text{nuevo}} = w_{ij}^{\\text{anterior}} - \\alpha \\cdot \\frac{\\partial E}{\\partial w_{ij}}\\]\nDonde \\(E\\) es el error, \\(w_{ij}\\) es el peso de la conexi√≥n entre la neurona \\(\\) y la neurona \\(j\\), y \\(\\alpha\\) es la tasa de aprendizaje.\nEl error global se propaga hacia atr√°s desde la capa de salida, trav√©s de las capas ocultas, hasta la capa de entrada.En cada capa, se calcula el gradiente del error con respecto los pesos de las conexiones de esa capa. Esto implica el uso de la regla de la cadena del c√°lculo diferencial para determinar cu√°nto contribuye cada peso al error final.Una vez calculados los gradientes, los pesos de la red se actualizan en la direcci√≥n opuesta al gradiente (es decir, en la direcci√≥n de mayor descenso) para reducir el error. Esta actualizaci√≥n se realiza con una tasa de aprendizaje que controla el tama√±o del paso.\n\\[w_{ij}^{\\text{nuevo}} = w_{ij}^{\\text{anterior}} - \\alpha \\cdot \\frac{\\partial E}{\\partial w_{ij}}\\]\nDonde \\(E\\) es el error, \\(w_{ij}\\) es el peso de la conexi√≥n entre la neurona \\(\\) y la neurona \\(j\\), y \\(\\alpha\\) es la tasa de aprendizaje.En el contexto del aprendizaje global vs.¬†local, Back-Propagation es el coraz√≥n del entrenamiento de sistemas de aprendizaje global por excelencia (las redes neuronales multicapa). La red neuronal busca aprender una aproximaci√≥n de funci√≥n global que mapee las entradas las salidas, minimizando el error en todo el conjunto de datos. Si los datos se distribuyen linealmente, Back-Propagation permite que la red aprenda relaciones lineales complejas trav√©s de sus m√∫ltiples capas y funciones de activaci√≥n lineales. diferencia de LOESS o los m√©todos de regresi√≥n ponderada localmente, Back-Propagation divide expl√≠citamente el problema en m√∫ltiples problemas locales independientes para minimizar funciones de costo locales. En cambio, busca minimizar una funci√≥n de p√©rdida global para toda la red. Sin embargo, su capacidad para ajustar un gran n√∫mero de par√°metros (pesos) le permite construir representaciones internas de los datos que pueden ser incre√≠blemente flexibles y adaptables, superando la limitaci√≥n de que ‚Äúveces ning√∫n valor de par√°metro [en un modelo simple] puede proporcionar una aproximaci√≥n suficientemente buena‚Äù. La retropropagaci√≥n es lo que permiti√≥ las redes neuronales convertirse en poderosas herramientas de aprendizaje autom√°tico.","code":""},{"path":"redes-neuronales.html","id":"convolutional-neural-network-cnn","chapter":"üß† 4. Redes Neuronales","heading":"Convolutional Neural Network (CNN)","text":"Convolutional Neural Networks (CNNs), tambi√©n conocidas como ConvNets, son una clase especializada de redes neuronales profundas que han demostrado ser excepcionalmente efectivas en tareas de visi√≥n por computadora (como clasificaci√≥n de im√°genes, detecci√≥n de objetos, reconocimiento facial) y, m√°s recientemente, en procesamiento de lenguaje natural. La idea fundamental de una CNN es imitar el funcionamiento del c√≥rtex visual en el cerebro humano, utilizando capas de convoluci√≥n para detectar autom√°ticamente patrones y caracter√≠sticas jer√°rquicas directamente de los datos de entrada sin necesidad de una extracci√≥n manual de caracter√≠sticas.diferencia de los Multilayer Perceptrons (MLPs) que conectan cada neurona de una capa con cada neurona de la siguiente capa (lo que resulta en una enorme cantidad de par√°metros para datos de alta dimensi√≥n como im√°genes), las CNNs aprovechan tres ideas arquitect√≥nicas clave:Capas de Convoluci√≥n: Estas capas aplican un peque√±o conjunto de filtros (kernels) la entrada (ej., una imagen). Cada filtro ‚Äúse desliza‚Äù por la entrada (operaci√≥n de convoluci√≥n) y calcula un producto punto entre sus valores y los valores de la regi√≥n de la entrada que est√° cubriendo. Esto genera un mapa de caracter√≠sticas que resalta la presencia de patrones espec√≠ficos (bordes, texturas, formas) en diferentes ubicaciones de la entrada. La ventaja es que los mismos filtros se aplican en m√∫ltiples ubicaciones, lo que reduce dr√°sticamente el n√∫mero de par√°metros y captura la localidad de los patrones y la invarianza traslacional.Capas de Pooling (Submuestreo): Estas capas se insertan peri√≥dicamente entre las capas convolucionales. Su funci√≥n es reducir la dimensionalidad espacial de los mapas de caracter√≠sticas (ej., reduciendo el n√∫mero de p√≠xeles), lo que ayuda hacer que el modelo sea m√°s robusto peque√±as variaciones o distorsiones en la posici√≥n de las caracter√≠sticas. Las operaciones comunes son el max pooling (tomar el valor m√°ximo de una regi√≥n) o el average pooling (tomar el promedio).Capas Totalmente Conectadas (Dense): Despu√©s de varias capas convolucionales y de pooling, los mapas de caracter√≠sticas finales se aplanan en un vector y se conectan una o m√°s capas totalmente conectadas (similares las de un MLP). Estas capas finales realizan la clasificaci√≥n o regresi√≥n bas√°ndose en las caracter√≠sticas de alto nivel extra√≠das por las capas anteriores.El entrenamiento de una CNN se realiza utilizando el algoritmo de Back-Propagation y descenso de gradiente (con sus variantes como SGD, Adam, etc.), ajustando los pesos de los filtros y las conexiones de las capas densas para minimizar una funci√≥n de p√©rdida.En el contexto del aprendizaje global vs.¬†local, las CNNs son un ejemplo sobresaliente de un sistema de aprendizaje global que, en sus capas iniciales, se beneficia de la detecci√≥n de patrones locales. Cada filtro de convoluci√≥n aprende detectar un patr√≥n local espec√≠fico (un borde vertical, una esquina, etc.) que se repite en diferentes partes de la imagen (lo que es una forma de ‚Äúregresi√≥n ponderada localmente‚Äù en el sentido de que el filtro ‚Äúaplica‚Äù su conocimiento local diferentes ventanas de entrada). Sin embargo, la combinaci√≥n jer√°rquica de m√∫ltiples capas convolucionales y de pooling, seguida de capas totalmente conectadas, permite que la red construya representaciones cada vez m√°s abstractas y globales del contenido de la imagen. Esto significa que si los datos se distribuyen linealmente, las CNNs pueden aprender modelar relaciones extremadamente complejas y lineales al componer caracter√≠sticas locales en representaciones globales. La arquitectura de CNNs resuelve la limitaci√≥n de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en modelos m√°s simples al permitir que la red aprenda caracter√≠sticas relevantes de forma autom√°tica y jer√°rquica, adapt√°ndose las complejidades inherentes de datos como im√°genes y videos.","code":""},{"path":"redes-neuronales.html","id":"hopfield-network","chapter":"üß† 4. Redes Neuronales","heading":"Hopfield Network","text":"La Red de Hopfield es un tipo de red neuronal recurrente o red neuronal con memoria asociativa, propuesta por John Hopfield en 1982. diferencia de las redes neuronales de propagaci√≥n hacia adelante (como el Perceptr√≥n o las MLP entrenadas con Back-Propagation) que se utilizan para el mapeo de entrada salida, la idea fundamental de una Red de Hopfield es funcionar como un sistema de memoria asociativa y un sistema din√°mico que converge estados estables. Su objetivo principal es almacenar y recuperar patrones binarios, as√≠ como resolver problemas de optimizaci√≥n.El funcionamiento de una Red de Hopfield se basa en los siguientes principios:Neuronas Binarias: La red consta de un conjunto de neuronas (nodos) que son binarias, lo que significa que solo pueden tomar dos estados posibles, generalmente \\(1\\) o \\(-1\\).Conexiones Ponderadas: Cada neurona est√° conectada todas las dem√°s neuronas (excepto s√≠ misma) mediante conexiones sim√©tricas y ponderadas. Los pesos de estas conexiones se calculan de manera que los patrones que se quieren ‚Äúmemorizar‚Äù se conviertan en estados de energ√≠a m√≠nima de la red. La regla de aprendizaje m√°s com√∫n para establecer estos pesos es la regla de Hebb: si dos neuronas se activan juntas para un patr√≥n, el peso entre ellas se incrementa.Din√°mica de Activaci√≥n: Cuando se presenta una entrada la red (que puede ser un patr√≥n ruidoso o incompleto), las neuronas se actualizan de forma as√≠ncrona o s√≠ncrona. La activaci√≥n de cada neurona se recalcula en funci√≥n de la suma ponderada de las activaciones de las otras neuronas las que est√° conectada.\n\\[S_i = \\text{sgn}\\left(\\sum_{j \\neq } W_{ij} S_j\\right)\\]\nDonde \\(S_i\\) es el estado de la neurona \\(\\), \\(W_{ij}\\) es el peso entre la neurona \\(\\) y \\(j\\), y \\(\\text{sgn}\\) es la funci√≥n signo.Convergencia Estados Estables: Este proceso de actualizaci√≥n se repite hasta que la red alcanza un estado estable (un ‚Äúatractor‚Äù), donde las activaciones de las neuronas ya cambian. Si la red ha sido entrenada correctamente, este estado estable corresponder√° al patr√≥n memorizado m√°s cercano la entrada inicial (memoria asociativa).Funci√≥n de Energ√≠a: La estabilidad de la red se puede describir mediante una funci√≥n de energ√≠a de Lyapunov. Durante la din√°mica de la red, la energ√≠a de la red siempre disminuye hasta que se alcanza un m√≠nimo local (un patr√≥n memorizado).En el contexto del aprendizaje global vs.¬†local, la Red de Hopfield es un sistema de aprendizaje global que exhibe un comportamiento de optimizaci√≥n local. La regla de aprendizaje (como la regla de Hebb) establece los pesos de todas las conexiones para que los patrones deseados se conviertan en m√≠nimos de energ√≠a en todo el espacio de estados. Es decir, se busca una configuraci√≥n global de pesos para memorizar un conjunto de patrones. Sin embargo, la din√°mica de recuperaci√≥n de la red es intr√≠nsecamente un proceso de convergencia local: dada una entrada inicial, la red ‚Äúcae‚Äù en el m√≠nimo de energ√≠a m√°s cercano, que corresponde al patr√≥n memorizado.Si los datos se distribuyen linealmente, la Red de Hopfield aplica el concepto de regresi√≥n (o clasificaci√≥n) de la misma manera que LOESS o los √°rboles de decisi√≥n. En cambio, funciona como un sistema de memoria y recuperaci√≥n de patrones lineales. Puede almacenar y recuperar patrones complejos que son linealmente separables. La red busca una soluci√≥n global (un conjunto de pesos) para almacenar los patrones, y luego, en la recuperaci√≥n, utiliza un proceso de ‚Äúb√∫squeda‚Äù local en el espacio de energ√≠a para converger un patr√≥n memorizado. Esto aborda la idea de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un modelo de regresi√≥n lineal, ya que la Red de Hopfield es un modelo de regresi√≥n en s√≠, sino un sistema din√°mico que encuentra estados de equilibrio. Su capacidad para manejar patrones ruidosos o incompletos para recuperar el patr√≥n completo es una de sus principales fortalezas.","code":""},{"path":"redes-neuronales.html","id":"multilayer-perceptron-mp","chapter":"üß† 4. Redes Neuronales","heading":"Multilayer Perceptron (MP)","text":"El Multilayer Perceptron (MLP), tambi√©n conocido como red neuronal de propagaci√≥n hacia adelante cl√°sica, es un tipo fundamental de red neuronal artificial utilizada para una amplia gama de tareas de aprendizaje supervisado, incluyendo clasificaci√≥n y regresi√≥n. La idea fundamental del MLP es extender el concepto del Perceptr√≥n simple al incorporar una o m√°s capas ocultas entre la capa de entrada y la capa de salida, y utilizando funciones de activaci√≥n lineales en estas capas. Esta arquitectura de m√∫ltiples capas es lo que le confiere los MLP su capacidad para aprender y modelar relaciones complejas y lineales en los datos.La estructura de un MLP t√≠picamente incluye:Capa de Entrada: Recibe las caracter√≠sticas de entrada del problema.Capas Ocultas: Son una o m√°s capas intermedias donde se realizan c√°lculos complejos. Cada neurona en una capa oculta recibe entradas de la capa anterior, calcula una suma ponderada de estas entradas (m√°s un sesgo), y luego aplica una funci√≥n de activaci√≥n lineal (como la funci√≥n sigmoide, tanh o ReLU) esta suma. Es la linealidad de estas funciones de activaci√≥n la que permite al MLP aprender relaciones lineales.\n\\[a_j = f\\left(\\sum_{=1}^{n} w_{ij} x_i + b_j\\right)\\]\nDonde \\(a_j\\) es la activaci√≥n de la neurona \\(j\\), \\(x_i\\) son las entradas de la capa anterior, \\(w_{ij}\\) son los pesos, \\(b_j\\) es el sesgo, y \\(f\\) es la funci√≥n de activaci√≥n lineal.Capa de Salida: Produce la predicci√≥n final de la red. La funci√≥n de activaci√≥n en esta capa depende del tipo de problema (ej., una funci√≥n lineal para regresi√≥n, softmax para clasificaci√≥n multiclase, o sigmoide para clasificaci√≥n binaria).El entrenamiento de un MLP se realiza t√≠picamente utilizando el algoritmo de Back-Propagation, que ajusta los pesos de la red de manera iterativa para minimizar una funci√≥n de p√©rdida (error) calculada en la capa de salida.En el contexto del aprendizaje global vs.¬†local, el Multilayer Perceptron es el paradigma de un sistema de aprendizaje global. La red aprende una aproximaci√≥n de funci√≥n global que mapea las entradas las salidas, buscando minimizar la funci√≥n de p√©rdida en todo el conjunto de datos de entrenamiento. diferencia de los sistemas de aprendizaje local que dividen expl√≠citamente el problema global en m√∫ltiples problemas m√°s peque√±os, el MLP ajusta todos sus pesos de forma interconectada para aprender una representaci√≥n distribuida de los patrones en los datos. Si los datos se distribuyen linealmente, el MLP es excepcionalmente capaz de modelar estas relaciones complejas gracias sus capas ocultas y funciones de activaci√≥n lineales. Esto aborda directamente la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en modelos lineales o m√°s simples, ya que el MLP puede construir representaciones internas de gran complejidad para aproximar casi cualquier funci√≥n continua. Hoy en d√≠a, los MLP son la base de muchas arquitecturas de ‚ÄúDeep Learning‚Äù.","code":""},{"path":"redes-neuronales.html","id":"perceptron","chapter":"üß† 4. Redes Neuronales","heading":"Perceptron","text":"El Perceptron es el algoritmo de aprendizaje supervisado m√°s simple y uno de los primeros modelos de redes neuronales artificiales, propuesto por Frank Rosenblatt en 1957. Est√° dise√±ado para tareas de clasificaci√≥n binaria, es decir, para decidir si una entrada pertenece una de dos clases posibles. Su idea fundamental es modelar c√≥mo una neurona biol√≥gica podr√≠a tomar decisiones.El funcionamiento de un Perceptron es bastante directo:Entradas y Pesos: Recibe m√∫ltiples entradas (caracter√≠sticas) y cada entrada se le asigna un peso. Estos pesos representan la importancia de cada caracter√≠stica.Suma Ponderada: Las entradas se multiplican por sus respectivos pesos y se suman. esta suma se le a√±ade un t√©rmino de sesgo (bias).\n\\[z = \\sum_{=1}^{n} w_i x_i + b\\]\nDonde \\(x_i\\) son las entradas, \\(w_i\\) son los pesos, \\(b\\) es el sesgo, y \\(n\\) es el n√∫mero de entradas.Funci√≥n de Activaci√≥n: El resultado de la suma ponderada (\\(z\\)) se pasa trav√©s de una funci√≥n de activaci√≥n (generalmente una funci√≥n escal√≥n o step function). Esta funci√≥n decide la salida final, que es 1 si la suma excede un umbral (o 0 si lo excede). Para el Perceptron original, la salida es binaria.\n\\[\\text{salida} = \\begin{cases} 1 & \\text{si } z \\geq \\text{umbral} \\\\ 0 & \\text{si } z < \\text{umbral} \\end{cases}\\]Aprendizaje (Regla de Perceptron): El Perceptron aprende ajustando sus pesos de forma iterativa. Si la predicci√≥n es incorrecta, los pesos se actualizan para reducir el error en la siguiente iteraci√≥n. La regla de actualizaci√≥n de pesos es:\n\\[w_i^{\\text{nuevo}} = w_i^{\\text{anterior}} + \\alpha \\cdot (y - \\hat{y}) \\cdot x_i\\]\nDonde \\(\\alpha\\) es la tasa de aprendizaje, \\(y\\) es el valor real, y \\(\\hat{y}\\) es la predicci√≥n del Perceptron.En el contexto del aprendizaje global vs.¬†local, el Perceptron es un sistema de aprendizaje global por naturaleza. Busca encontrar un hiperplano de separaci√≥n lineal √∫nico que divida el espacio de caracter√≠sticas en dos regiones. La idea es que, si los datos son linealmente separables (es decir, si existe una l√≠nea, plano o hiperplano que puede separar perfectamente las dos clases), el Perceptron est√° garantizado para converger y encontrar esa soluci√≥n.Sin embargo, precisamente porque busca una soluci√≥n lineal global, si los datos se distribuyen linealmente (es decir, son linealmente separables), el Perceptron puede encontrar una soluci√≥n convergente y puede aprender la relaci√≥n. Esto ilustra la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù cuando se busca una soluci√≥n global r√≠gida. El Perceptron original puede aplicar el concepto de regresi√≥n ponderada localmente ni adaptarse complejidades lineales, diferencia de modelos posteriores como las redes neuronales multicapa con funciones de activaci√≥n lineales o los algoritmos de √°rboles de decisi√≥n. pesar de esta limitaci√≥n, el Perceptron sent√≥ las bases para el desarrollo posterior de redes neuronales m√°s complejas.","code":""},{"path":"redes-neuronales.html","id":"radial-basis-function-network-rbfn","chapter":"üß† 4. Redes Neuronales","heading":"Radial Basis Function Network (RBFN)","text":"Radial Basis Function Network (RBFN) es un tipo de red neuronal artificial que se utiliza tanto para tareas de clasificaci√≥n como de regresi√≥n. diferencia de las redes neuronales multicapa perceptr√≥n tradicionales que utilizan funciones de activaci√≥n sigmoide o ReLU, las RBFN emplean funciones de base radial como sus funciones de activaci√≥n en la capa oculta. Su estructura es t√≠picamente m√°s simple que un perceptr√≥n multicapa, consistiendo generalmente en tres capas: una capa de entrada, una capa oculta con neuronas de base radial, y una capa de salida.La idea fundamental de una RBFN radica en su capacidad para modelar relaciones lineales al mapear datos de entrada un espacio de caracter√≠sticas de mayor dimensi√≥n donde pueden ser linealmente separables (para clasificaci√≥n) o donde una funci√≥n lineal puede aproximar la relaci√≥n (para regresi√≥n). Esto se logra trav√©s de las neuronas de la capa oculta, cada una de las cuales representa un ‚Äúcentro‚Äù en el espacio de caracter√≠sticas.El funcionamiento de una RBFN implica:Capa de Entrada: Recibe las caracter√≠sticas de entrada.Capa Oculta (Neuronas de Base Radial): Cada neurona en esta capa tiene un centro (\\(c_i\\)) y un radio (o desviaci√≥n est√°ndar, \\(\\sigma_i\\)). La funci√≥n de activaci√≥n de estas neuronas (com√∫nmente una funci√≥n Gaussiana) calcula la distancia entre el vector de entrada (\\(x\\)) y el centro de la neurona (\\(c_i\\)), y luego aplica la funci√≥n de base radial. Cuanto m√°s cerca est√© la entrada del centro de la neurona, mayor ser√° la activaci√≥n de esa neurona.\n\\[\\phi_i(x) = \\exp\\left(-\\frac{\\|x - c_i\\|^2}{2\\sigma_i^2}\\right)\\]\nDonde \\(\\phi_i(x)\\) es la salida de la neurona \\(\\), \\(\\|x - c_i\\|\\) es la distancia euclidiana entre la entrada \\(x\\) y el centro \\(c_i\\), y \\(\\sigma_i\\) es el radio (ancho) de la funci√≥n Gaussiana.Capa de Salida: Las salidas de las neuronas de la capa oculta se combinan linealmente (ponderadas por unos coeficientes, \\(w_{ij}\\)) para producir la salida final de la red. Para regresi√≥n, es una suma ponderada; para clasificaci√≥n, menudo se usa una funci√≥n de activaci√≥n softmax.\n\\[y_j = \\sum_{=1}^{M} w_{ij}\\phi_i(x)\\]\nDonde \\(y_j\\) es la salida \\(j\\), \\(M\\) es el n√∫mero de neuronas ocultas, y \\(w_{ij}\\) son los pesos de la capa de salida.En el contexto del aprendizaje global vs.¬†local, las RBFN son intr√≠nsecamente sistemas de aprendizaje local. Cada neurona de la capa oculta es sensible una regi√≥n espec√≠fica del espacio de entrada, definida por su centro y su radio. La red como un todo es una combinaci√≥n de estas respuestas locales. Si los datos se distribuyen linealmente, el concepto de regresi√≥n (o clasificaci√≥n) se aplica de forma muy eficaz mediante esta naturaleza de regresi√≥n ponderada localmente. Las RBFN pueden aproximar cualquier funci√≥n continua con la suficiente cantidad de neuronas de base radial. Esto aborda directamente la desventaja de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en un solo modelo global, ya que la red puede adaptarse localmente las caracter√≠sticas de diferentes regiones del espacio de datos. Son particularmente √∫tiles para problemas de aproximaci√≥n de funciones, series de tiempo y reconocimiento de patrones.","code":""},{"path":"redes-neuronales.html","id":"recurrent-neural-networks-rnns","chapter":"üß† 4. Redes Neuronales","heading":"Recurrent Neural Networks (RNNs)","text":"Recurrent Neural Networks (RNNs) son un tipo de red neuronal artificial dise√±ado espec√≠ficamente para manejar datos secuenciales o temporales, donde la informaci√≥n de pasos anteriores en la secuencia es relevante para la predicci√≥n actual. diferencia de las redes de propagaci√≥n hacia adelante (como MLP o CNN) que asumen que las entradas son independientes entre s√≠, las RNNs tienen ‚Äúmemoria‚Äù o conexiones recurrentes que les permiten mantener un estado interno que encapsula informaci√≥n de pasos de tiempo anteriores. Esta caracter√≠stica las hace ideales para tareas como el procesamiento de lenguaje natural (PLN), el reconocimiento de voz, la traducci√≥n autom√°tica y la predicci√≥n de series de tiempo.La idea fundamental de una RNN es que una unidad recurrente aplica la misma funci√≥n de transformaci√≥n cada elemento de una secuencia, con la particularidad de que la salida de la unidad en un paso de tiempo dado se realimenta como entrada para el mismo proceso en el siguiente paso de tiempo. Esto permite que la red ‚Äúrecuerde‚Äù y utilice informaci√≥n pasada al procesar la secuencia actual.El funcionamiento b√°sico de una RNN en un paso de tiempo (\\(t\\)) implica:Entrada actual (\\(x_t\\)): El elemento actual de la secuencia.Estado oculto anterior (\\(h_{t-1}\\)): La ‚Äúmemoria‚Äù o estado interno de la red del paso de tiempo anterior.C√°lculo del Estado Oculto Actual (\\(h_t\\)): Se combina la entrada actual y el estado oculto anterior, y se aplica una funci√≥n de activaci√≥n (ej., tanh o ReLU).\n\\[h_t = f(W_{hh} h_{t-1} + W_{xh} x_t + b_h)\\]\nDonde \\(W_{hh}\\) son los pesos de la conexi√≥n recurrente, \\(W_{xh}\\) son los pesos de la entrada, y \\(b_h\\) es el sesgo.Salida Actual (\\(y_t\\)): Se genera una salida partir del estado oculto actual.\n\\[y_t = W_{hy} h_t + b_y\\]\nDonde \\(W_{hy}\\) son los pesos de la salida y \\(b_y\\) es el sesgo.Este proceso de actualizaci√≥n de estado y salida se repite para cada elemento de la secuencia. La ‚Äúmemoria‚Äù de la RNN est√° codificada en el estado oculto que se pasa de un paso de tiempo al siguiente.El entrenamiento de las RNNs se realiza mediante una variante del algoritmo de Back-Propagation llamada Back-Propagation Time (BPTT). BPTT desenrolla la red lo largo del tiempo, tratando cada paso de tiempo como una capa separada, y luego aplica la retropropagaci√≥n de manera similar c√≥mo se entrena un MLP, pero propagando los errores trav√©s de las conexiones recurrentes. Sin embargo, las RNNs simples pueden sufrir de problemas como el desvanecimiento del gradiente (vanishing gradient) o el explosi√≥n del gradiente (exploding gradient) para secuencias largas, lo que llev√≥ al desarrollo de arquitecturas m√°s avanzadas como LSTM (Long Short-Term Memory) y GRU (Gated Recurrent Unit).En el contexto del aprendizaje global vs.¬†local, las RNNs son sistemas de aprendizaje global que est√°n dise√±ados para aprender y modelar dependencias temporales y patrones secuenciales en un dominio global. diferencia de los m√©todos de regresi√≥n ponderada localmente como LOESS, que se enfocan en ajustar curvas en regiones espec√≠ficas de datos, las RNNs intentan aprender una funci√≥n de mapeo compleja que considera toda la secuencia hist√≥rica para producir una predicci√≥n. Si los datos (secuenciales) se distribuyen linealmente, las RNNs son extremadamente efectivas para capturar estas relaciones lineales y dependencias largo plazo. Al tener un estado interno que recuerda informaci√≥n pasada, abordan directamente la limitaci√≥n de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en modelos est√°ticos o lineales, ya que pueden adaptar sus predicciones din√°micamente en funci√≥n del contexto secuencial, lo que las convierte en una herramienta fundamental para el an√°lisis de series de tiempo y el procesamiento de lenguaje.","code":""},{"path":"redes-neuronales.html","id":"transformers","chapter":"üß† 4. Redes Neuronales","heading":"Transformers","text":"Los Transformers son una arquitectura de red neuronal profunda que ha revolucionado el campo del Procesamiento de Lenguaje Natural (PLN) y, m√°s recientemente, se ha expandido la visi√≥n por computadora y otras √°reas. Introducidos en el art√≠culo ‚ÄúAttention Need‚Äù (Vaswani et al., 2017), la idea fundamental de los Transformers es prescindir de la naturaleza recurrente de las RNNs y las convolucionales de las CNNs, bas√°ndose enteramente en un mecanismo llamado auto-atenci√≥n (self-attention) para capturar dependencias de largo alcance en las secuencias de entrada.Antes de los Transformers, las RNNs eran el modelo dominante para datos secuenciales. Sin embargo, las RNNs ten√≠an limitaciones como la dificultad para capturar dependencias muy largo plazo (problema del gradiente desvanecido) y la imposibilidad de paralelizar completamente el procesamiento de secuencias (debido su naturaleza secuencial). Los Transformers resuelven estos problemas al permitir que cada elemento de la secuencia interact√∫e directamente con todos los dem√°s elementos de la secuencia, sin importar su distancia.Los componentes clave de un Transformer incluyen:Mecanismo de Auto-Atenci√≥n (Self-Attention): Este es el coraz√≥n del Transformer. Para cada token (palabra) en una secuencia, el mecanismo de auto-atenci√≥n calcula una puntuaci√≥n de ‚Äúrelevancia‚Äù entre ese token y todos los dem√°s tokens de la secuencia. Esto permite que el modelo ‚Äúpese‚Äù la importancia de cada token al generar la representaci√≥n de otro token. Este proceso se implementa trav√©s de tres vectores para cada token: Query (Q), Key (K) y Value (V).\n\\[\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\\]\nDonde \\(d_k\\) es la dimensi√≥n de los vectores Key.Mecanismo de Auto-Atenci√≥n (Self-Attention): Este es el coraz√≥n del Transformer. Para cada token (palabra) en una secuencia, el mecanismo de auto-atenci√≥n calcula una puntuaci√≥n de ‚Äúrelevancia‚Äù entre ese token y todos los dem√°s tokens de la secuencia. Esto permite que el modelo ‚Äúpese‚Äù la importancia de cada token al generar la representaci√≥n de otro token. Este proceso se implementa trav√©s de tres vectores para cada token: Query (Q), Key (K) y Value (V).\n\\[\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\\]\nDonde \\(d_k\\) es la dimensi√≥n de los vectores Key.Atenci√≥n Multi-Cabeza (Multi-Head Attention): Para mejorar la capacidad del modelo de enfocarse en diferentes aspectos de la secuencia, el mecanismo de auto-atenci√≥n se aplica m√∫ltiples veces en paralelo con diferentes conjuntos de matrices de pesos (cabezas). Las salidas de estas cabezas se concatenan y se transforman linealmente.Atenci√≥n Multi-Cabeza (Multi-Head Attention): Para mejorar la capacidad del modelo de enfocarse en diferentes aspectos de la secuencia, el mecanismo de auto-atenci√≥n se aplica m√∫ltiples veces en paralelo con diferentes conjuntos de matrices de pesos (cabezas). Las salidas de estas cabezas se concatenan y se transforman linealmente.Capas Feed-Forward (Posici√≥n por Posici√≥n): Despu√©s del mecanismo de atenci√≥n, hay una red neuronal de propagaci√≥n hacia adelante (un MLP simple) que se aplica de forma independiente cada posici√≥n en la secuencia.Capas Feed-Forward (Posici√≥n por Posici√≥n): Despu√©s del mecanismo de atenci√≥n, hay una red neuronal de propagaci√≥n hacia adelante (un MLP simple) que se aplica de forma independiente cada posici√≥n en la secuencia.Codificador-Decodificador (Encoder-Decoder Architecture): El Transformer original consta de un codificador y un decodificador.\nEl codificador toma la secuencia de entrada y genera una representaci√≥n. Consiste en m√∫ltiples capas id√©nticas, cada una con una capa de auto-atenci√≥n multi-cabeza y una capa feed-forward.\nEl decodificador toma la representaci√≥n del codificador y genera la secuencia de salida (por ejemplo, la traducci√≥n). Tambi√©n consiste en m√∫ltiples capas, cada una con auto-atenci√≥n multi-cabeza, atenci√≥n multi-cabeza (que atiende la salida del codificador) y una capa feed-forward.\nCodificador-Decodificador (Encoder-Decoder Architecture): El Transformer original consta de un codificador y un decodificador.El codificador toma la secuencia de entrada y genera una representaci√≥n. Consiste en m√∫ltiples capas id√©nticas, cada una con una capa de auto-atenci√≥n multi-cabeza y una capa feed-forward.El decodificador toma la representaci√≥n del codificador y genera la secuencia de salida (por ejemplo, la traducci√≥n). Tambi√©n consiste en m√∫ltiples capas, cada una con auto-atenci√≥n multi-cabeza, atenci√≥n multi-cabeza (que atiende la salida del codificador) y una capa feed-forward.Codificaci√≥n Posicional (Positional Encoding): Dado que los Transformers procesan secuencias en paralelo y tienen una noci√≥n inherente de la posici√≥n de los tokens (diferencia de las RNNs), se a√±ade informaci√≥n de la posici√≥n de cada token sus incrustaciones de entrada.Codificaci√≥n Posicional (Positional Encoding): Dado que los Transformers procesan secuencias en paralelo y tienen una noci√≥n inherente de la posici√≥n de los tokens (diferencia de las RNNs), se a√±ade informaci√≥n de la posici√≥n de cada token sus incrustaciones de entrada.En el contexto del aprendizaje global vs.¬†local, los Transformers son un sistema de aprendizaje global que, gracias su mecanismo de atenci√≥n, pueden aprender dependencias largo alcance y relaciones complejas que son inherentemente globales en la secuencia. Aunque los c√°lculos individuales de atenci√≥n pueden verse como una forma de ponderaci√≥n de la importancia local de los tokens, la red en su conjunto construye una representaci√≥n global de la secuencia. Si los datos (secuenciales) se distribuyen linealmente, los Transformers son excepcionalmente capaces de modelar estas relaciones lineales y dependencias trav√©s de su capacidad para ‚Äúobservar‚Äù toda la secuencia la vez y ponderar la relevancia de cada parte. Esto resuelve de manera fundamental la limitaci√≥n de que ‚Äúveces ning√∫n valor de par√°metro puede proporcionar una aproximaci√≥n suficientemente buena‚Äù en modelos secuenciales anteriores, ya que la arquitectura de atenci√≥n les permite aprender patrones complejos y lineales en datos secuenciales sin las restricciones de memoria de las RNNs, lo que los convierte en la arquitectura dominante para tareas de PLN avanzadas.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"reducci√≥n-de-dimensionalidad","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"üß© 5. Reducci√≥n de Dimensionalidad","text":"Ejemplos: PCA (An√°lisis de Componentes Principales), t-SNE, UMAP.Uso: Fundamental para visualizar datos de alta dimensi√≥n, haci√©ndolos m√°s comprensibles. Tambi√©n es un paso clave de preprocesamiento para eliminar ruido o multicolinealidad antes de aplicar otros modelos.Ventajas: Puede mejorar significativamente el rendimiento y la velocidad de otros algoritmos de machine learning.Limitaciones: veces se pierde la interpretabilidad de los datos originales y siempre garantiza una mejora en el desempe√±o de los modelos.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"flexible-discriminant-analysis-fda","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Flexible Discriminant Analysis (FDA)","text":"Flexible Discriminant Analysis (FDA) es un m√©todo de clasificaci√≥n que generaliza el An√°lisis Discriminante Lineal (LDA) para manejar relaciones lineales entre las variables predictoras y las clases. diferencia de LDA, que asume l√≠mites de decisi√≥n lineales y distribuciones gaussianas con matrices de covarianza iguales, FDA es mucho m√°s adaptable.FDA logra esta flexibilidad al combinar dos conceptos:\n1. Optimal Scoring: Transforma las variables de respuesta categ√≥ricas en valores num√©ricos (scores √≥ptimos) de manera que las clases sean m√°s f√°cilmente separables linealmente.\n2. Modelos de Regresi√≥n Param√©tricos: En lugar de usar una regresi√≥n lineal simple (como en LDA), FDA utiliza m√©todos de regresi√≥n param√©tricos m√°s flexibles, como las Multivariate Adaptive Regression Splines (MARS). Esto permite que la relaci√≥n entre las variables transformadas y los scores √≥ptimos sea lineal, lo que su vez se traduce en fronteras de decisi√≥n lineales en el espacio original de los datos.Es decir, FDA toma los datos, los transforma de una manera inteligente para que sean m√°s f√°ciles de separar, y luego aplica una discriminaci√≥n lineal en ese espacio transformado, lo que resulta en una frontera de decisi√≥n compleja y flexible en el espacio original.En el contexto del aprendizaje global vs.¬†local, FDA se considera un modelo que integra aspectos de ambos.Aspecto Global: El objetivo final de FDA es encontrar una funci√≥n discriminante global que separe las clases en el espacio transformado. Los scores √≥ptimos y las funciones base del m√©todo de regresi√≥n (como MARS) se aprenden considerando la estructura general de los datos para lograr la mejor separaci√≥n nivel global. El modelo resultante es una funci√≥n que se aplica de manera consistente cualquier nueva observaci√≥n.Aspecto Global: El objetivo final de FDA es encontrar una funci√≥n discriminante global que separe las clases en el espacio transformado. Los scores √≥ptimos y las funciones base del m√©todo de regresi√≥n (como MARS) se aprenden considerando la estructura general de los datos para lograr la mejor separaci√≥n nivel global. El modelo resultante es una funci√≥n que se aplica de manera consistente cualquier nueva observaci√≥n.Aspecto Local (debido al uso de modelos param√©tricos como MARS): La flexibilidad de FDA proviene de su uso de m√©todos como MARS, que dividen el espacio de las caracter√≠sticas en regiones locales y ajustan relaciones simples dentro de cada una. Esto permite que el modelo se adapte linealidades y cambios en la relaci√≥n entre las variables en diferentes partes del espacio de datos. As√≠, si los datos se distribuyen linealmente, FDA puede construir fronteras de decisi√≥n que capturan esas complejidades al ‚Äúlocalizar‚Äù las relaciones importantes.Aspecto Local (debido al uso de modelos param√©tricos como MARS): La flexibilidad de FDA proviene de su uso de m√©todos como MARS, que dividen el espacio de las caracter√≠sticas en regiones locales y ajustan relaciones simples dentro de cada una. Esto permite que el modelo se adapte linealidades y cambios en la relaci√≥n entre las variables en diferentes partes del espacio de datos. As√≠, si los datos se distribuyen linealmente, FDA puede construir fronteras de decisi√≥n que capturan esas complejidades al ‚Äúlocalizar‚Äù las relaciones importantes.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"linear-discriminant-analysis-lda","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Linear Discriminant Analysis (LDA)","text":"El An√°lisis Discriminante Lineal (LDA) es un m√©todo de clasificaci√≥n y reducci√≥n de dimensionalidad utilizado para encontrar una combinaci√≥n lineal de caracter√≠sticas que mejor separe dos o m√°s clases de objetos o eventos. Su objetivo principal es modelar la diferencia entre las clases, lo que lo hace muy √∫til para tareas de clasificaci√≥n supervisada.LDA funciona proyectando los puntos de datos un espacio de menor dimensi√≥n (generalmente una o pocas dimensiones) de tal manera que las clases est√©n lo m√°s separadas posible. Para lograr esto, busca una direcci√≥n (un eje) que maximice la separaci√≥n entre las medias de las clases (varianza entre clases) mientras minimiza la varianza dentro de cada clase (varianza intraclase). En un problema de clasificaci√≥n binaria, esto significa encontrar la l√≠nea √≥ptima para proyectar los datos de modo que las dos clases se superpongan lo menos posible.diferencia de modelos como la Regresi√≥n Log√≠stica, que buscan modelar la probabilidad de pertenencia una clase, LDA modela directamente la distribuci√≥n de los datos dentro de cada clase y luego utiliza el Teorema de Bayes para asignar una nueva observaci√≥n la clase m√°s probable. LDA asume que las varianzas (o matrices de covarianza) de las clases son iguales y que los datos est√°n distribuidos normalmente.Aprendizaje Global vs.¬†Local:El An√°lisis Discriminante Lineal (LDA) es un modelo de aprendizaje puramente global.Aspecto Global: LDA busca una √∫nica transformaci√≥n lineal o un conjunto de direcciones (ejes) que se aplican todos los datos para lograr la m√°xima separaci√≥n entre las clases en un espacio de menor dimensi√≥n. La frontera de decisi√≥n que resulta de LDA es siempre lineal y se define globalmente partir de las medias y las varianzas combinadas (asumidas como iguales) de todas las clases. El modelo es ‚Äúfijo‚Äù y se aplica uniformemente cualquier nueva observaci√≥n, sin importar su ubicaci√≥n espec√≠fica en el espacio de caracter√≠sticas. se ajustan modelos diferentes para distintos vecindarios de datos, sino que se aprende una regla de separaci√≥n que es v√°lida para todo el dominio.Por lo tanto, si los datos se distribuyen linealmente o las fronteras de decisi√≥n entre las clases son inherentemente lineales (por ejemplo, si una clase rodea otra), LDA puede ser el m√©todo m√°s adecuado. En esos escenarios, modelos de aprendizaje local o m√°s flexibles (como los √°rboles de decisi√≥n, SVM con kernels lineales, o FDA que extiende LDA para linealidades) suelen ofrecer un mejor rendimiento.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"mixture-discriminant-analysis-mda","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Mixture Discriminant Analysis (MDA)","text":"El An√°lisis Discriminante de Mezclas (MDA) es una extensi√≥n del An√°lisis Discriminante Lineal (LDA) y del An√°lisis Discriminante Cuadr√°tico (QDA) que aborda la limitaci√≥n de que estas t√©cnicas asumen que cada clase proviene de una √∫nica distribuci√≥n normal (o gaussiana). MDA relaja esta suposici√≥n al permitir que cada clase sea modelada como una mezcla de m√∫ltiples distribuciones gaussianas. Esto le otorga una capacidad significativamente mayor para manejar clases con formas complejas o multimodales, que pueden ser descritas adecuadamente por una sola distribuci√≥n normal.MDA funciona de la siguiente manera:Modelado por Componentes de Mezcla: Para cada clase, MDA estima los par√°metros (media y matriz de covarianza) de varias distribuciones gaussianas (‚Äúcomponentes de mezcla‚Äù) en lugar de solo una. Es similar al proceso de agrupamiento de mezclas gaussianas (Gaussian Mixture Models - GMM) aplicado dentro de cada clase.Asignaci√≥n la Clase: Una vez que se han modelado las distribuciones de mezcla para cada clase, para una nueva observaci√≥n, MDA calcula la probabilidad de que esa observaci√≥n pertenezca cada componente de mezcla en cada clase. Luego, asigna la observaci√≥n la clase que maximiza la probabilidad posterior, es decir, la clase que es m√°s probable que haya generado esa observaci√≥n.Fronteras de Decisi√≥n Flexibles: Al modelar cada clase como una mezcla de gaussianas, MDA puede generar fronteras de decisi√≥n que son mucho m√°s flexibles y lineales que las de LDA (que son lineales) o QDA (que son cuadr√°ticas). Esto le permite adaptarse clases con estructuras complejas, que pueden tener ‚Äúagrupaciones‚Äù internas o formas irregulares.Los par√°metros del modelo (las medias, covarianzas y pesos de los componentes de mezcla para cada clase) se suelen estimar utilizando un algoritmo iterativo como la Maximizaci√≥n de Expectativas (Expectation-Maximization - EM).Aprendizaje Global vs.¬†Local:El An√°lisis Discriminante de Mezclas (MDA) se encuentra en un punto intermedio, inclin√°ndose hacia un modelo que combina aspectos de aprendizaje global y local, con una mayor flexibilidad para capturar la estructura local de los datos en comparaci√≥n con LDA o QDA.Aspecto Global: Al igual que LDA, el objetivo final de MDA es crear un clasificador global que pueda asignar cualquier nueva observaci√≥n una de las clases. Las distribuciones de mezcla para cada clase se aprenden partir de todo el conjunto de datos de entrenamiento para esas clases, y el clasificador resultante se aplica de manera consistente en todo el espacio de caracter√≠sticas. La regla de decisi√≥n final es una funci√≥n que se deriva de las distribuciones aprendidas para todas las clases.Aspecto Global: Al igual que LDA, el objetivo final de MDA es crear un clasificador global que pueda asignar cualquier nueva observaci√≥n una de las clases. Las distribuciones de mezcla para cada clase se aprenden partir de todo el conjunto de datos de entrenamiento para esas clases, y el clasificador resultante se aplica de manera consistente en todo el espacio de caracter√≠sticas. La regla de decisi√≥n final es una funci√≥n que se deriva de las distribuciones aprendidas para todas las clases.Aspecto Local: La ‚Äúflexibilidad‚Äù de MDA y su capacidad para manejar linealidades proviene de su suposici√≥n de que cada clase puede estar compuesta por m√∫ltiples componentes gaussianos. Esto significa que, dentro de una misma clase, puede haber sub-agrupaciones o densidades locales que son modeladas individualmente. Al permitir estas m√∫ltiples distribuciones gaussianas dentro de cada clase, MDA puede adaptarse mejor las caracter√≠sticas y densidades de los datos en diferentes vecindarios o subregiones del espacio de caracter√≠sticas. Si los datos se distribuyen linealmente y tienen formas complejas (como clusters separados dentro de una clase), MDA puede ‚Äúlocalizar‚Äù y modelar estas estructuras, llevando fronteras de decisi√≥n mucho m√°s complejas y lineales que se ajustan mejor la forma real de las clases.Aspecto Local: La ‚Äúflexibilidad‚Äù de MDA y su capacidad para manejar linealidades proviene de su suposici√≥n de que cada clase puede estar compuesta por m√∫ltiples componentes gaussianos. Esto significa que, dentro de una misma clase, puede haber sub-agrupaciones o densidades locales que son modeladas individualmente. Al permitir estas m√∫ltiples distribuciones gaussianas dentro de cada clase, MDA puede adaptarse mejor las caracter√≠sticas y densidades de los datos en diferentes vecindarios o subregiones del espacio de caracter√≠sticas. Si los datos se distribuyen linealmente y tienen formas complejas (como clusters separados dentro de una clase), MDA puede ‚Äúlocalizar‚Äù y modelar estas estructuras, llevando fronteras de decisi√≥n mucho m√°s complejas y lineales que se ajustan mejor la forma real de las clases.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"multidimensional-scaling-mds","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Multidimensional Scaling (MDS)","text":"El Escalamiento Multidimensional (MDS) es una t√©cnica de reducci√≥n de dimensionalidad utilizada para visualizar y explorar las similitudes o disimilitudes entre un conjunto de objetos. Su objetivo principal es tomar datos de alta dimensi√≥n, donde las relaciones entre los puntos pueden ser dif√≠ciles de entender, y representarlos en un espacio de menor dimensi√≥n (t√≠picamente 2D o 3D) de tal manera que las distancias entre los puntos en el nuevo espacio reflejen lo m√°s fielmente posible las distancias (o disimilitudes) originales entre los objetos.Imagina que tienes una tabla de distancias de viaje entre varias ciudades. MDS intentar√≠a dibujar un mapa de esas ciudades donde las distancias en el mapa se correspondieran lo m√°s posible con las distancias de la tabla.El proceso general de MDS implica:Matriz de Disimilitud: Se necesita una matriz que contenga las disimilitudes (distancias) entre cada par de objetos. Estas disimilitudes pueden ser distancias euclidianas, correlaciones, o cualquier otra medida de qu√© tan diferentes (o similares) son dos objetos.Optimizaci√≥n: El algoritmo busca una configuraci√≥n de puntos en el espacio de menor dimensi√≥n que minimice una funci√≥n de ‚Äúestr√©s‚Äù o ‚Äúajuste‚Äù. Esta funci√≥n mide qu√© tan bien las distancias en el espacio reducido se corresponden con las disimilitudes originales. Una funci√≥n de estr√©s baja indica un buen ajuste.Visualizaci√≥n: Los puntos resultantes en el espacio de menor dimensi√≥n pueden ser graficados para revelar patrones, clusters o la estructura subyacente de los datos que eran evidentes en las dimensiones originales.Existen varias variantes de MDS, como el MDS Cl√°sico (o M√©trica), que asume que las disimilitudes son distancias euclidianas y busca una soluci√≥n anal√≠tica, y el MDS -M√©trico, que solo busca preservar el orden de las disimilitudes (es decir, si es m√°s diferente de B que de C, esa relaci√≥n se mantendr√° en el espacio reducido, sin que las distancias exactas tengan que ser iguales).Aprendizaje Global vs.¬†Local:El Escalamiento Multidimensional (MDS) se considera predominantemente una t√©cnica de aprendizaje global.Aspecto Global: MDS busca una configuraci√≥n √∫nica de puntos en el espacio de baja dimensi√≥n que optimice el ajuste de todas las disimilitudes en el conjunto de datos de manera simult√°nea. La funci√≥n de estr√©s que se minimiza considera las distancias entre todos los pares de puntos, buscando una soluci√≥n que sea globalmente la mejor representaci√≥n de esas relaciones. El objetivo es preservar la estructura general de las distancias en el conjunto de datos completo, solo las relaciones en vecindarios espec√≠ficos. La soluci√≥n que se encuentra es una ‚Äúvista a√©rea‚Äù o un ‚Äúmapa‚Äù de las relaciones de todo el conjunto de datos.Aunque las disimilitudes originales son ‚Äúlocales‚Äù en el sentido de que son medidas entre pares de puntos, la forma en que MDS utiliza todas estas medidas para construir un mapa coherente y de baja dimensi√≥n es un proceso global de optimizaci√≥n. se ajustan modelos separados para diferentes subconjuntos de datos; en su lugar, se busca una representaci√≥n unificada que capture la estructura general de similaridad/disimilitud de todos los datos. Por lo tanto, si los datos tienen una estructura global bien definida basada en distancias, MDS es una herramienta efectiva para revelar esa estructura.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"quadratic-discriminant-analysis-qda","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Quadratic Discriminant Analysis (QDA)","text":"El An√°lisis Discriminante Cuadr√°tico (QDA) es un m√©todo de clasificaci√≥n que, al igual que el An√°lisis Discriminante Lineal (LDA), modela la distribuci√≥n de cada clase para clasificar nuevas observaciones. Sin embargo, QDA es una extensi√≥n de LDA que relaja una de sus suposiciones clave: mientras que LDA asume que todas las clases comparten la misma matriz de covarianza (es decir, las distribuciones tienen la misma ‚Äúforma‚Äù o ‚Äúorientaci√≥n‚Äù), QDA permite que cada clase tenga su propia matriz de covarianza distinta.Esta diferencia es fundamental:\n* LDA: Asume que la variaci√≥n de los datos es la misma en todas las clases, lo que resulta en fronteras de decisi√≥n lineales entre las clases.\n* QDA: Permite que la variaci√≥n de los datos sea diferente para cada clase, lo que resulta en fronteras de decisi√≥n cuadr√°ticas entre las clases. Esto significa que las fronteras de decisi√≥n pueden ser curvas (elipsoides, par√°bolas, hip√©rbolas), lo que permite QDA modelar relaciones m√°s complejas y lineales entre las variables y las clases.El funcionamiento de QDA implica:\n1. Modelado de Distribuciones: Para cada clase, QDA estima la media y la matriz de covarianza espec√≠ficas de esa clase, asumiendo una distribuci√≥n normal multivariada.\n2. Clasificaci√≥n: Para una nueva observaci√≥n, QDA calcula la probabilidad de que esa observaci√≥n provenga de cada clase, utilizando las distribuciones normales modeladas para cada clase. Luego, asigna la observaci√≥n la clase con la probabilidad posterior m√°s alta (aplicando el Teorema de Bayes).Aprendizaje Global vs.¬†Local:El An√°lisis Discriminante Cuadr√°tico (QDA) es, al igual que LDA, un modelo de aprendizaje global.Aspecto Global: QDA construye un clasificador global basado en las distribuciones de probabilidad aprendidas para cada clase. Las medias y las matrices de covarianza se estiman partir de todo el conjunto de datos de entrenamiento para cada clase, y estos par√°metros definen una funci√≥n discriminante que se aplica de manera uniforme cualquier nueva observaci√≥n en el espacio de caracter√≠sticas. La frontera de decisi√≥n, aunque cuadr√°tica y lineal, es una √∫nica funci√≥n matem√°tica definida nivel global por los par√°metros del modelo. se ajustan modelos separados para diferentes vecindarios de datos.Aspecto Global: QDA construye un clasificador global basado en las distribuciones de probabilidad aprendidas para cada clase. Las medias y las matrices de covarianza se estiman partir de todo el conjunto de datos de entrenamiento para cada clase, y estos par√°metros definen una funci√≥n discriminante que se aplica de manera uniforme cualquier nueva observaci√≥n en el espacio de caracter√≠sticas. La frontera de decisi√≥n, aunque cuadr√°tica y lineal, es una √∫nica funci√≥n matem√°tica definida nivel global por los par√°metros del modelo. se ajustan modelos separados para diferentes vecindarios de datos.Mayor Flexibilidad Globalmente: Aunque sigue siendo un modelo global, la capacidad de QDA para tener matrices de covarianza separadas para cada clase le otorga una mayor flexibilidad para adaptarse formas de clase m√°s diversas en comparaci√≥n con LDA. Esto significa que QDA puede modelar situaciones donde las clases tienen diferentes orientaciones o dispersiones en el espacio de caracter√≠sticas, lo que resulta en fronteras de decisi√≥n que pueden capturar ciertas linealidades de manera global. Sin embargo, sigue asumiendo distribuciones gaussianas para cada clase y una forma cuadr√°tica para las fronteras, lo que puede ser una limitaci√≥n si la verdadera complejidad de los datos es a√∫n mayor o se ajusta estas suposiciones.Mayor Flexibilidad Globalmente: Aunque sigue siendo un modelo global, la capacidad de QDA para tener matrices de covarianza separadas para cada clase le otorga una mayor flexibilidad para adaptarse formas de clase m√°s diversas en comparaci√≥n con LDA. Esto significa que QDA puede modelar situaciones donde las clases tienen diferentes orientaciones o dispersiones en el espacio de caracter√≠sticas, lo que resulta en fronteras de decisi√≥n que pueden capturar ciertas linealidades de manera global. Sin embargo, sigue asumiendo distribuciones gaussianas para cada clase y una forma cuadr√°tica para las fronteras, lo que puede ser una limitaci√≥n si la verdadera complejidad de los datos es a√∫n mayor o se ajusta estas suposiciones.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"partial-least-squares-regression-plsr","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Partial Least Squares Regression (PLSR)","text":"Partial Least Squares Regression (PLSR) es una t√©cnica de regresi√≥n multivariada que combina caracter√≠sticas de la regresi√≥n por m√≠nimos cuadrados ordinarios (OLS) y el an√°lisis de componentes principales (PCA). Se utiliza para modelar la relaci√≥n entre un conjunto de variables predictoras (X) y uno o m√°s conjuntos de variables de respuesta (Y), siendo particularmente √∫til en situaciones donde hay un gran n√∫mero de variables predictoras, multicolinealidad (altas correlaciones entre las variables predictoras), o cuando el n√∫mero de predictoras excede el n√∫mero de observaciones.La idea fundamental de PLSR es encontrar un conjunto de componentes latentes (tambi√©n conocidos como ‚Äúfactores‚Äù o ‚Äúvariables latentes‚Äù) tanto en el espacio de las variables X como en el de las variables Y. Estos componentes se construyen de tal manera que maximizan la covarianza entre las variables predictoras y las variables de respuesta. diferencia de PCA, que solo busca componentes que expliquen la m√°xima varianza en X, PLSR busca componentes que sean relevantes para explicar la varianza en X y que tambi√©n est√©n altamente correlacionados con Y. Una vez que se extraen estos componentes, se realiza una regresi√≥n de m√≠nimos cuadrados ordinarios de Y sobre estos componentes latentes.El proceso general de PLSR implica:Extracci√≥n de Componentes Latentes: PLSR construye iterativamente un conjunto de componentes latentes. En cada paso:\nIdentifica una combinaci√≥n lineal de las variables X (un componente de X) y una combinaci√≥n lineal de las variables Y (un componente de Y) que tienen la mayor covarianza entre s√≠.\nEstos componentes representan las direcciones en el espacio de datos que explican la mayor cantidad de la relaci√≥n entre X y Y.\nUna vez que se extrae un componente, la varianza explicada por ese componente se ‚Äúdeflacta‚Äù (se elimina) de las matrices X e Y, y el proceso se repite con los residuos para encontrar el siguiente componente ortogonal.\nIdentifica una combinaci√≥n lineal de las variables X (un componente de X) y una combinaci√≥n lineal de las variables Y (un componente de Y) que tienen la mayor covarianza entre s√≠.Estos componentes representan las direcciones en el espacio de datos que explican la mayor cantidad de la relaci√≥n entre X y Y.Una vez que se extrae un componente, la varianza explicada por ese componente se ‚Äúdeflacta‚Äù (se elimina) de las matrices X e Y, y el proceso se repite con los residuos para encontrar el siguiente componente ortogonal.Regresi√≥n: Una vez que se ha determinado el n√∫mero √≥ptimo de componentes latentes (menudo trav√©s de validaci√≥n cruzada), se realiza una regresi√≥n lineal est√°ndar de las variables Y sobre estos componentes latentes de X.Ventajas clave de PLSR:Manejo de Multicolinealidad: Es muy efectivo en la reducci√≥n de dimensionalidad y el manejo de predictoras altamente correlacionadas, donde la regresi√≥n OLS fallar√≠a o producir√≠a estimaciones inestables.Manejo de Datos de Alta Dimensionalidad: Funciona bien cuando el n√∫mero de variables predictoras es mayor que el n√∫mero de observaciones.Enfoque Predictivo: Se centra en desarrollar modelos con una fuerte capacidad predictiva.Aprendizaje Global vs.¬†Local:La Regresi√≥n por M√≠nimos Cuadrados Parciales (PLSR) se considera un modelo de aprendizaje global.Aspecto Global: PLSR construye un modelo lineal global que relaciona las variables predictoras con la variable de respuesta trav√©s de sus componentes latentes. Los componentes PLS se derivan de la estructura de covarianza de todas las variables (tanto predictoras como de respuesta) en el conjunto de datos completo, y el modelo de regresi√≥n final se ajusta sobre estos componentes, generando una ecuaci√≥n que se aplica de manera consistente cualquier nueva observaci√≥n. se ajustan modelos separados para diferentes vecindarios de datos; en cambio, se busca una transformaci√≥n global de los datos que facilite la predicci√≥n.Si bien PLSR es un m√©todo de regresi√≥n ponderada localmente como LOESS (que ajusta modelos simples subconjuntos locales de datos), comparte con ellos el objetivo de modelar relaciones complejas. Sin embargo, lo hace de una manera diferente. En lugar de dividir el espacio de caracter√≠sticas y aplicar modelos locales, PLSR transforma el espacio de caracter√≠sticas de forma global para encontrar una representaci√≥n de menor dimensionalidad que sea √≥ptima para la predicci√≥n. Cuando los datos se distribuyen linealmente, PLSR puede ser la herramienta m√°s adecuada en su forma lineal b√°sica, ya que sigue siendo una t√©cnica lineal. Sin embargo, al encontrar las direcciones m√°s relevantes en el espacio de los datos, puede capturar aspectos importantes de la estructura de los datos que son √∫tiles incluso si la relaci√≥n subyacente es lineal. Para manejar la linealidad expl√≠citamente, existen extensiones como Nonlinear Partial Least Squares (NPLS) o Kernel PLS (KPLS), que introducen funciones kernel para mapear los datos un espacio de caracter√≠sticas de mayor dimensi√≥n donde la relaci√≥n podr√≠a ser linealmente modelable por PLS.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"partial-least-squares-discriminant-analysis-plsda","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Partial Least Squares Discriminant Analysis (PLSDA)","text":"El An√°lisis Discriminante de M√≠nimos Cuadrados Parciales (PLSDA) es una extensi√≥n del algoritmo de Regresi√≥n por M√≠nimos Cuadrados Parciales (PLSR), adaptada para problemas de clasificaci√≥n. Al igual que PLSR, PLSDA es particularmente √∫til cuando se tienen muchas variables predictoras (X) y estas est√°n altamente correlacionadas (multicolinealidad), situaciones comunes en campos como la metabol√≥mica, la prote√≥mica o la espectroscopia.En esencia, PLSDA transforma un problema de clasificaci√≥n en un problema de regresi√≥n. Esto se logra de la siguiente manera:Codificaci√≥n de la Variable de Clase: La variable de respuesta categ√≥rica (la clase la que pertenece una observaci√≥n) se transforma en una o m√°s variables num√©ricas. Por ejemplo, en un problema de clasificaci√≥n binaria, una clase puede codificarse como ‚Äò0‚Äô y la otra como ‚Äò1‚Äô. Para m√∫ltiples clases, se puede usar una codificaci√≥n ‚Äúone-hot encoding‚Äù (ej., [1,0,0] para Clase , [0,1,0] para Clase B, etc.).Extracci√≥n de Componentes Latentes: Similar PLSR, PLSDA construye componentes latentes (factores PLS) que son combinaciones lineales de las variables predictoras. Estos componentes se eligen para maximizar la covarianza entre las variables predictoras y las variables de respuesta codificadas. Esto asegura que los componentes capturen la varianza en X que es relevante para la separaci√≥n de clases en Y.Clasificaci√≥n: Una vez que se han obtenido los componentes PLS y se ha realizado la regresi√≥n sobre ellos para predecir los valores codificados de la clase, se aplica una regla de decisi√≥n (por ejemplo, un umbral o un clasificador lineal simple) las predicciones para asignar cada observaci√≥n una clase. Si se usa codificaci√≥n one-hot, la observaci√≥n se asigna la clase con el valor predicho m√°s alto.PLSDA es ventajoso porque puede manejar conjuntos de datos con muchas m√°s variables que observaciones (problemas \\(p \\gg n\\)), y es robusto la multicolinealidad.Aprendizaje Global vs.¬†Local:El An√°lisis Discriminante de M√≠nimos Cuadrados Parciales (PLSDA) es un modelo de aprendizaje global.Aspecto Global: PLSDA busca una transformaci√≥n lineal global de las variables predictoras componentes latentes, y luego una relaci√≥n lineal global entre esos componentes y la variable de respuesta codificada (clase). Los componentes PLS se derivan de la estructura de covarianza de todo el conjunto de datos, y el modelo de regresi√≥n final (que se usa para la clasificaci√≥n) se aplica de manera consistente cualquier nueva observaci√≥n. La frontera de decisi√≥n impl√≠cita en PLSDA es t√≠picamente lineal en el espacio de los componentes PLS (y por lo tanto lineal o una combinaci√≥n lineal de las variables originales), lo que resulta en un clasificador que opera globalmente en el espacio de caracter√≠sticas.Aspecto Global: PLSDA busca una transformaci√≥n lineal global de las variables predictoras componentes latentes, y luego una relaci√≥n lineal global entre esos componentes y la variable de respuesta codificada (clase). Los componentes PLS se derivan de la estructura de covarianza de todo el conjunto de datos, y el modelo de regresi√≥n final (que se usa para la clasificaci√≥n) se aplica de manera consistente cualquier nueva observaci√≥n. La frontera de decisi√≥n impl√≠cita en PLSDA es t√≠picamente lineal en el espacio de los componentes PLS (y por lo tanto lineal o una combinaci√≥n lineal de las variables originales), lo que resulta en un clasificador que opera globalmente en el espacio de caracter√≠sticas.Enfoque en la Relevancia Global: Aunque reduce la dimensionalidad y selecciona componentes que son relevantes para la respuesta, la soluci√≥n final es un mapeo y una regla de decisi√≥n que son v√°lidos para todo el dominio de los datos. ajusta modelos locales para diferentes regiones del espacio de caracter√≠sticas. Por lo tanto, PLSDA es una t√©cnica eficiente para encontrar patrones globales de separaci√≥n de clases en presencia de alta dimensionalidad y multicolinealidad, pero si las relaciones entre las variables y las clases son inherentemente lineales o tienen estructuras muy complejas que pueden ser capturadas por una transformaci√≥n lineal, su capacidad puede ser limitada.Enfoque en la Relevancia Global: Aunque reduce la dimensionalidad y selecciona componentes que son relevantes para la respuesta, la soluci√≥n final es un mapeo y una regla de decisi√≥n que son v√°lidos para todo el dominio de los datos. ajusta modelos locales para diferentes regiones del espacio de caracter√≠sticas. Por lo tanto, PLSDA es una t√©cnica eficiente para encontrar patrones globales de separaci√≥n de clases en presencia de alta dimensionalidad y multicolinealidad, pero si las relaciones entre las variables y las clases son inherentemente lineales o tienen estructuras muy complejas que pueden ser capturadas por una transformaci√≥n lineal, su capacidad puede ser limitada.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"principal-component-analysis-pca","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Principal Component Analysis (PCA)","text":"El An√°lisis de Componentes Principales (PCA) es una t√©cnica fundamental de reducci√≥n de dimensionalidad supervisada. Su objetivo principal es simplificar conjuntos de datos complejos con muchas variables, transform√°ndolos en un conjunto m√°s peque√±o de nuevas variables, llamadas componentes principales, sin perder demasiada informaci√≥n. Estos componentes principales son combinaciones lineales de las variables originales y son ortogonales (correlacionados) entre s√≠.PCA funciona identificando las direcciones en el espacio de datos donde la varianza es m√°xima. La primera componente principal (PC1) captura la mayor cantidad de varianza posible en los datos. La segunda componente principal (PC2) captura la mayor varianza restante, sujeta ser ortogonal la primera, y as√≠ sucesivamente. De esta manera, PCA organiza la varianza en los datos en un conjunto jer√°rquico de componentes.Los usos comunes de PCA incluyen:\n* Reducci√≥n de dimensionalidad: Disminuir el n√∫mero de variables en un dataset, lo que puede acelerar los algoritmos de Machine Learning y reducir el riesgo de sobreajuste.\n* Visualizaci√≥n de datos: Proyectar datos de alta dimensi√≥n en 2D o 3D para facilitar su visualizaci√≥n y la identificaci√≥n de patrones, clusters o outliers.\n* Denoising: Eliminar el ruido de los datos al retener solo los componentes principales que capturan la se√±al real.Aprendizaje Global vs.¬†Local:El An√°lisis de Componentes Principales (PCA) es un modelo de aprendizaje puramente global.Aspecto Global: PCA busca una transformaci√≥n lineal global del espacio de caracter√≠sticas. Los componentes principales se derivan de la matriz de covarianza (o correlaci√≥n) de todo el conjunto de datos. Esto significa que las direcciones de m√°xima varianza se determinan considerando la estructura de dispersi√≥n general de todos los puntos de datos. El conjunto de componentes principales que se obtiene es un sistema de coordenadas global al que se proyecta cualquier punto de datos. se ajustan diferentes transformaciones para distintas regiones o vecindarios de datos; en su lugar, se aprende una √∫nica proyecci√≥n que se aplica uniformemente todo el dominio.Por lo tanto, si la estructura de los datos es consistentemente lineal o tiene relaciones de varianza que se extienden linealmente lo largo del espacio, PCA funcionar√° muy bien. Sin embargo, si los datos tienen estructuras lineales complejas (por ejemplo, datos que forman una espiral o una esfera), PCA puede tener limitaciones para capturar estas relaciones, ya que solo busca direcciones lineales de m√°xima varianza.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"principal-component-regression-pcr","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Principal Component Regression (PCR)","text":"La Regresi√≥n de Componentes Principales (PCR) es un m√©todo de regresi√≥n que combina el An√°lisis de Componentes Principales (PCA) con la Regresi√≥n por M√≠nimos Cuadrados Ordinarios (OLS). Su principal utilidad radica en situaciones donde se tienen muchas variables predictoras (X) y existe una alta multicolinealidad (fuerte correlaci√≥n entre ellas), lo que puede hacer que los modelos de regresi√≥n OLS sean inestables o ineficientes.El proceso de PCR consta de dos pasos principales:Reducci√≥n de Dimensionalidad con PCA: Primero, se aplica PCA las variables predictoras (X) para transformarlas en un conjunto m√°s peque√±o de componentes principales. Estos componentes son combinaciones lineales correlacionadas de las variables originales y capturan la mayor parte de la varianza en las variables X. Se selecciona un subconjunto de estos componentes principales (aquellos que explican la mayor parte de la varianza total) para retener. Es importante destacar que, en este paso, PCA tiene conocimiento de la variable de respuesta (Y); solo se enfoca en la estructura de las variables X.Regresi√≥n OLS sobre Componentes: Una vez que se han obtenido los componentes principales seleccionados, se realiza una regresi√≥n lineal est√°ndar (OLS) de la variable de respuesta (Y) sobre estos componentes. Como los componentes principales son ortogonales, la multicolinealidad ya es un problema en este paso de regresi√≥n.El beneficio de PCR es que permite construir un modelo de regresi√≥n en escenarios con multicolinealidad severa, reduciendo el n√∫mero de variables un conjunto m√°s manejable y estable, mientras se intenta preservar la mayor cantidad de informaci√≥n de las variables predictoras.Aprendizaje Global vs.¬†Local:La Regresi√≥n de Componentes Principales (PCR) es un modelo de aprendizaje global.Aspecto Global: Ambos pasos de PCR son intr√≠nsecamente globales.\nPCA (Paso Global): Como se mencion√≥ anteriormente, PCA es una t√©cnica global que encuentra una transformaci√≥n lineal de los datos que se aplica de manera uniforme todo el espacio de caracter√≠sticas. Los componentes principales se derivan de la estructura de varianza global de las variables predictoras.\nOLS (Paso Global): La regresi√≥n realizada sobre los componentes principales es un modelo OLS est√°ndar, que tambi√©n es una t√©cnica global. Busca una √∫nica relaci√≥n lineal que se aplica todos los datos transformados.\nPCA (Paso Global): Como se mencion√≥ anteriormente, PCA es una t√©cnica global que encuentra una transformaci√≥n lineal de los datos que se aplica de manera uniforme todo el espacio de caracter√≠sticas. Los componentes principales se derivan de la estructura de varianza global de las variables predictoras.OLS (Paso Global): La regresi√≥n realizada sobre los componentes principales es un modelo OLS est√°ndar, que tambi√©n es una t√©cnica global. Busca una √∫nica relaci√≥n lineal que se aplica todos los datos transformados.En conjunto, PCR construye una funci√≥n de regresi√≥n global que mapea el espacio de caracter√≠sticas original (transformado componentes principales) la variable de respuesta. La soluci√≥n resultante es una ecuaci√≥n que se aplica de manera consistente para todas las observaciones, sin ajustar modelos diferentes para subconjuntos locales de datos. Esto significa que si la relaci√≥n entre las variables predictoras y la respuesta es lineal o cambia dr√°sticamente en diferentes regiones del espacio de caracter√≠sticas, PCR podr√≠a ser la opci√≥n m√°s flexible, ya que se basa en transformaciones y regresiones lineales globales.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"projection-pursuit-pp","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Projection Pursuit (PP)","text":"Projection Pursuit (PP) es una t√©cnica estad√≠stica de reducci√≥n de dimensionalidad y an√°lisis exploratorio de datos utilizada para encontrar las proyecciones ‚Äúm√°s interesantes‚Äù de datos multivariados de alta dimensi√≥n en un espacio de menor dimensi√≥n (generalmente 1D o 2D). La clave de PP es que las proyecciones ‚Äúinteresantes‚Äù son aquellas que se desv√≠an m√°s de una distribuci√≥n normal (gaussiana), ya que las estructuras como agrupaciones, valores at√≠picos, o formas inusuales tienden ser m√°s evidentes en proyecciones gaussianas.El algoritmo de PP busca simplemente la mayor varianza (como PCA), sino que intenta encontrar direcciones de proyecci√≥n que revelen la estructura subyacente y las caracter√≠sticas lineales de los datos. Lo hace maximizando un ‚Äú√≠ndice de proyecci√≥n‚Äù que mide la ‚Äúinteresante‚Äù o la ‚Äú-gaussianidad‚Äù de la proyecci√≥n. Diferentes √≠ndices pueden enfocarse en diferentes aspectos, como la asimetr√≠a, la curtosis, o la presencia de m√∫ltiples modos (grupos).Existen variantes de PP para diferentes prop√≥sitos, como:\n* Exploratory Projection Pursuit (EPP): Para visualizaci√≥n y detecci√≥n de estructuras.\n* Projection Pursuit Regression (PPR): Para construir modelos de regresi√≥n lineales.\n* Projection Pursuit Classification (PPC): Para tareas de clasificaci√≥n.Aprendizaje Global vs.¬†Local:Projection Pursuit (PP) se puede considerar como un modelo que combina aspectos de aprendizaje global y local, con un fuerte √©nfasis en la detecci√≥n de caracter√≠sticas locales en un contexto global.Aspecto Global: PP busca una transformaci√≥n lineal global (la direcci√≥n de proyecci√≥n) que se aplica todo el conjunto de datos para encontrar las proyecciones ‚Äúm√°s interesantes‚Äù. La optimizaci√≥n del √≠ndice de proyecci√≥n se realiza sobre todo el espacio de caracter√≠sticas para identificar estas direcciones. Las funciones resultantes (como en PPR o PPC) son combinaciones de funciones lineales aplicadas estas proyecciones globales.Aspecto Global: PP busca una transformaci√≥n lineal global (la direcci√≥n de proyecci√≥n) que se aplica todo el conjunto de datos para encontrar las proyecciones ‚Äúm√°s interesantes‚Äù. La optimizaci√≥n del √≠ndice de proyecci√≥n se realiza sobre todo el espacio de caracter√≠sticas para identificar estas direcciones. Las funciones resultantes (como en PPR o PPC) son combinaciones de funciones lineales aplicadas estas proyecciones globales.Aspecto Local (al revelar estructuras): Donde PP exhibe un car√°cter ‚Äúlocal‚Äù es en su capacidad para resaltar estructuras que son intr√≠nsecamente locales (como clusters o valores at√≠picos) que podr√≠an estar ocultas en las altas dimensiones o en proyecciones puramente globales (como PCA). Al buscar desviaciones de la normalidad, PP es capaz de ‚Äúperseguir‚Äù (de ah√≠ ‚Äúpursuit‚Äù) las direcciones que exponen agrupaciones densas o huecos en los datos, que son fen√≥menos locales. La idea es que si los datos se distribuyen linealmente o tienen estructuras complejas, PP puede encontrar proyecciones donde la ‚Äúdensidad‚Äù o ‚Äúforma‚Äù local de los datos es m√°s informativa, permitiendo al usuario o un algoritmo posterior identificar estas estructuras que son una forma de ‚Äúregresi√≥n ponderada localmente‚Äù o un an√°lisis local de patrones.Aspecto Local (al revelar estructuras): Donde PP exhibe un car√°cter ‚Äúlocal‚Äù es en su capacidad para resaltar estructuras que son intr√≠nsecamente locales (como clusters o valores at√≠picos) que podr√≠an estar ocultas en las altas dimensiones o en proyecciones puramente globales (como PCA). Al buscar desviaciones de la normalidad, PP es capaz de ‚Äúperseguir‚Äù (de ah√≠ ‚Äúpursuit‚Äù) las direcciones que exponen agrupaciones densas o huecos en los datos, que son fen√≥menos locales. La idea es que si los datos se distribuyen linealmente o tienen estructuras complejas, PP puede encontrar proyecciones donde la ‚Äúdensidad‚Äù o ‚Äúforma‚Äù local de los datos es m√°s informativa, permitiendo al usuario o un algoritmo posterior identificar estas estructuras que son una forma de ‚Äúregresi√≥n ponderada localmente‚Äù o un an√°lisis local de patrones.En resumen, PP es una t√©cnica potente para explorar la estructura de datos de alta dimensi√≥n, especialmente cuando las relaciones son lineales o complejas. Si bien el proceso de b√∫squeda de proyecciones es global, el ‚Äúinter√©s‚Äù de estas proyecciones menudo radica en su capacidad para revelar caracter√≠sticas locales y gaussianas que son cruciales para entender los datos.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"sammon-mapping","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Sammon Mapping","text":"Sammon Mapping es una t√©cnica de reducci√≥n de dimensionalidad lineal que se utiliza para visualizar datos de alta dimensi√≥n en un espacio de menor dimensi√≥n (generalmente 2D o 3D). Su principal objetivo es preservar la estructura de distancia local de los datos originales en la representaci√≥n de menor dimensi√≥n.diferencia de t√©cnicas como PCA que buscan preservar la varianza global (y por lo tanto las distancias euclidianas globales), Sammon Mapping se enfoca en que las distancias peque√±as (entre puntos cercanos) en el espacio original sean representadas con mayor fidelidad en el espacio reducido que las distancias grandes. Esto lo hace particularmente bueno para revelar agrupaciones o clusters que podr√≠an estar ocultos en proyecciones lineales o en otras t√©cnicas de reducci√≥n de dimensionalidad que priorizan las distancias locales.El algoritmo de Sammon Mapping funciona minimizando una funci√≥n de ‚Äúerror‚Äù o ‚Äúestr√©s‚Äù espec√≠fica, conocida como el ‚Äúestr√©s de Sammon‚Äù. Esta funci√≥n penaliza m√°s fuertemente las grandes discrepancias en las distancias peque√±as que las grandes discrepancias en las distancias grandes. La minimizaci√≥n de esta funci√≥n se realiza mediante un proceso iterativo de descenso de gradiente.Aprendizaje Global vs.¬†Local:Sammon Mapping es un modelo que exhibe un fuerte car√°cter de aprendizaje local, aunque la optimizaci√≥n se realiza sobre la totalidad de los datos.Aspecto Local: La caracter√≠stica distintiva de Sammon Mapping es su √©nfasis en la preservaci√≥n de las distancias locales. Al penalizar m√°s las distancias peque√±as que se deforman en la proyecci√≥n, el algoritmo se esfuerza por mantener los puntos que estaban cerca en el espacio original, cerca en el espacio de menor dimensi√≥n. Esto es crucial para revelar la estructura local y las agrupaciones dentro de los datos. Es como si el algoritmo estuviera haciendo una serie de ‚Äúregresiones ponderadas localmente‚Äù para cada vecindario de puntos, ajustando las posiciones en el mapa de baja dimensi√≥n para que las relaciones cercanas se mantengan. Esta prioridad en las relaciones de vecindad es una marca del aprendizaje local.Aspecto Local: La caracter√≠stica distintiva de Sammon Mapping es su √©nfasis en la preservaci√≥n de las distancias locales. Al penalizar m√°s las distancias peque√±as que se deforman en la proyecci√≥n, el algoritmo se esfuerza por mantener los puntos que estaban cerca en el espacio original, cerca en el espacio de menor dimensi√≥n. Esto es crucial para revelar la estructura local y las agrupaciones dentro de los datos. Es como si el algoritmo estuviera haciendo una serie de ‚Äúregresiones ponderadas localmente‚Äù para cada vecindario de puntos, ajustando las posiciones en el mapa de baja dimensi√≥n para que las relaciones cercanas se mantengan. Esta prioridad en las relaciones de vecindad es una marca del aprendizaje local.Optimizaci√≥n Global: pesar de su enfoque local, la funci√≥n de estr√©s de Sammon se calcula y se minimiza sobre todos los pares de puntos en el conjunto de datos. La soluci√≥n final es una configuraci√≥n global de puntos en el espacio de baja dimensi√≥n. Por lo tanto, el proceso de optimizaci√≥n es global, pero su criterio de ‚Äúmejor ajuste‚Äù da una importancia desproporcionada la preservaci√≥n de las relaciones locales.Optimizaci√≥n Global: pesar de su enfoque local, la funci√≥n de estr√©s de Sammon se calcula y se minimiza sobre todos los pares de puntos en el conjunto de datos. La soluci√≥n final es una configuraci√≥n global de puntos en el espacio de baja dimensi√≥n. Por lo tanto, el proceso de optimizaci√≥n es global, pero su criterio de ‚Äúmejor ajuste‚Äù da una importancia desproporcionada la preservaci√≥n de las relaciones locales.En resumen, Sammon Mapping es una t√©cnica poderosa para visualizar datos de alta dimensi√≥n, especialmente cuando los clusters o las estructuras locales son importantes. Si los datos se distribuyen linealmente y lo que se busca es entender c√≥mo se agrupan los puntos en sus vecindarios, Sammon Mapping ofrece una representaci√≥n donde las relaciones locales son el foco principal, lo que lo convierte en una excelente herramienta para la exploraci√≥n de estructuras lineales y la detecci√≥n de agrupaciones.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"regularized-discriminant-analysis-rda","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Regularized Discriminant Analysis (RDA)","text":"El An√°lisis Discriminante Regularizado (RDA) es un m√©todo de clasificaci√≥n que act√∫a como un intermedio flexible entre el An√°lisis Discriminante Lineal (LDA) y el An√°lisis Discriminante Cuadr√°tico (QDA). Fue desarrollado por Jerome Friedman para abordar las limitaciones de LDA (que asume covarianzas iguales para todas las clases, lo que resulta en fronteras lineales) y QDA (que permite covarianzas separadas pero puede ser inestable con pocos datos o muchas variables).RDA introduce dos par√°metros de regularizaci√≥n, \\(\\alpha\\) y \\(\\gamma\\), que controlan la flexibilidad del modelo y su capacidad para adaptarse los datos:Par√°metro \\(\\alpha\\) (alpha): Controla el grado en que la matriz de covarianza de cada clase se contrae hacia una matriz de covarianza com√∫n (como en LDA).\nSi \\(\\alpha = 0\\), RDA se comporta como QDA (cada clase tiene su propia matriz de covarianza).\nSi \\(\\alpha = 1\\), RDA se comporta como LDA (todas las clases comparten una matriz de covarianza com√∫n).\nPara valores entre 0 y 1, RDA utiliza un promedio ponderado de la matriz de covarianza espec√≠fica de la clase y la matriz de covarianza com√∫n. Esto ayuda estabilizar las estimaciones de covarianza en QDA, especialmente cuando los tama√±os de muestra son peque√±os o el n√∫mero de variables es grande.\nSi \\(\\alpha = 0\\), RDA se comporta como QDA (cada clase tiene su propia matriz de covarianza).Si \\(\\alpha = 1\\), RDA se comporta como LDA (todas las clases comparten una matriz de covarianza com√∫n).Para valores entre 0 y 1, RDA utiliza un promedio ponderado de la matriz de covarianza espec√≠fica de la clase y la matriz de covarianza com√∫n. Esto ayuda estabilizar las estimaciones de covarianza en QDA, especialmente cuando los tama√±os de muestra son peque√±os o el n√∫mero de variables es grande.Par√°metro \\(\\gamma\\) (gamma): Controla el grado en que la matriz de covarianza (ya sea com√∫n o espec√≠fica de la clase, dependiendo de \\(\\alpha\\)) se contrae hacia una matriz diagonal.\nSi \\(\\gamma = 0\\), hay contracci√≥n diagonal adicional.\nSi \\(\\gamma = 1\\), la matriz de covarianza se contrae completamente una matriz diagonal (lo que implica independencia entre las variables).\nPara valores entre 0 y 1, se aplica una contracci√≥n hacia la diagonal, lo que puede ser √∫til cuando hay multicolinealidad.\nSi \\(\\gamma = 0\\), hay contracci√≥n diagonal adicional.Si \\(\\gamma = 1\\), la matriz de covarianza se contrae completamente una matriz diagonal (lo que implica independencia entre las variables).Para valores entre 0 y 1, se aplica una contracci√≥n hacia la diagonal, lo que puede ser √∫til cuando hay multicolinealidad.Al sintonizar estos dos par√°metros (generalmente mediante validaci√≥n cruzada), RDA puede encontrar un equilibrio √≥ptimo entre la simplicidad de LDA y la flexibilidad de QDA, adapt√°ndose mejor la estructura de covarianza real de los datos y mejorando la estabilidad del modelo.Aprendizaje Global vs.¬†Local:El An√°lisis Discriminante Regularizado (RDA) es un modelo de aprendizaje global que incorpora un grado de adaptaci√≥n local trav√©s de su regularizaci√≥n.Aspecto Global: Al igual que LDA y QDA, RDA construye un clasificador global basado en las distribuciones de probabilidad modeladas para cada clase. Las matrices de covarianza regularizadas y las medias de las clases se estiman partir de todo el conjunto de datos de entrenamiento, y la regla de clasificaci√≥n resultante se aplica de manera consistente en todo el espacio de caracter√≠sticas. La frontera de decisi√≥n que RDA define es una funci√≥n global (que puede ser lineal o cuadr√°tica, o una combinaci√≥n de ambas, dependiendo de los par√°metros de regularizaci√≥n).Aspecto Global: Al igual que LDA y QDA, RDA construye un clasificador global basado en las distribuciones de probabilidad modeladas para cada clase. Las matrices de covarianza regularizadas y las medias de las clases se estiman partir de todo el conjunto de datos de entrenamiento, y la regla de clasificaci√≥n resultante se aplica de manera consistente en todo el espacio de caracter√≠sticas. La frontera de decisi√≥n que RDA define es una funci√≥n global (que puede ser lineal o cuadr√°tica, o una combinaci√≥n de ambas, dependiendo de los par√°metros de regularizaci√≥n).Adaptaci√≥n Local (trav√©s de la regularizaci√≥n de covarianza): La flexibilidad de RDA para ajustarse mejor los datos que LDA o QDA proviene de su capacidad para modelar las estructuras de covarianza de las clases de una manera m√°s matizada. Al permitir una contracci√≥n parcial de las matrices de covarianza hacia una com√∫n (par√°metro \\(\\alpha\\)) o hacia una diagonal (par√°metro \\(\\gamma\\)), RDA puede adaptar las formas de las distribuciones de las clases. Esto permite que el modelo capture mejor las caracter√≠sticas de dispersi√≥n de los datos en diferentes regiones, lo que en √∫ltima instancia se traduce en fronteras de decisi√≥n m√°s adaptables que pueden manejar cierto grado de linealidad o formas complejas de clase. es un ajuste local en el sentido de LOESS, sino una forma de adaptar la complejidad del modelo global la estructura de covarianza percibida de cada clase.Adaptaci√≥n Local (trav√©s de la regularizaci√≥n de covarianza): La flexibilidad de RDA para ajustarse mejor los datos que LDA o QDA proviene de su capacidad para modelar las estructuras de covarianza de las clases de una manera m√°s matizada. Al permitir una contracci√≥n parcial de las matrices de covarianza hacia una com√∫n (par√°metro \\(\\alpha\\)) o hacia una diagonal (par√°metro \\(\\gamma\\)), RDA puede adaptar las formas de las distribuciones de las clases. Esto permite que el modelo capture mejor las caracter√≠sticas de dispersi√≥n de los datos en diferentes regiones, lo que en √∫ltima instancia se traduce en fronteras de decisi√≥n m√°s adaptables que pueden manejar cierto grado de linealidad o formas complejas de clase. es un ajuste local en el sentido de LOESS, sino una forma de adaptar la complejidad del modelo global la estructura de covarianza percibida de cada clase.","code":""},{"path":"reducci√≥n-de-dimensionalidad.html","id":"uniform-manifold-approximation-and-projection-umap","chapter":"üß© 5. Reducci√≥n de Dimensionalidad","heading":"Uniform Manifold Approximation and Projection (UMAP)","text":"Uniform Manifold Approximation Projection (UMAP) es una t√©cnica de reducci√≥n de dimensionalidad lineal de vanguardia, utilizada principalmente para la visualizaci√≥n de datos de alta dimensi√≥n y para el aprendizaje de caracter√≠sticas (feature learning). Fue desarrollada por Leland McInnes, John Healy y James Melville. UMAP es una alternativa m√°s reciente y menudo m√°s r√°pida y escalable t-SNE (t-Distributed Stochastic Neighbor Embedding), manteniendo su capacidad para preservar la estructura local y global de los datos.La idea central de UMAP se basa en la teor√≠a de los conjuntos difusos (fuzzy set theory) y la geometr√≠a riemanniana. Intenta construir una representaci√≥n de baja dimensi√≥n de los datos asumiendo que los datos de alta dimensi√≥n residen en una variedad (manifold) subyacente de baja dimensi√≥n. El algoritmo opera en dos fases:Construcci√≥n del Grafo de Vecindad Difusa:\nPrimero, UMAP construye un grafo ponderado difuso en el espacio de alta dimensi√≥n. Los nodos del grafo son los puntos de datos y los pesos de las aristas representan la probabilidad de que dos puntos est√©n conectados (es decir, qu√© tan similares o cercanos son).\nPara ello, UMAP estima las distancias entre los puntos en el manifold subyacente y luego convierte estas distancias en probabilidades de conectividad. Esto es crucial porque le permite adaptarse la densidad local de los datos (puntos en regiones densas pueden estar cerca incluso con distancias euclidianas grandes, y viceversa en regiones dispersas).\nPrimero, UMAP construye un grafo ponderado difuso en el espacio de alta dimensi√≥n. Los nodos del grafo son los puntos de datos y los pesos de las aristas representan la probabilidad de que dos puntos est√©n conectados (es decir, qu√© tan similares o cercanos son).Para ello, UMAP estima las distancias entre los puntos en el manifold subyacente y luego convierte estas distancias en probabilidades de conectividad. Esto es crucial porque le permite adaptarse la densidad local de los datos (puntos en regiones densas pueden estar cerca incluso con distancias euclidianas grandes, y viceversa en regiones dispersas).Optimizaci√≥n del Dise√±o en Baja Dimensi√≥n:\nLuego, UMAP optimiza el dise√±o de los puntos en un espacio de baja dimensi√≥n (ej., 2D) para que la estructura del grafo construido en alta dimensi√≥n sea lo m√°s similar posible al grafo construido en baja dimensi√≥n.\nEsto se logra minimizando una funci√≥n de costo que intenta hacer que las probabilidades de conectividad en el espacio de baja dimensi√≥n coincidan con las probabilidades de conectividad del grafo de alta dimensi√≥n.\nLuego, UMAP optimiza el dise√±o de los puntos en un espacio de baja dimensi√≥n (ej., 2D) para que la estructura del grafo construido en alta dimensi√≥n sea lo m√°s similar posible al grafo construido en baja dimensi√≥n.Esto se logra minimizando una funci√≥n de costo que intenta hacer que las probabilidades de conectividad en el espacio de baja dimensi√≥n coincidan con las probabilidades de conectividad del grafo de alta dimensi√≥n.UMAP es valorado por su velocidad, escalabilidad grandes conjuntos de datos, y su capacidad para preservar simult√°neamente la estructura local y global de los datos, lo que lo hace ideal para visualizar agrupaciones y relaciones complejas.Aprendizaje Global vs.¬†Local:UMAP es un excelente ejemplo de un modelo que logra un equilibrio sofisticado entre el aprendizaje local y global.Aspecto Local: UMAP pone un fuerte √©nfasis en la preservaci√≥n de la estructura local. Al construir el grafo de vecindad difusa, se enfoca en las relaciones de los vecinos m√°s cercanos de cada punto (controlado por el par√°metro n_neighbors). La forma en que calcula las probabilidades de conectividad se adapta la densidad local de los datos, asegurando que los cl√∫steres y las agrupaciones cercanas se mantengan cohesivos en la representaci√≥n de baja dimensi√≥n. Las relaciones ‚Äúlocales‚Äù son las que definen el ‚Äúmanifold‚Äù en primera instancia. Esto significa que si los datos se distribuyen linealmente y tienen estructuras complejas con vecindarios distintos (como diferentes clusters o ramas en una estructura), UMAP es capaz de capturarlas con alta fidelidad, de forma similar como una ‚Äúregresi√≥n ponderada localmente‚Äù operar√≠a en cada vecindario.Aspecto Local: UMAP pone un fuerte √©nfasis en la preservaci√≥n de la estructura local. Al construir el grafo de vecindad difusa, se enfoca en las relaciones de los vecinos m√°s cercanos de cada punto (controlado por el par√°metro n_neighbors). La forma en que calcula las probabilidades de conectividad se adapta la densidad local de los datos, asegurando que los cl√∫steres y las agrupaciones cercanas se mantengan cohesivos en la representaci√≥n de baja dimensi√≥n. Las relaciones ‚Äúlocales‚Äù son las que definen el ‚Äúmanifold‚Äù en primera instancia. Esto significa que si los datos se distribuyen linealmente y tienen estructuras complejas con vecindarios distintos (como diferentes clusters o ramas en una estructura), UMAP es capaz de capturarlas con alta fidelidad, de forma similar como una ‚Äúregresi√≥n ponderada localmente‚Äù operar√≠a en cada vecindario.Aspecto Global: pesar de su √©nfasis local, UMAP tambi√©n hace un esfuerzo consciente por preservar la estructura global de los datos. Al minimizar la funci√≥n de costo para que la estructura del grafo se mantenga en el espacio de baja dimensi√≥n, UMAP solo se asegura de que los puntos cercanos permanezcan cercanos, sino que tambi√©n intenta que los grupos de puntos que estaban globalmente separados en la alta dimensi√≥n permanezcan separados en la baja dimensi√≥n. El par√°metro min_dist ayuda controlar cu√°n compactos deben ser los cl√∫steres, lo que influye en la separaci√≥n global. Esta capacidad de equilibrar ambos aspectos es una de las principales ventajas de UMAP sobre t√©cnicas que veces sacrifican la estructura global (como t-SNE, que puede ‚Äúromper‚Äù grandes cl√∫steres).Aspecto Global: pesar de su √©nfasis local, UMAP tambi√©n hace un esfuerzo consciente por preservar la estructura global de los datos. Al minimizar la funci√≥n de costo para que la estructura del grafo se mantenga en el espacio de baja dimensi√≥n, UMAP solo se asegura de que los puntos cercanos permanezcan cercanos, sino que tambi√©n intenta que los grupos de puntos que estaban globalmente separados en la alta dimensi√≥n permanezcan separados en la baja dimensi√≥n. El par√°metro min_dist ayuda controlar cu√°n compactos deben ser los cl√∫steres, lo que influye en la separaci√≥n global. Esta capacidad de equilibrar ambos aspectos es una de las principales ventajas de UMAP sobre t√©cnicas que veces sacrifican la estructura global (como t-SNE, que puede ‚Äúromper‚Äù grandes cl√∫steres).","code":""},{"path":"modelos-bayesianos.html","id":"modelos-bayesianos","chapter":"üß¨ 6. Modelos Bayesianos","heading":"üß¨ 6. Modelos Bayesianos","text":"Ejemplos: Naive Bayes, Redes Bayesianas.Uso: Ideales para clasificaci√≥n r√°pida, especialmente en escenarios con supuestos simples sobre los datos. Son muy populares en tareas de procesamiento de texto y detecci√≥n de spam.Ventajas: Son modelos muy r√°pidos de entrenar y predecir, y est√°n s√≥lidamente fundamentados en la teor√≠a de probabilidad.Limitaciones: La principal es que asumen independencia entre las variables predictoras, lo cual siempre se cumple en la realidad y puede afectar su precisi√≥n en ciertos problemas.","code":""},{"path":"modelos-bayesianos.html","id":"averaged-one---dependence-estimators-aode","chapter":"üß¨ 6. Modelos Bayesianos","heading":"Averaged One - Dependence Estimators (AODE)","text":"Averaged One-Dependence Estimators (AODE) es un algoritmo de clasificaci√≥n supervisada que pertenece la familia de los clasificadores basados en modelos bayesianos. Es una mejora sobre el cl√°sico Naive Bayes (NB), dise√±ado para superar la limitaci√≥n clave de NB: la asunci√≥n de independencia condicional estricta entre las variables predictoras (atributos) dado el valor de la clase. Esta suposici√≥n, aunque simplifica mucho el c√°lculo y permite Naive Bayes ser muy eficiente, rara vez se cumple en la realidad y puede llevar una p√©rdida de precisi√≥n.AODE relaja parcialmente la suposici√≥n de independencia de Naive Bayes al considerar que cada atributo es dependiente, como m√°ximo, de un solo otro atributo (adem√°s de la variable de clase). En lugar de construir un √∫nico modelo de √°rbol de dependencia (como en el √Årbol de Dependencia de Atributos - ADTree), AODE construye una colecci√≥n de clasificadores ‚ÄúOne-Dependence‚Äù (ODE) y luego promedia sus predicciones.El funcionamiento de AODE se puede resumir as√≠:Generaci√≥n de Clasificadores ODE: Para cada atributo predictivo \\(A_i\\) en el conjunto de datos (que cumpla ciertos criterios, como tener suficientes instancias), AODE construye un clasificador ODE. Este clasificador asume que todos los dem√°s atributos son condicionalmente independientes de \\(A_i\\) dado la clase. En otras palabras, se estima la probabilidad condicional de cada atributo \\(A_j\\) dado la clase \\(C\\) y el atributo \\(A_i\\): \\(P(A_j | C, A_i)\\).Ponderaci√≥n y Promedio: Cuando se hace una predicci√≥n para una nueva instancia, AODE calcula la probabilidad de cada clase para cada uno de los clasificadores ODE generados. Luego, estas probabilidades se combinan (t√≠picamente promediando) para obtener una predicci√≥n final.Al promediar las predicciones de m√∫ltiples modelos ODE, AODE logra mitigar el sesgo introducido por la suposici√≥n de independencia estricta de Naive Bayes, menudo obteniendo un mejor rendimiento sin incurrir en una complejidad computacional excesiva.Aprendizaje Global vs.¬†Local:Averaged One-Dependence Estimators (AODE) es un modelo que se clasifica como de aprendizaje global, aunque con una estructura que busca capturar dependencias que tienen una naturaleza m√°s ‚Äúlocal‚Äù en el contexto de las relaciones entre atributos.Aspecto Global: AODE construye un conjunto de modelos (los ODEs) que son entrenados sobre la totalidad del conjunto de datos para estimar las probabilidades condicionales. La combinaci√≥n de estas probabilidades (el promedio) para llegar una predicci√≥n final es una regla que se aplica de manera consistente cualquier nueva observaci√≥n. Los par√°metros de cada clasificador ODE (las probabilidades condicionales) se estiman de manera global partir de las frecuencias observadas en todo el conjunto de entrenamiento.Aspecto Global: AODE construye un conjunto de modelos (los ODEs) que son entrenados sobre la totalidad del conjunto de datos para estimar las probabilidades condicionales. La combinaci√≥n de estas probabilidades (el promedio) para llegar una predicci√≥n final es una regla que se aplica de manera consistente cualquier nueva observaci√≥n. Los par√°metros de cada clasificador ODE (las probabilidades condicionales) se estiman de manera global partir de las frecuencias observadas en todo el conjunto de entrenamiento.Matiz (Captura de Dependencias Locales): Aunque el enfoque general es global, la raz√≥n por la que AODE es m√°s potente que Naive Bayes radica en su capacidad para modelar dependencias entre atributos. Cada clasificador ODE considera que un atributo espec√≠fico tiene una dependencia directa de otro atributo, lo que es una forma de capturar una relaci√≥n ‚Äúlocal‚Äù entre un par de atributos dado el contexto de la clase. Al promediar sobre estos m√∫ltiples modelos que capturan diferentes dependencias de ‚Äúun solo par‚Äù, AODE puede adaptarse mejor las complejidades de los datos donde las relaciones son puramente independientes y se distribuyen linealmente, sin la necesidad de dividir el espacio de caracter√≠sticas en regiones discretas como los √°rboles de decisi√≥n. Sin embargo, la soluci√≥n final de promediado es un clasificador global que se aplica toda la instancia de entrada.Matiz (Captura de Dependencias Locales): Aunque el enfoque general es global, la raz√≥n por la que AODE es m√°s potente que Naive Bayes radica en su capacidad para modelar dependencias entre atributos. Cada clasificador ODE considera que un atributo espec√≠fico tiene una dependencia directa de otro atributo, lo que es una forma de capturar una relaci√≥n ‚Äúlocal‚Äù entre un par de atributos dado el contexto de la clase. Al promediar sobre estos m√∫ltiples modelos que capturan diferentes dependencias de ‚Äúun solo par‚Äù, AODE puede adaptarse mejor las complejidades de los datos donde las relaciones son puramente independientes y se distribuyen linealmente, sin la necesidad de dividir el espacio de caracter√≠sticas en regiones discretas como los √°rboles de decisi√≥n. Sin embargo, la soluci√≥n final de promediado es un clasificador global que se aplica toda la instancia de entrada.","code":""},{"path":"modelos-bayesianos.html","id":"bayesian-network-bn","chapter":"üß¨ 6. Modelos Bayesianos","heading":"Bayesian Network (BN)","text":"Una Red Bayesiana (BN), tambi√©n conocida como Red Bayesiana Causal o Modelo Gr√°fico Dirigido Ac√≠clico (DAG), es un modelo probabil√≠stico que representa un conjunto de variables y sus relaciones de dependencia condicional utilizando un grafo dirigido ac√≠clico. En este grafo:Nodos: Representan las variables aleatorias (pueden ser discretas o continuas).Arcos (flechas): Representan las dependencias condicionales entre las variables. Una flecha de B significa que B depende directamente de (es ‚Äúpadre‚Äù de B). La ausencia de un arco entre dos nodos indica una independencia condicional.La estructura del grafo de una Red Bayesiana permite visualizar y comprender las relaciones de causa y efecto (o asociaci√≥n) entre las variables. Junto con la estructura del grafo, una BN tambi√©n especifica las distribuciones de probabilidad condicional (CPDs) para cada nodo, dadas las combinaciones de estados de sus nodos padre. Por ejemplo, si un nodo tiene padres, se define la probabilidad de sus valores para cada combinaci√≥n de valores de sus padres.Las Redes Bayesianas son potentes para:\n* Modelado de Conocimiento: Codificar el conocimiento experto o aprendido de los datos sobre c√≥mo interact√∫an las variables.\n* Inferencia Probabil√≠stica: Calcular la probabilidad de que una variable tome un valor espec√≠fico, dadas las observaciones de otras variables (evidencia). Esto puede incluir diagn√≥stico (inferir causas partir de efectos) o predicci√≥n (inferir efectos partir de causas).\n* Aprendizaje de Estructura y Par√°metros: Aprender la estructura del grafo (las dependencias) y las CPDs partir de datos.Aprendizaje Global vs.¬†Local:Una Red Bayesiana (BN) es fundamentalmente un modelo de aprendizaje global en su estructura general, pero con una fuerte base en el aprendizaje local de las dependencias.Aspecto Global: La estructura del grafo y el conjunto de tablas de probabilidad condicional (CPDs) forman un modelo probabil√≠stico coherente y global de la distribuci√≥n de probabilidad conjunta de todas las variables. Este modelo global puede ser utilizado para realizar inferencias sobre cualquier combinaci√≥n de variables en cualquier parte del espacio de datos. La red define c√≥mo la informaci√≥n fluye y c√≥mo las probabilidades se propagan trav√©s de todas las variables, dando una visi√≥n hol√≠stica de las interacciones del sistema.Aspecto Global: La estructura del grafo y el conjunto de tablas de probabilidad condicional (CPDs) forman un modelo probabil√≠stico coherente y global de la distribuci√≥n de probabilidad conjunta de todas las variables. Este modelo global puede ser utilizado para realizar inferencias sobre cualquier combinaci√≥n de variables en cualquier parte del espacio de datos. La red define c√≥mo la informaci√≥n fluye y c√≥mo las probabilidades se propagan trav√©s de todas las variables, dando una visi√≥n hol√≠stica de las interacciones del sistema.Aspecto Local (Dependencias y Parametrizaci√≥n): Donde la BN tiene un fuerte componente local es en la definici√≥n de las dependencias y la parametrizaci√≥n de las CPDs. Cada nodo solo necesita conocer las probabilidades condicionales dadas sus padres directos. Esto es un principio de independencia condicional local: una variable es independiente de sus -descendientes dado sus padres. Esto descompone un problema complejo de modelado de la distribuci√≥n conjunta en problemas m√°s peque√±os y manejables de modelar las dependencias locales. Por ejemplo, para estimar \\(P(X_i | Padres(X_i))\\), solo se necesita informaci√≥n local relacionada con \\(X_i\\) y sus padres, con todas las dem√°s variables en la red. Esta capacidad de modelar dependencias de forma localizada, y luego ensamblarlas en un modelo global, permite las BNs manejar relaciones lineales y complejas de una manera estructurada y probabil√≠stica. Si los datos se distribuyen linealmente, la estructura de la BN puede adaptarse para reflejar las relaciones lineales entre las variables trav√©s de sus arcos y CPDs.Aspecto Local (Dependencias y Parametrizaci√≥n): Donde la BN tiene un fuerte componente local es en la definici√≥n de las dependencias y la parametrizaci√≥n de las CPDs. Cada nodo solo necesita conocer las probabilidades condicionales dadas sus padres directos. Esto es un principio de independencia condicional local: una variable es independiente de sus -descendientes dado sus padres. Esto descompone un problema complejo de modelado de la distribuci√≥n conjunta en problemas m√°s peque√±os y manejables de modelar las dependencias locales. Por ejemplo, para estimar \\(P(X_i | Padres(X_i))\\), solo se necesita informaci√≥n local relacionada con \\(X_i\\) y sus padres, con todas las dem√°s variables en la red. Esta capacidad de modelar dependencias de forma localizada, y luego ensamblarlas en un modelo global, permite las BNs manejar relaciones lineales y complejas de una manera estructurada y probabil√≠stica. Si los datos se distribuyen linealmente, la estructura de la BN puede adaptarse para reflejar las relaciones lineales entre las variables trav√©s de sus arcos y CPDs.","code":""},{"path":"modelos-bayesianos.html","id":"bayesian-belief-network-bbn","chapter":"üß¨ 6. Modelos Bayesianos","heading":"Bayesian Belief Network (BBN)","text":"Una Red de Creencia Bayesiana (BBN) es simplemente otro t√©rmino para una Red Bayesiana (BN). hay una diferencia fundamental entre ambos nombres; ambos se refieren al mismo tipo de modelo probabil√≠stico. La terminolog√≠a ‚ÄúRed de Creencia‚Äù menudo enfatiza la capacidad del modelo para representar y actualizar ‚Äúcreencias‚Äù (probabilidades) sobre el estado de variables inciertas medida que se introduce nueva evidencia.Como ya se describi√≥, una BBN (o BN) es un modelo gr√°fico probabil√≠stico dirigido ac√≠clico (DAG) que representa un conjunto de variables aleatorias como nodos y sus relaciones de dependencia condicional como arcos (flechas). La ausencia de un arco entre dos nodos indica una independencia condicional. Cada nodo est√° asociado con una distribuci√≥n de probabilidad condicional (CPD) que cuantifica la relaci√≥n de ese nodo con sus padres.Las BBNs son herramientas poderosas para:\n* Modelar el conocimiento incierto: Permiten representar c√≥mo diferentes factores interact√∫an bajo incertidumbre.\n* Inferencia probabil√≠stica: Dada alguna evidencia (observaciones de algunas variables), la red puede calcular las probabilidades actualizadas de las otras variables. Esto es fundamental para el diagn√≥stico, la predicci√≥n y la toma de decisiones bajo incertidumbre.\n* Aprendizaje partir de datos: Las BBNs pueden ser aprendidas tanto en su estructura (c√≥mo se conectan los nodos) como en sus par√°metros (las CPDs) partir de conjuntos de datos.Aprendizaje Global vs.¬†Local:Al igual que una Red Bayesiana, una Red de Creencia Bayesiana es fundamentalmente un modelo de aprendizaje global en su formulaci√≥n general, pero se basa en la especificaci√≥n local de las dependencias probabil√≠sticas.Aspecto Global: La BBN como un todo representa la distribuci√≥n de probabilidad conjunta global de todas las variables en el sistema. Una vez que la estructura y las CPDs est√°n definidas, la red puede usarse para calcular cualquier probabilidad marginal o condicional de inter√©s, proporcionando una visi√≥n probabil√≠stica completa y coherente del dominio. Es una funci√≥n que mapea el espacio de todas las posibles combinaciones de variables sus probabilidades, y se aplica de manera consistente en todo el espacio.Aspecto Global: La BBN como un todo representa la distribuci√≥n de probabilidad conjunta global de todas las variables en el sistema. Una vez que la estructura y las CPDs est√°n definidas, la red puede usarse para calcular cualquier probabilidad marginal o condicional de inter√©s, proporcionando una visi√≥n probabil√≠stica completa y coherente del dominio. Es una funci√≥n que mapea el espacio de todas las posibles combinaciones de variables sus probabilidades, y se aplica de manera consistente en todo el espacio.Aspecto Local (Definici√≥n de Dependencias): La fortaleza y eficiencia de las BBNs radica en el principio de independencia condicional local. Cada variable (nodo) solo necesita tener su distribuci√≥n de probabilidad condicionada sus padres directos en el grafo. es necesario especificar las dependencias con todas las dem√°s variables en la red. Esta factorizaci√≥n de la distribuci√≥n conjunta en componentes locales (las CPDs) es lo que hace que las BBNs sean computacionalmente manejables y permite que el modelo capture relaciones lineales y complejas entre las variables de una manera estructurada. Al modelar estas dependencias ‚Äúlocales‚Äù de forma expl√≠cita, la BBN puede representar con precisi√≥n c√≥mo la probabilidad de un evento cambia en funci√≥n de los eventos directamente relacionados, incluso si la relaci√≥n es lineal.Aspecto Local (Definici√≥n de Dependencias): La fortaleza y eficiencia de las BBNs radica en el principio de independencia condicional local. Cada variable (nodo) solo necesita tener su distribuci√≥n de probabilidad condicionada sus padres directos en el grafo. es necesario especificar las dependencias con todas las dem√°s variables en la red. Esta factorizaci√≥n de la distribuci√≥n conjunta en componentes locales (las CPDs) es lo que hace que las BBNs sean computacionalmente manejables y permite que el modelo capture relaciones lineales y complejas entre las variables de una manera estructurada. Al modelar estas dependencias ‚Äúlocales‚Äù de forma expl√≠cita, la BBN puede representar con precisi√≥n c√≥mo la probabilidad de un evento cambia en funci√≥n de los eventos directamente relacionados, incluso si la relaci√≥n es lineal.En resumen, las Redes de Creencia Bayesianas son modelos globales que permiten modelar relaciones probabil√≠sticas complejas y lineales al especificar dependencias de manera local entre las variables. Son herramientas poderosas para el razonamiento bajo incertidumbre y la toma de decisiones.","code":""},{"path":"modelos-bayesianos.html","id":"gaussian-naive-bayes-gnb","chapter":"üß¨ 6. Modelos Bayesianos","heading":"Gaussian Naive Bayes (GNB)","text":"Gaussian Naive Bayes (GNB) es una variante del popular algoritmo Naive Bayes (NB), utilizado para tareas de clasificaci√≥n supervisada. Es particularmente adecuado cuando las variables predictoras (atributos) son de tipo continuo. Al igual que todos los clasificadores Naive Bayes, GNB se basa en el Teorema de Bayes y, fundamentalmente, en la suposici√≥n de independencia condicional entre las variables predictoras, dado el valor de la clase.La diferencia clave entre GNB y otras variantes de Naive Bayes (como Multinomial Naive Bayes o Bernoulli Naive Bayes) es la forma en que modela la probabilidad de los atributos continuos. Espec√≠ficamente:Suposici√≥n de Distribuci√≥n Gaussiana: GNB asume que los valores de cada atributo continuo, dada una clase espec√≠fica, siguen una distribuci√≥n normal (Gaussiana). Es decir, para cada clase y cada atributo, se estima la media (\\(\\mu\\)) y la desviaci√≥n est√°ndar (\\(\\sigma\\)) de los valores de ese atributo dentro de esa clase.C√°lculo de Probabilidades: Cuando se necesita clasificar una nueva observaci√≥n, GNB utiliza las funciones de densidad de probabilidad (PDF) de estas distribuciones Gaussianas para calcular la probabilidad de observar el valor del atributo para cada clase.Aplicaci√≥n del Teorema de Bayes: Finalmente, utiliza el Teorema de Bayes para calcular la probabilidad posterior de cada clase, dadas las probabilidades de los atributos, y asigna la observaci√≥n la clase con la probabilidad posterior m√°s alta.pesar de su suposici√≥n de independencia (que rara vez se cumple perfectamente en la pr√°ctica), GNB menudo funciona sorprendentemente bien, especialmente en conjuntos de datos grandes o cuando las caracter√≠sticas son ruidosas. Su simplicidad y eficiencia computacional lo hacen un buen punto de partida para muchos problemas de clasificaci√≥n.Aprendizaje Global vs.¬†Local:Gaussian Naive Bayes (GNB) es un modelo de aprendizaje global.Aspecto Global: GNB construye un modelo probabil√≠stico global de la relaci√≥n entre las caracter√≠sticas y las clases. Las medias y desviaciones est√°ndar de las distribuciones Gaussianas para cada atributo dentro de cada clase se estiman partir de todos los datos de entrenamiento. La regla de clasificaci√≥n final, que asigna una nueva instancia la clase m√°s probable, se basa en estas distribuciones param√©tricas globales y en el Teorema de Bayes, aplic√°ndose de manera uniforme en todo el espacio de caracter√≠sticas. se ajustan modelos locales para diferentes vecindarios de datos.Aspecto Global: GNB construye un modelo probabil√≠stico global de la relaci√≥n entre las caracter√≠sticas y las clases. Las medias y desviaciones est√°ndar de las distribuciones Gaussianas para cada atributo dentro de cada clase se estiman partir de todos los datos de entrenamiento. La regla de clasificaci√≥n final, que asigna una nueva instancia la clase m√°s probable, se basa en estas distribuciones param√©tricas globales y en el Teorema de Bayes, aplic√°ndose de manera uniforme en todo el espacio de caracter√≠sticas. se ajustan modelos locales para diferentes vecindarios de datos.Impacto de la Asunci√≥n de Independencia: La suposici√≥n de independencia condicional (que los atributos son independientes entre s√≠ dado la clase) significa que GNB intenta capturar interacciones complejas o lineales entre las variables predictoras. Si bien esto simplifica dr√°sticamente el modelo y lo hace eficiente, tambi√©n implica que su capacidad para modelar relaciones lineales entre predictores es limitada. Si los datos se distribuyen linealmente y las interacciones entre los predictores son cruciales para la clasificaci√≥n, GNB podr√≠a ser el modelo m√°s flexible. Sin embargo, su robustez ante la violaci√≥n de suposiciones y su velocidad lo mantienen como una opci√≥n valiosa en muchos escenarios.Impacto de la Asunci√≥n de Independencia: La suposici√≥n de independencia condicional (que los atributos son independientes entre s√≠ dado la clase) significa que GNB intenta capturar interacciones complejas o lineales entre las variables predictoras. Si bien esto simplifica dr√°sticamente el modelo y lo hace eficiente, tambi√©n implica que su capacidad para modelar relaciones lineales entre predictores es limitada. Si los datos se distribuyen linealmente y las interacciones entre los predictores son cruciales para la clasificaci√≥n, GNB podr√≠a ser el modelo m√°s flexible. Sin embargo, su robustez ante la violaci√≥n de suposiciones y su velocidad lo mantienen como una opci√≥n valiosa en muchos escenarios.","code":""},{"path":"modelos-bayesianos.html","id":"multinomial-naive-bayes-mnb","chapter":"üß¨ 6. Modelos Bayesianos","heading":"Multinomial Naive Bayes (MNB)","text":"Multinomial Naive Bayes (MNB) es una variante del algoritmo Naive Bayes dise√±ada espec√≠ficamente para la clasificaci√≥n de datos discretos, y es particularmente popular en tareas de procesamiento de lenguaje natural (NLP), como la clasificaci√≥n de texto (ej., spam/spam, clasificaci√≥n de documentos por tema). Al igual que otras formas de Naive Bayes, se basa en el Teorema de Bayes y la suposici√≥n clave de independencia condicional entre las caracter√≠sticas, dado el valor de la clase.La diferencia fundamental de MNB radica en que asume que las caracter√≠sticas (como el recuento de palabras en un documento de texto) provienen de una distribuci√≥n multinomial. Esto significa que:Caracter√≠sticas de Recuento: MNB es ideal para caracter√≠sticas que representan frecuencias o recuentos (ej., el n√∫mero de veces que aparece una palabra en un documento, el n√∫mero de veces que ocurre un evento).Modelado de Probabilidades: Para cada clase, MNB calcula la probabilidad de observar cada caracter√≠stica (ej., cada palabra del vocabulario) dado que la instancia pertenece esa clase. Estas probabilidades se estiman menudo utilizando suavizado Laplace (o aditivo) para evitar probabilidades de cero para palabras vistas durante el entrenamiento.Aplicaci√≥n del Teorema de Bayes: Luego, para clasificar una nueva instancia, multiplica las probabilidades de las caracter√≠sticas (asumiendo independencia) por la probabilidad previa de cada clase, y elige la clase que tiene la probabilidad posterior m√°s alta.MNB es altamente eficiente, escalable para grandes conjuntos de datos y menudo sorprendentemente efectivo pesar de su ingenua suposici√≥n de independencia, lo que lo convierte en una l√≠nea base s√≥lida para muchos problemas de clasificaci√≥n de texto.Aprendizaje Global vs.¬†Local:Multinomial Naive Bayes (MNB) es un modelo de aprendizaje global.Aspecto Global: MNB construye un modelo probabil√≠stico global para la relaci√≥n entre las caracter√≠sticas discretas (como recuentos de palabras) y las clases. Las probabilidades de las caracter√≠sticas dadas las clases (y las probabilidades previas de las clases) se estiman partir de todos los datos de entrenamiento. La regla de clasificaci√≥n final, basada en el Teorema de Bayes, se aplica de manera uniforme cualquier nueva instancia en el espacio de caracter√≠sticas. se ajustan modelos locales para diferentes vecindarios de datos; en su lugar, se utilizan las mismas probabilidades estimadas globalmente para todas las predicciones.Aspecto Global: MNB construye un modelo probabil√≠stico global para la relaci√≥n entre las caracter√≠sticas discretas (como recuentos de palabras) y las clases. Las probabilidades de las caracter√≠sticas dadas las clases (y las probabilidades previas de las clases) se estiman partir de todos los datos de entrenamiento. La regla de clasificaci√≥n final, basada en el Teorema de Bayes, se aplica de manera uniforme cualquier nueva instancia en el espacio de caracter√≠sticas. se ajustan modelos locales para diferentes vecindarios de datos; en su lugar, se utilizan las mismas probabilidades estimadas globalmente para todas las predicciones.Impacto de la Asunci√≥n de Independencia: La suposici√≥n de independencia condicional entre las caracter√≠sticas (ej., que la presencia de una palabra influye en la probabilidad de otra palabra dada la categor√≠a del documento) es una simplificaci√≥n global. Si bien esta simplicidad permite que MNB sea muy eficiente y robusto veces, tambi√©n significa que puede capturar interacciones complejas o dependencias lineales entre las caracter√≠sticas en el mismo sentido que modelos m√°s avanzados. Sin embargo, en muchas aplicaciones como la clasificaci√≥n de texto, donde la frecuencia individual de las palabras es muy informativa, esta suposici√≥n es lo suficientemente robusta para un buen rendimiento. Es un modelo que asume una estructura de probabilidad global y la aplica consistentemente.Impacto de la Asunci√≥n de Independencia: La suposici√≥n de independencia condicional entre las caracter√≠sticas (ej., que la presencia de una palabra influye en la probabilidad de otra palabra dada la categor√≠a del documento) es una simplificaci√≥n global. Si bien esta simplicidad permite que MNB sea muy eficiente y robusto veces, tambi√©n significa que puede capturar interacciones complejas o dependencias lineales entre las caracter√≠sticas en el mismo sentido que modelos m√°s avanzados. Sin embargo, en muchas aplicaciones como la clasificaci√≥n de texto, donde la frecuencia individual de las palabras es muy informativa, esta suposici√≥n es lo suficientemente robusta para un buen rendimiento. Es un modelo que asume una estructura de probabilidad global y la aplica consistentemente.","code":""},{"path":"modelos-bayesianos.html","id":"naive-bayes-nb","chapter":"üß¨ 6. Modelos Bayesianos","heading":"Naive Bayes (NB)","text":"Naive Bayes (NB) es un algoritmo de clasificaci√≥n supervisada popular y computacionalmente eficiente, basado en el Teorema de Bayes y una fuerte (o ‚Äúingenua‚Äù) suposici√≥n de independencia condicional entre las caracter√≠sticas (variables predictoras) dado el valor de la clase. Esta suposici√≥n significa que el modelo asume que la presencia o ausencia de una caracter√≠stica particular afecta la presencia o ausencia de otra caracter√≠stica, una vez que se conoce la clase.pesar de que esta suposici√≥n rara vez se cumple perfectamente en problemas del mundo real, Naive Bayes menudo ofrece un rendimiento sorprendentemente bueno, especialmente en tareas de clasificaci√≥n de texto y con grandes conjuntos de datos. Su simplicidad y velocidad lo convierten en un excelente algoritmo de l√≠nea base.El funcionamiento b√°sico de Naive Bayes es el siguiente:C√°lculo de Probabilidades Previas: Estima la probabilidad de cada clase en el conjunto de entrenamiento (ej., P(Clase ), P(Clase B)).C√°lculo de Probabilidades de Verosimilitud: Para cada caracter√≠stica y cada clase, calcula la probabilidad de que la caracter√≠stica tome un valor espec√≠fico, dado que la instancia pertenece esa clase (ej., P(Caracter√≠stica X | Clase )). Aqu√≠ es donde entran las diferentes variantes de Naive Bayes (Gaussian para caracter√≠sticas continuas, Multinomial para recuentos, Bernoulli para caracter√≠sticas binarias).Aplicaci√≥n del Teorema de Bayes: Para clasificar una nueva instancia, utiliza el Teorema de Bayes para combinar estas probabilidades y calcular la probabilidad posterior de cada clase, dadas las caracter√≠sticas de la nueva instancia. Finalmente, asigna la instancia la clase con la probabilidad posterior m√°s alta.Aprendizaje Global vs.¬†Local:Naive Bayes (NB) es un modelo de aprendizaje puramente global.Aspecto Global: Naive Bayes construye un modelo probabil√≠stico global que describe la relaci√≥n entre las caracter√≠sticas y las clases para todo el conjunto de datos. Las probabilidades previas de las clases y las probabilidades condicionales de las caracter√≠sticas dadas las clases se estiman partir de todos los datos de entrenamiento. La regla de clasificaci√≥n resultante se aplica de manera uniforme cualquier nueva instancia en el espacio de caracter√≠sticas, sin ajustar modelos locales para diferentes vecindarios de datos. El modelo aprende una distribuci√≥n de probabilidad que se asume v√°lida para todo el dominio.Aspecto Global: Naive Bayes construye un modelo probabil√≠stico global que describe la relaci√≥n entre las caracter√≠sticas y las clases para todo el conjunto de datos. Las probabilidades previas de las clases y las probabilidades condicionales de las caracter√≠sticas dadas las clases se estiman partir de todos los datos de entrenamiento. La regla de clasificaci√≥n resultante se aplica de manera uniforme cualquier nueva instancia en el espacio de caracter√≠sticas, sin ajustar modelos locales para diferentes vecindarios de datos. El modelo aprende una distribuci√≥n de probabilidad que se asume v√°lida para todo el dominio.Impacto de la Suposici√≥n de Independencia: La ‚Äúingenuidad‚Äù del modelo, es decir, la suposici√≥n de independencia entre las caracter√≠sticas, es una simplificaci√≥n global. intenta capturar interacciones complejas o lineales entre las caracter√≠sticas en s√≠. Si bien esto puede ser una limitaci√≥n cuando las relaciones entre las caracter√≠sticas son muy intrincadas y lineales, es precisamente esta suposici√≥n la que le otorga su eficiencia y robustez en muchos escenarios pr√°cticos. Es un modelo que asume una estructura de probabilidad global y la aplica de manera consistente.Impacto de la Suposici√≥n de Independencia: La ‚Äúingenuidad‚Äù del modelo, es decir, la suposici√≥n de independencia entre las caracter√≠sticas, es una simplificaci√≥n global. intenta capturar interacciones complejas o lineales entre las caracter√≠sticas en s√≠. Si bien esto puede ser una limitaci√≥n cuando las relaciones entre las caracter√≠sticas son muy intrincadas y lineales, es precisamente esta suposici√≥n la que le otorga su eficiencia y robustez en muchos escenarios pr√°cticos. Es un modelo que asume una estructura de probabilidad global y la aplica de manera consistente.","code":""},{"path":"regularizaci√≥n.html","id":"regularizaci√≥n","chapter":"üßÆ 7. Regularizaci√≥n","heading":"üßÆ 7. Regularizaci√≥n","text":"Ejemplos: L1 (Lasso), L2 (Ridge), Elastic Net.Uso: Esencial para prevenir el sobreajuste en modelos, especialmente los lineales y las redes neuronales. Muy √∫til cuando trabajas con muchas variables (alta dimensionalidad).Ventajas: Su principal beneficio es que penaliza la complejidad del modelo, forz√°ndolo ser m√°s simple y generalizable.Limitaciones: Si se aplica en exceso, la regularizaci√≥n puede eliminar variables √∫tiles y, por lo tanto, afectar el rendimiento del modelo.","code":""},{"path":"regularizaci√≥n.html","id":"elastic-net","chapter":"üßÆ 7. Regularizaci√≥n","heading":"Elastic Net","text":"Elastic Net es un m√©todo de regresi√≥n lineal regularizada que combina las penalizaciones de Ridge Regression (regresi√≥n L2) y Lasso Regression (regresi√≥n L1). Fue desarrollado para superar las limitaciones de Lasso, que puede tener problemas cuando hay un gran n√∫mero de variables predictoras o cuando estas variables est√°n altamente correlacionadas (multicolinealidad). Elastic Net es una herramienta muy vers√°til para la selecci√≥n de caracter√≠sticas, la reducci√≥n de sobreajuste y el manejo de datos de alta dimensi√≥n.La funci√≥n de costo de Elastic Net a√±ade dos t√©rminos de penalizaci√≥n la suma de los errores cuadrados de los residuos (como en la regresi√≥n OLS):Penalizaci√≥n L1 (Lasso): La suma del valor absoluto de los coeficientes. Esta penalizaci√≥n tiende reducir los coeficientes de las variables menos importantes cero, realizando as√≠ una selecci√≥n autom√°tica de caracter√≠sticas.Penalizaci√≥n L2 (Ridge): La suma del cuadrado de los coeficientes. Esta penalizaci√≥n encoge los coeficientes hacia cero, pero los fuerza ser exactamente cero. Es particularmente √∫til para manejar la multicolinealidad, ya que tiende distribuir la influencia de las variables correlacionadas de manera m√°s equitativa.Elastic Net utiliza dos hiperpar√°metros de sintonizaci√≥n:\\(\\alpha\\) (alpha): Controla el balance entre las penalizaciones L1 y L2.\nSi \\(\\alpha = 0\\), Elastic Net se convierte en Ridge Regression.\nSi \\(\\alpha = 1\\), Elastic Net se convierte en Lasso Regression.\nPara valores entre 0 y 1, es una mezcla de ambas.\nSi \\(\\alpha = 0\\), Elastic Net se convierte en Ridge Regression.Si \\(\\alpha = 1\\), Elastic Net se convierte en Lasso Regression.Para valores entre 0 y 1, es una mezcla de ambas.\\(\\lambda\\) (lambda): Controla la fuerza general de la regularizaci√≥n. Un \\(\\lambda\\) m√°s grande implica una mayor penalizaci√≥n y, por lo tanto, coeficientes m√°s peque√±os.Al combinar L1 y L2, Elastic Net logra lo mejor de ambos mundos: realiza selecci√≥n de caracter√≠sticas como Lasso y maneja la multicolinealidad y la estabilidad de los coeficientes como Ridge. Esto lo hace muy robusto en escenarios donde hay muchas variables correlacionadas.Aprendizaje Global vs.¬†Local:Elastic Net es un modelo de aprendizaje global.Aspecto Global: Elastic Net construye un modelo lineal global que se aplica todo el conjunto de datos. Los coeficientes de la regresi√≥n se estiman optimizando una funci√≥n de costo que considera todos los puntos de datos simult√°neamente. La penalizaci√≥n se aplica todos los coeficientes de manera uniforme, lo que busca una soluci√≥n que minimice el error de predicci√≥n y controle la complejidad del modelo nivel global. La ecuaci√≥n de regresi√≥n final es una funci√≥n que se aplica de manera consistente cualquier nueva observaci√≥n, sin importar su ubicaci√≥n en el espacio de caracter√≠sticas.Aspecto Global: Elastic Net construye un modelo lineal global que se aplica todo el conjunto de datos. Los coeficientes de la regresi√≥n se estiman optimizando una funci√≥n de costo que considera todos los puntos de datos simult√°neamente. La penalizaci√≥n se aplica todos los coeficientes de manera uniforme, lo que busca una soluci√≥n que minimice el error de predicci√≥n y controle la complejidad del modelo nivel global. La ecuaci√≥n de regresi√≥n final es una funci√≥n que se aplica de manera consistente cualquier nueva observaci√≥n, sin importar su ubicaci√≥n en el espacio de caracter√≠sticas.Influencia de la Regularizaci√≥n: Aunque la regresi√≥n en s√≠ es global, las penalizaciones de regularizaci√≥n pueden tener un efecto que podr√≠amos considerar ‚Äúadaptativo‚Äù en el sentido de que ajustan la influencia de las variables en funci√≥n de su relaci√≥n con otras variables y la respuesta. Por ejemplo, la penalizaci√≥n L1 puede ‚Äúlocalizar‚Äù las variables m√°s importantes al poner otras cero, y la L2 puede distribuir la importancia entre variables correlacionadas. Sin embargo, estas son propiedades de la optimizaci√≥n global del modelo, de ajustar modelos separados para diferentes subregiones del espacio de datos. La Elastic Net, al igual que OLS, Ridge y Lasso, busca una √∫nica relaci√≥n lineal que describa la tendencia general de los datos.Influencia de la Regularizaci√≥n: Aunque la regresi√≥n en s√≠ es global, las penalizaciones de regularizaci√≥n pueden tener un efecto que podr√≠amos considerar ‚Äúadaptativo‚Äù en el sentido de que ajustan la influencia de las variables en funci√≥n de su relaci√≥n con otras variables y la respuesta. Por ejemplo, la penalizaci√≥n L1 puede ‚Äúlocalizar‚Äù las variables m√°s importantes al poner otras cero, y la L2 puede distribuir la importancia entre variables correlacionadas. Sin embargo, estas son propiedades de la optimizaci√≥n global del modelo, de ajustar modelos separados para diferentes subregiones del espacio de datos. La Elastic Net, al igual que OLS, Ridge y Lasso, busca una √∫nica relaci√≥n lineal que describa la tendencia general de los datos.","code":""},{"path":"regularizaci√≥n.html","id":"ridge-regression","chapter":"üßÆ 7. Regularizaci√≥n","heading":"Ridge Regression","text":"Ridge Regression (Regresi√≥n Ridge) es un m√©todo de regresi√≥n lineal regularizada que se utiliza para mejorar la estimaci√≥n de los coeficientes en modelos lineales, especialmente cuando existe multicolinealidad (alta correlaci√≥n entre las variables predictoras) o cuando el n√∫mero de predictores es grande en relaci√≥n con el n√∫mero de observaciones. Ridge Regression fue una de las primeras t√©cnicas de regularizaci√≥n y es fundamental para comprender m√©todos m√°s avanzados como Lasso o Elastic Net.La Regresi√≥n Ridge aborda los problemas de la regresi√≥n por m√≠nimos cuadrados ordinarios (OLS) al a√±adir un t√©rmino de penalizaci√≥n L2 la funci√≥n de costo de los m√≠nimos cuadrados. La funci√≥n de costo que minimiza Ridge Regression es:\\[\\text{RSS} + \\lambda \\sum_{j=1}^{p} \\beta_j^2\\]Donde:\n* \\(\\text{RSS}\\) es la suma de los errores cuadrados de los residuos (Residual Sum Squares), que es lo que minimiza OLS.\n* \\(\\lambda\\) (lambda) es un par√°metro de sintonizaci√≥n (hiperpar√°metro) negativo. Este par√°metro controla la fuerza de la penalizaci√≥n.\n* \\(\\sum_{j=1}^{p} \\beta_j^2\\) es la penalizaci√≥n L2, que es la suma de los cuadrados de los coeficientes de regresi√≥n (excluyendo el intercepto).Efecto de la Penalizaci√≥n L2:\n* Encogimiento de Coeficientes: La penalizaci√≥n L2 encoge los coeficientes hacia cero. Cuanto mayor sea el valor de \\(\\lambda\\), mayor ser√° el encogimiento y m√°s peque√±os ser√°n los coeficientes.\n* Reducci√≥n de Varianza: Este encogimiento reduce la varianza de las estimaciones de los coeficientes, haci√©ndolos m√°s estables y menos sensibles peque√±as variaciones en los datos de entrenamiento. Esto ayuda reducir el sobreajuste.\n* Manejo de Multicolinealidad: En presencia de multicolinealidad, OLS puede asignar grandes valores los coeficientes de variables correlacionadas. Ridge Regression distribuye la influencia entre las variables correlacionadas de manera m√°s uniforme y reduce la magnitud de estos coeficientes, lo que resulta en un modelo m√°s robusto.\n* realiza selecci√≥n de caracter√≠sticas: diferencia de Lasso, Ridge Regression encoge los coeficientes, pero rara vez los fuerza ser exactamente cero. Esto significa que todas las variables predictoras (o casi todas) seguir√°n en el modelo.El valor √≥ptimo de \\(\\lambda\\) se selecciona t√≠picamente mediante t√©cnicas de validaci√≥n cruzada.Aprendizaje Global vs.¬†Local:Ridge Regression es un modelo de aprendizaje global.Aspecto Global: Ridge Regression construye un modelo lineal global que se aplica todo el conjunto de datos. Los coeficientes se estiman optimizando una funci√≥n de costo que considera todos los puntos de datos simult√°neamente. La penalizaci√≥n L2 se aplica todos los coeficientes para controlar la complejidad y la estabilidad del modelo nivel global. La ecuaci√≥n de regresi√≥n resultante es una funci√≥n √∫nica que se aplica de manera consistente cualquier nueva observaci√≥n, sin importar su ubicaci√≥n espec√≠fica en el espacio de caracter√≠sticas.Aspecto Global: Ridge Regression construye un modelo lineal global que se aplica todo el conjunto de datos. Los coeficientes se estiman optimizando una funci√≥n de costo que considera todos los puntos de datos simult√°neamente. La penalizaci√≥n L2 se aplica todos los coeficientes para controlar la complejidad y la estabilidad del modelo nivel global. La ecuaci√≥n de regresi√≥n resultante es una funci√≥n √∫nica que se aplica de manera consistente cualquier nueva observaci√≥n, sin importar su ubicaci√≥n espec√≠fica en el espacio de caracter√≠sticas.Estabilizaci√≥n Global: Aunque la regularizaci√≥n L2 mejora la estabilidad de las estimaciones de los coeficientes y ayuda manejar la multicolinealidad, lo hace como parte de una optimizaci√≥n global. implica la creaci√≥n de m√∫ltiples modelos locales o la adaptaci√≥n subregiones espec√≠ficas de los datos. La Regresi√≥n Ridge busca una relaci√≥n lineal subyacente que sea la mejor aproximaci√≥n para el conjunto de datos completo, penalizando la complejidad para mejorar la generalizaci√≥n global.Estabilizaci√≥n Global: Aunque la regularizaci√≥n L2 mejora la estabilidad de las estimaciones de los coeficientes y ayuda manejar la multicolinealidad, lo hace como parte de una optimizaci√≥n global. implica la creaci√≥n de m√∫ltiples modelos locales o la adaptaci√≥n subregiones espec√≠ficas de los datos. La Regresi√≥n Ridge busca una relaci√≥n lineal subyacente que sea la mejor aproximaci√≥n para el conjunto de datos completo, penalizando la complejidad para mejorar la generalizaci√≥n global.","code":""},{"path":"regularizaci√≥n.html","id":"least-absolute-shrinkage-and-selection-operator-lasso","chapter":"üßÆ 7. Regularizaci√≥n","heading":"Least Absolute Shrinkage and Selection Operator (LASSO)","text":"LASSO (Least Absolute Shrinkage Selection Operator) es un m√©todo de regresi√≥n lineal regularizada que, al igual que Ridge Regression, se utiliza para mejorar la estimaci√≥n de los coeficientes en modelos lineales y para abordar el sobreajuste, especialmente en escenarios con un gran n√∫mero de variables predictoras o cuando algunas de ellas son irrelevantes. LASSO es particularmente famoso por su capacidad para realizar selecci√≥n autom√°tica de caracter√≠sticas.LASSO logra esto a√±adiendo un t√©rmino de penalizaci√≥n L1 la funci√≥n de costo de los m√≠nimos cuadrados. La funci√≥n de costo que minimiza LASSO es:\\[\\text{RSS} + \\lambda \\sum_{j=1}^{p} |\\beta_j|\\]Donde:\n* \\(\\text{RSS}\\) es la suma de los errores cuadrados de los residuos.\n* \\(\\lambda\\) (lambda) es un par√°metro de sintonizaci√≥n (hiperpar√°metro) negativo que controla la fuerza de la penalizaci√≥n.\n* \\(\\sum_{j=1}^{p} |\\beta_j|\\) es la penalizaci√≥n L1, que es la suma del valor absoluto de los coeficientes de regresi√≥n (excluyendo el intercepto).Efecto de la Penalizaci√≥n L1:\n* Encogimiento de Coeficientes: Similar Ridge, la penalizaci√≥n L1 encoge los coeficientes hacia cero.\n* Selecci√≥n de Caracter√≠sticas: La caracter√≠stica distintiva de LASSO es que, debido la naturaleza de la penalizaci√≥n L1 (la suma de los valores absolutos), puede forzar los coeficientes de las variables menos importantes ser exactamente cero. Esto significa que LASSO solo encoge los coeficientes, sino que tambi√©n realiza una selecci√≥n autom√°tica de caracter√≠sticas, eliminando efectivamente las variables irrelevantes del modelo. Esto resulta en modelos m√°s simples y f√°ciles de interpretar.\n* Manejo de Multicolinealidad (con cuidado): Aunque LASSO puede manejar la multicolinealidad, tiende seleccionar arbitrariamente una de las variables correlacionadas y poner cero las dem√°s, lo que puede ser una desventaja en comparaci√≥n con Ridge (que distribuye la influencia). Elastic Net surgi√≥ para abordar esto.El valor √≥ptimo de \\(\\lambda\\) se selecciona t√≠picamente mediante t√©cnicas de validaci√≥n cruzada.Aprendizaje Global vs.¬†Local:LASSO es un modelo de aprendizaje global.Aspecto Global: LASSO construye un modelo lineal global que se aplica todo el conjunto de datos. Los coeficientes se estiman optimizando una funci√≥n de costo que considera todos los puntos de datos simult√°neamente. La penalizaci√≥n L1 se aplica todos los coeficientes para controlar la complejidad y realizar la selecci√≥n de caracter√≠sticas nivel global. La ecuaci√≥n de regresi√≥n final es una funci√≥n √∫nica que se aplica de manera consistente cualquier nueva observaci√≥n, sin importar su ubicaci√≥n en el espacio de caracter√≠sticas.Aspecto Global: LASSO construye un modelo lineal global que se aplica todo el conjunto de datos. Los coeficientes se estiman optimizando una funci√≥n de costo que considera todos los puntos de datos simult√°neamente. La penalizaci√≥n L1 se aplica todos los coeficientes para controlar la complejidad y realizar la selecci√≥n de caracter√≠sticas nivel global. La ecuaci√≥n de regresi√≥n final es una funci√≥n √∫nica que se aplica de manera consistente cualquier nueva observaci√≥n, sin importar su ubicaci√≥n en el espacio de caracter√≠sticas.Selecci√≥n Global de Caracter√≠sticas: Aunque LASSO puede ‚Äúlocalizar‚Äù qu√© variables son importantes al reducir sus coeficientes cero, esto se hace como parte de un proceso de optimizaci√≥n global que eval√∫a la contribuci√≥n de cada variable la predicci√≥n general del modelo. implica la creaci√≥n de m√∫ltiples modelos locales o la adaptaci√≥n subregiones espec√≠ficas de los datos. LASSO busca la relaci√≥n lineal m√°s parsimoniosa que mejor se ajuste al conjunto de datos completo.Selecci√≥n Global de Caracter√≠sticas: Aunque LASSO puede ‚Äúlocalizar‚Äù qu√© variables son importantes al reducir sus coeficientes cero, esto se hace como parte de un proceso de optimizaci√≥n global que eval√∫a la contribuci√≥n de cada variable la predicci√≥n general del modelo. implica la creaci√≥n de m√∫ltiples modelos locales o la adaptaci√≥n subregiones espec√≠ficas de los datos. LASSO busca la relaci√≥n lineal m√°s parsimoniosa que mejor se ajuste al conjunto de datos completo.","code":""},{"path":"regularizaci√≥n.html","id":"least-angle-regression-lars","chapter":"üßÆ 7. Regularizaci√≥n","heading":"Least Angle Regression (LARS)","text":"Least Angle Regression (LARS) es un algoritmo de regresi√≥n lineal desarrollado por Bradley Efron, Trevor Hastie, Iain Johnstone y Robert Tibshirani. Es particularmente interesante porque puede considerarse como una versi√≥n m√°s eficiente y paso paso de LASSO (Least Absolute Shrinkage Selection Operator) y es √∫til para seleccionar caracter√≠sticas y manejar datos de alta dimensi√≥n.diferencia de OLS, que calcula todos los coeficientes de una vez, o de Lasso, que requiere optimizaci√≥n m√°s compleja, LARS opera de manera incremental. Su idea central es avanzar los coeficientes de forma que su √°ngulo con el vector de residuos sea siempre el mismo y que sea el ‚Äúm√°s peque√±o‚Äù posible.El proceso de LARS se puede resumir as√≠:Inicio: Todos los coeficientes se inicializan en cero.Identificaci√≥n del Predictor m√°s Correlacionado: El algoritmo encuentra la variable predictora que est√° m√°s correlacionada con la variable de respuesta (o con el residuo actual).Movimiento en la Direcci√≥n del Predictor: El coeficiente de esa variable predictora se mueve gradualmente desde cero en la direcci√≥n del signo de su correlaci√≥n. medida que el coeficiente se mueve, el residuo cambia.Activaci√≥n de Nuevos Predictores: Cuando otra variable predictora alcanza la misma correlaci√≥n con el residuo actual que la variable que ya est√° activa, el algoritmo cambia de direcci√≥n. Ahora, los coeficientes de ambas variables activas se mueven juntas en un ‚Äú√°ngulo equiestad√≠stico‚Äù de tal manera que permanecen igualmente correlacionadas con el residuo.Proceso Iterativo: Este proceso contin√∫a, a√±adiendo nuevas variables al conjunto de variables ‚Äúactivas‚Äù (es decir, aquellas con coeficientes distintos de cero) medida que estas alcanzan la misma correlaci√≥n con el residuo. Los coeficientes se mueven de forma coordinada.Criterio de Parada: El algoritmo se detiene cuando todos los predictores han sido incluidos en el modelo, o cuando se alcanza un n√∫mero predefinido de pasos o de variables.Relaci√≥n con otros modelos:\n* Si LARS se detiene cuando los coeficientes de las variables activas son menores o iguales la correlaci√≥n actual de las variables activas (y los coeficientes de las variables activas se fijan en cero si su correlaci√≥n es menor), entonces genera la soluci√≥n completa del camino de LASSO.\n* Tambi√©n puede generar el camino de soluciones para la Ridge Regression si se modifica ligeramente.LARS es eficiente porque solo requiere un n√∫mero de pasos igual al n√∫mero de variables, o menos si se detiene antes.Aprendizaje Global vs.¬†Local:Least Angle Regression (LARS) es un modelo de aprendizaje global.Aspecto Global: LARS construye un modelo lineal global paso paso. Aunque el algoritmo a√±ade variables una por una y ajusta sus coeficientes de manera incremental, el modelo resultante en cada paso es una ecuaci√≥n de regresi√≥n lineal que se aplica todo el conjunto de datos. La decisi√≥n de qu√© variable a√±adir y c√≥mo ajustar los coeficientes se basa en las correlaciones globales entre las variables predictoras y la respuesta (o el residuo). La finalidad es encontrar los coeficientes √≥ptimos para una funci√≥n de regresi√≥n que se aplica todo el espacio de caracter√≠sticas.Aspecto Global: LARS construye un modelo lineal global paso paso. Aunque el algoritmo a√±ade variables una por una y ajusta sus coeficientes de manera incremental, el modelo resultante en cada paso es una ecuaci√≥n de regresi√≥n lineal que se aplica todo el conjunto de datos. La decisi√≥n de qu√© variable a√±adir y c√≥mo ajustar los coeficientes se basa en las correlaciones globales entre las variables predictoras y la respuesta (o el residuo). La finalidad es encontrar los coeficientes √≥ptimos para una funci√≥n de regresi√≥n que se aplica todo el espacio de caracter√≠sticas.Selecci√≥n de Caracter√≠sticas Globalmente: La capacidad de LARS para realizar selecci√≥n de caracter√≠sticas (al igual que LASSO) es un proceso global. Se identifican las variables m√°s influyentes en el contexto de todo el conjunto de datos, y su inclusi√≥n en el modelo contribuye la formaci√≥n de una relaci√≥n global entre los predictores y la respuesta. se construyen modelos separados para diferentes subregiones de los datos; en cambio, se construye un √∫nico modelo global de manera progresiva.Selecci√≥n de Caracter√≠sticas Globalmente: La capacidad de LARS para realizar selecci√≥n de caracter√≠sticas (al igual que LASSO) es un proceso global. Se identifican las variables m√°s influyentes en el contexto de todo el conjunto de datos, y su inclusi√≥n en el modelo contribuye la formaci√≥n de una relaci√≥n global entre los predictores y la respuesta. se construyen modelos separados para diferentes subregiones de los datos; en cambio, se construye un √∫nico modelo global de manera progresiva.","code":""},{"path":"modelos-basados-en-instancias.html","id":"modelos-basados-en-instancias","chapter":"üîç 8. Modelos Basados en Instancias","heading":"üîç 8. Modelos Basados en Instancias","text":"Ejemplos: K-Nearest Neighbors (KNN).Uso: Son ideales cuando tienes una cantidad limitada de datos y esperas que los patrones relevantes se encuentren en la similitud local entre casos. Se utilizan mucho cuando la similitud directa entre las observaciones es un factor clave.Ventajas: Su implementaci√≥n es simple y son bastante eficaces en problemas con pocas dimensiones.Limitaciones: Escalan mal con grandes vol√∫menes de datos debido que necesitan almacenar y comparar cada instancia. Adem√°s, son sensibles al ruido en los datos.","code":""},{"path":"modelos-basados-en-instancias.html","id":"k---nearest-neighbour-knn","chapter":"üîç 8. Modelos Basados en Instancias","heading":"k - Nearest Neighbour (kNN)","text":"k-Nearest Neighbour (kNN) es un algoritmo de Machine Learning param√©trico que se utiliza tanto para tareas de clasificaci√≥n como de regresi√≥n. Es considerado uno de los algoritmos m√°s simples y se basa en la idea de que los puntos de datos que est√°n cerca entre s√≠ en el espacio de caracter√≠sticas suelen tener propiedades similares. es un algoritmo que ‚Äúaprende‚Äù un modelo expl√≠cito durante la fase de entrenamiento, sino que es un algoritmo perezoso (lazy learner).Funcionamiento de kNN:Entrenamiento: En la fase de entrenamiento, kNN simplemente almacena todo el conjunto de datos de entrenamiento. hay un proceso de ‚Äúaprendizaje‚Äù de par√°metros o construcci√≥n de un modelo, como en la regresi√≥n lineal o las redes neuronales.Predicci√≥n (para una nueva instancia):\nIdentificar Vecinos: Para clasificar o predecir el valor de una nueva instancia, kNN calcula la distancia entre esta nueva instancia y todas las instancias en el conjunto de entrenamiento. La m√©trica de distancia m√°s com√∫n es la distancia euclidiana, pero se pueden usar otras (Manhattan, Minkowski, etc.).\nSeleccionar ‚Äòk‚Äô Vecinos M√°s Cercanos: Se identifican los ‚Äòk‚Äô puntos de datos del entrenamiento que son m√°s cercanos la nueva instancia. El valor de ‚Äòk‚Äô es un hiperpar√°metro que debe ser seleccionado por el usuario.\nClasificaci√≥n: Para tareas de clasificaci√≥n, la nueva instancia se asigna la clase que es la mayor√≠a entre sus ‚Äòk‚Äô vecinos m√°s cercanos (votaci√≥n mayoritaria).\nRegresi√≥n: Para tareas de regresi√≥n, el valor predicho para la nueva instancia es el promedio (o mediana) de los valores de la variable de respuesta de sus ‚Äòk‚Äô vecinos m√°s cercanos.\nIdentificar Vecinos: Para clasificar o predecir el valor de una nueva instancia, kNN calcula la distancia entre esta nueva instancia y todas las instancias en el conjunto de entrenamiento. La m√©trica de distancia m√°s com√∫n es la distancia euclidiana, pero se pueden usar otras (Manhattan, Minkowski, etc.).Seleccionar ‚Äòk‚Äô Vecinos M√°s Cercanos: Se identifican los ‚Äòk‚Äô puntos de datos del entrenamiento que son m√°s cercanos la nueva instancia. El valor de ‚Äòk‚Äô es un hiperpar√°metro que debe ser seleccionado por el usuario.Clasificaci√≥n: Para tareas de clasificaci√≥n, la nueva instancia se asigna la clase que es la mayor√≠a entre sus ‚Äòk‚Äô vecinos m√°s cercanos (votaci√≥n mayoritaria).Regresi√≥n: Para tareas de regresi√≥n, el valor predicho para la nueva instancia es el promedio (o mediana) de los valores de la variable de respuesta de sus ‚Äòk‚Äô vecinos m√°s cercanos.La elecci√≥n del valor de ‚Äòk‚Äô es crucial: un ‚Äòk‚Äô peque√±o puede hacer el modelo sensible al ruido (sobreajuste), mientras que un ‚Äòk‚Äô grande puede suavizar demasiado la predicci√≥n (subajuste) y las fronteras de decisi√≥n.Aprendizaje Global vs.¬†Local:k-Nearest Neighbour (kNN) es el ejemplo por excelencia de un modelo de aprendizaje puramente local.Aspecto Local: La predicci√≥n para una nueva instancia depende exclusivamente de los ‚Äòk‚Äô puntos de datos m√°s cercanos ella en el espacio de caracter√≠sticas. se construye un modelo global que abarque todo el conjunto de datos. En cambio, para cada nueva consulta, el algoritmo ‚Äúre-calcula‚Äù el vecindario relevante y realiza una predicci√≥n basada solo en la informaci√≥n de esa peque√±a regi√≥n local. Esto significa que la frontera de decisi√≥n (en clasificaci√≥n) o la funci√≥n de regresi√≥n (en regresi√≥n) se ajusta localmente las caracter√≠sticas del vecindario del punto de consulta. Si los datos se distribuyen linealmente y tienen estructuras complejas con patrones que var√≠an en diferentes regiones, kNN es muy efectivo porque puede adaptarse estas variaciones locales al funcionar como una ‚Äúregresi√≥n (o clasificaci√≥n) ponderada localmente‚Äù.Aspecto Local: La predicci√≥n para una nueva instancia depende exclusivamente de los ‚Äòk‚Äô puntos de datos m√°s cercanos ella en el espacio de caracter√≠sticas. se construye un modelo global que abarque todo el conjunto de datos. En cambio, para cada nueva consulta, el algoritmo ‚Äúre-calcula‚Äù el vecindario relevante y realiza una predicci√≥n basada solo en la informaci√≥n de esa peque√±a regi√≥n local. Esto significa que la frontera de decisi√≥n (en clasificaci√≥n) o la funci√≥n de regresi√≥n (en regresi√≥n) se ajusta localmente las caracter√≠sticas del vecindario del punto de consulta. Si los datos se distribuyen linealmente y tienen estructuras complejas con patrones que var√≠an en diferentes regiones, kNN es muy efectivo porque puede adaptarse estas variaciones locales al funcionar como una ‚Äúregresi√≥n (o clasificaci√≥n) ponderada localmente‚Äù.Sin Modelo Expl√≠cito Global: Debido su naturaleza de ‚Äúaprendizaje perezoso‚Äù, kNN genera una funci√≥n matem√°tica expl√≠cita o un conjunto de coeficientes que describan la relaci√≥n global entre las variables. Todo el conocimiento del modelo est√° impl√≠cito en la base de datos de entrenamiento.Sin Modelo Expl√≠cito Global: Debido su naturaleza de ‚Äúaprendizaje perezoso‚Äù, kNN genera una funci√≥n matem√°tica expl√≠cita o un conjunto de coeficientes que describan la relaci√≥n global entre las variables. Todo el conocimiento del modelo est√° impl√≠cito en la base de datos de entrenamiento.","code":""},{"path":"modelos-basados-en-instancias.html","id":"learning-vector-quantization-lvq","chapter":"üîç 8. Modelos Basados en Instancias","heading":"Learning Vector Quantization (LVQ)","text":"Learning Vector Quantization (LVQ) es un algoritmo de clasificaci√≥n supervisada basado en prototipos, desarrollado por Teuvo Kohonen. Puede ser visto como un tipo de red neuronal artificial que utiliza un enfoque de ‚Äúganador se lleva todo‚Äù (winner-take-) para aprender clasificar datos. LVQ es una alternativa al algoritmo k-Nearest Neighbour (kNN) que busca reducir la cantidad de informaci√≥n necesaria para almacenar los datos de entrenamiento, aprendiendo un conjunto m√°s peque√±o de prototipos que representan las clases.La idea central de LVQ es la siguiente:Representaci√≥n por Prototipos: En lugar de memorizar todos los puntos de datos de entrenamiento (como kNN), LVQ aprende un conjunto de vectores prototipo (o ‚Äúcodebook vectors‚Äù). Cada prototipo est√° asociado una clase espec√≠fica y representa una ‚Äúregi√≥n‚Äù en el espacio de caracter√≠sticas que pertenece esa clase.Proceso de Aprendizaje (Entrenamiento Supervisado):\nSe inicializan los prototipos (menudo aleatoriamente o con puntos de datos de entrenamiento).\nPara cada instancia de entrenamiento:\nSe encuentra el prototipo m√°s cercano (el ‚Äúganador‚Äù) esa instancia utilizando una m√©trica de distancia (com√∫nmente la distancia euclidiana).\nSe ajusta la posici√≥n de este prototipo ganador:\nSi el prototipo ganador tiene la misma clase que la instancia de entrenamiento, el prototipo se mueve ligeramente m√°s cerca de la instancia (recompensa).\nSi el prototipo ganador tiene una clase diferente la instancia de entrenamiento, el prototipo se mueve ligeramente m√°s lejos de la instancia (penalizaci√≥n).\n\n\nEste proceso iterativo contin√∫a hasta que los prototipos convergen o se alcanza un n√∫mero m√°ximo de √©pocas. Las diferentes variantes de LVQ (LVQ1, LVQ2.1, LVQ3) tienen reglas de actualizaci√≥n ligeramente distintas.\nSe inicializan los prototipos (menudo aleatoriamente o con puntos de datos de entrenamiento).Para cada instancia de entrenamiento:\nSe encuentra el prototipo m√°s cercano (el ‚Äúganador‚Äù) esa instancia utilizando una m√©trica de distancia (com√∫nmente la distancia euclidiana).\nSe ajusta la posici√≥n de este prototipo ganador:\nSi el prototipo ganador tiene la misma clase que la instancia de entrenamiento, el prototipo se mueve ligeramente m√°s cerca de la instancia (recompensa).\nSi el prototipo ganador tiene una clase diferente la instancia de entrenamiento, el prototipo se mueve ligeramente m√°s lejos de la instancia (penalizaci√≥n).\n\nSe encuentra el prototipo m√°s cercano (el ‚Äúganador‚Äù) esa instancia utilizando una m√©trica de distancia (com√∫nmente la distancia euclidiana).Se ajusta la posici√≥n de este prototipo ganador:\nSi el prototipo ganador tiene la misma clase que la instancia de entrenamiento, el prototipo se mueve ligeramente m√°s cerca de la instancia (recompensa).\nSi el prototipo ganador tiene una clase diferente la instancia de entrenamiento, el prototipo se mueve ligeramente m√°s lejos de la instancia (penalizaci√≥n).\nSi el prototipo ganador tiene la misma clase que la instancia de entrenamiento, el prototipo se mueve ligeramente m√°s cerca de la instancia (recompensa).Si el prototipo ganador tiene una clase diferente la instancia de entrenamiento, el prototipo se mueve ligeramente m√°s lejos de la instancia (penalizaci√≥n).Este proceso iterativo contin√∫a hasta que los prototipos convergen o se alcanza un n√∫mero m√°ximo de √©pocas. Las diferentes variantes de LVQ (LVQ1, LVQ2.1, LVQ3) tienen reglas de actualizaci√≥n ligeramente distintas.Clasificaci√≥n (Predicci√≥n): Para clasificar una nueva instancia, simplemente se encuentra el prototipo m√°s cercano esa instancia en el espacio de caracter√≠sticas. La nueva instancia se asigna la clase asociada con ese prototipo m√°s cercano. Es similar un clasificador 1-NN que opera sobre los prototipos aprendidos.LVQ es valorado por la interpretabilidad de sus prototipos (ya que son puntos en el espacio de caracter√≠sticas que representan una clase) y por su eficiencia una vez que los prototipos han sido aprendidos, ya que la predicci√≥n es mucho m√°s r√°pida que kNN en grandes conjuntos de datos.Aprendizaje Global vs.¬†Local:Learning Vector Quantization (LVQ) es un modelo que exhibe caracter√≠sticas de aprendizaje tanto global como local.Aspecto Local: El coraz√≥n del aprendizaje en LVQ es la adaptaci√≥n local de los prototipos. En cada paso de entrenamiento, solo el prototipo m√°s cercano (o los dos prototipos m√°s cercanos en algunas variantes como LVQ2.1 y LVQ3) una instancia de entrenamiento se ajusta. Esto significa que las reglas de aprendizaje operan en un vecindario localizado alrededor de la instancia de entrada. Los prototipos se mueven en el espacio de caracter√≠sticas para delimitar mejor las fronteras de clase, lo que refleja la estructura local de los datos. De esta manera, LVQ puede modelar relaciones lineales y estructuras de clase complejas al ajustar las posiciones de estos ‚Äúrepresentantes‚Äù locales de las clases.Aspecto Local: El coraz√≥n del aprendizaje en LVQ es la adaptaci√≥n local de los prototipos. En cada paso de entrenamiento, solo el prototipo m√°s cercano (o los dos prototipos m√°s cercanos en algunas variantes como LVQ2.1 y LVQ3) una instancia de entrenamiento se ajusta. Esto significa que las reglas de aprendizaje operan en un vecindario localizado alrededor de la instancia de entrada. Los prototipos se mueven en el espacio de caracter√≠sticas para delimitar mejor las fronteras de clase, lo que refleja la estructura local de los datos. De esta manera, LVQ puede modelar relaciones lineales y estructuras de clase complejas al ajustar las posiciones de estos ‚Äúrepresentantes‚Äù locales de las clases.Aspecto Global: Aunque el ajuste es local, el conjunto de todos los prototipos de LVQ, una vez entrenados, forma una representaci√≥n global del espacio de caracter√≠sticas que se utiliza para la clasificaci√≥n. Estos prototipos definen un mapa de clasificaci√≥n en todo el espacio de entrada, donde cada regi√≥n (celda de Voronoi) se asocia con una clase. Por lo tanto, el modelo final, que es la colecci√≥n de prototipos, se aplica de manera global para clasificar cualquier nueva observaci√≥n. El proceso de optimizaci√≥n para encontrar las posiciones de los prototipos, aunque iterativo y basado en actualizaciones locales, busca una configuraci√≥n global √≥ptima que minimice el error de clasificaci√≥n en todo el conjunto de entrenamiento.Aspecto Global: Aunque el ajuste es local, el conjunto de todos los prototipos de LVQ, una vez entrenados, forma una representaci√≥n global del espacio de caracter√≠sticas que se utiliza para la clasificaci√≥n. Estos prototipos definen un mapa de clasificaci√≥n en todo el espacio de entrada, donde cada regi√≥n (celda de Voronoi) se asocia con una clase. Por lo tanto, el modelo final, que es la colecci√≥n de prototipos, se aplica de manera global para clasificar cualquier nueva observaci√≥n. El proceso de optimizaci√≥n para encontrar las posiciones de los prototipos, aunque iterativo y basado en actualizaciones locales, busca una configuraci√≥n global √≥ptima que minimice el error de clasificaci√≥n en todo el conjunto de entrenamiento.","code":""},{"path":"modelos-basados-en-instancias.html","id":"locally-weighted-learning-lwl","chapter":"üîç 8. Modelos Basados en Instancias","heading":"Locally Weighted Learning (LWL)","text":"Locally Weighted Learning (LWL) es una clase de algoritmos de aprendizaje supervisado param√©trico que se distingue por su enfoque en la construcci√≥n de modelos locales para cada nueva instancia de consulta, en lugar de aprender un √∫nico modelo global para todo el conjunto de datos. Es un tipo de ‚Äúaprendizaje perezoso‚Äù (lazy learning), lo que significa que la mayor parte del ‚Äútrabajo‚Äù (c√°lculos) se realiza en el momento de la predicci√≥n, durante una fase de entrenamiento expl√≠cita.La idea central de LWL es que, para predecir la salida de una nueva instancia de consulta, se construye un modelo simple (menudo lineal o polin√≥mico) utilizando solo las instancias de entrenamiento que son ‚Äúcercanas‚Äù la instancia de consulta. Adem√°s, las instancias de entrenamiento m√°s cercanas se les asigna un peso mayor en la construcci√≥n de este modelo local.El proceso de LWL (especialmente para regresi√≥n, conocida como Regresi√≥n Lineal Ponderada Localmente - LWLR o LOESS/LOWESS) implica:Sin Fase de Entrenamiento expl√≠cita: El algoritmo simplemente almacena todo el conjunto de datos de entrenamiento.Para cada Instancia de Consulta (Predicci√≥n):\nC√°lculo de Distancias: Se calcula la distancia entre la instancia de consulta y todas las instancias de entrenamiento.\nAsignaci√≥n de Pesos: Se aplica una funci√≥n de kernel (funci√≥n de ponderaci√≥n) estas distancias para asignar un peso cada instancia de entrenamiento. Las instancias m√°s cercanas la consulta reciben un peso mayor, y los pesos disminuyen medida que la distancia aumenta. Un hiperpar√°metro llamado ancho de banda (bandwidth) controla qu√© tan r√°pido disminuyen los pesos con la distancia (determina el ‚Äútama√±o del vecindario‚Äù influyente).\nConstrucci√≥n del Modelo Local: Se ajusta un modelo simple (ej., una regresi√≥n lineal) las instancias de entrenamiento, pero esta vez, cada instancia se pondera seg√∫n el peso calculado. Esto es, se minimiza una suma de errores cuadrados ponderada.\nPredicci√≥n: El valor predicho para la instancia de consulta se obtiene utilizando este modelo local reci√©n construido. El modelo local se descarta despu√©s de hacer la predicci√≥n para esa instancia.\nC√°lculo de Distancias: Se calcula la distancia entre la instancia de consulta y todas las instancias de entrenamiento.Asignaci√≥n de Pesos: Se aplica una funci√≥n de kernel (funci√≥n de ponderaci√≥n) estas distancias para asignar un peso cada instancia de entrenamiento. Las instancias m√°s cercanas la consulta reciben un peso mayor, y los pesos disminuyen medida que la distancia aumenta. Un hiperpar√°metro llamado ancho de banda (bandwidth) controla qu√© tan r√°pido disminuyen los pesos con la distancia (determina el ‚Äútama√±o del vecindario‚Äù influyente).Construcci√≥n del Modelo Local: Se ajusta un modelo simple (ej., una regresi√≥n lineal) las instancias de entrenamiento, pero esta vez, cada instancia se pondera seg√∫n el peso calculado. Esto es, se minimiza una suma de errores cuadrados ponderada.Predicci√≥n: El valor predicho para la instancia de consulta se obtiene utilizando este modelo local reci√©n construido. El modelo local se descarta despu√©s de hacer la predicci√≥n para esa instancia.LWL es muy efectivo para modelar relaciones lineales y complejas en los datos porque puede adaptar la forma de la funci√≥n de predicci√≥n las variaciones locales. Es una generalizaci√≥n de k-Nearest Neighbors (kNN) donde en lugar de solo promediar o votar, se ajusta un modelo ponderado.Aprendizaje Global vs.¬†Local:Locally Weighted Learning (LWL) es el ep√≠tome del aprendizaje puramente local.Aspecto Local: LWL es intr√≠nsecamente local en su funcionamiento. Para cada nueva predicci√≥n, se construye un modelo espec√≠fico y √∫nico que solo es v√°lido en el vecindario local de la instancia de consulta. Los pesos asignados las instancias de entrenamiento enfatizan las que est√°n m√°s cerca del punto de consulta, lo que significa que el modelo se ‚Äúadapta‚Äù la estructura de los datos en esa regi√≥n particular del espacio de caracter√≠sticas. Esto le permite manejar eficientemente relaciones lineales y heterog√©neas, ya que la relaci√≥n puede ser diferente en distintas partes del dominio de los datos.Aspecto Local: LWL es intr√≠nsecamente local en su funcionamiento. Para cada nueva predicci√≥n, se construye un modelo espec√≠fico y √∫nico que solo es v√°lido en el vecindario local de la instancia de consulta. Los pesos asignados las instancias de entrenamiento enfatizan las que est√°n m√°s cerca del punto de consulta, lo que significa que el modelo se ‚Äúadapta‚Äù la estructura de los datos en esa regi√≥n particular del espacio de caracter√≠sticas. Esto le permite manejar eficientemente relaciones lineales y heterog√©neas, ya que la relaci√≥n puede ser diferente en distintas partes del dominio de los datos.Sin Modelo Expl√≠cito Global: hay un conjunto fijo de par√°metros o una funci√≥n matem√°tica √∫nica que describa la relaci√≥n entre las entradas y las salidas para todo el conjunto de datos. En cambio, el ‚Äúmodelo‚Äù se genera din√°micamente para cada punto de consulta, utilizando solo la informaci√≥n relevante de su vecindario. La complejidad computacional de LWL aumenta con el n√∫mero de predicciones, ya que cada una requiere la construcci√≥n de un nuevo modelo local.Sin Modelo Expl√≠cito Global: hay un conjunto fijo de par√°metros o una funci√≥n matem√°tica √∫nica que describa la relaci√≥n entre las entradas y las salidas para todo el conjunto de datos. En cambio, el ‚Äúmodelo‚Äù se genera din√°micamente para cada punto de consulta, utilizando solo la informaci√≥n relevante de su vecindario. La complejidad computacional de LWL aumenta con el n√∫mero de predicciones, ya que cada una requiere la construcci√≥n de un nuevo modelo local.","code":""},{"path":"modelos-basados-en-instancias.html","id":"self---organizing-map-som","chapter":"üîç 8. Modelos Basados en Instancias","heading":"Self - Organizing Map (SOM)","text":"Una Self-Organizing Map (SOM), tambi√©n conocida como Mapa Autoorganizado de Kohonen o Mapa de Caracter√≠sticas Autoorganizado (SOFM), es un tipo de red neuronal artificial supervisada utilizada principalmente para reducci√≥n de dimensionalidad y visualizaci√≥n de datos. Su objetivo es producir una representaci√≥n de baja dimensi√≥n (t√≠picamente bidimensional) de un conjunto de datos de alta dimensi√≥n, mientras preserva la estructura topol√≥gica de los datos originales. Esto significa que los puntos de datos que son similares en el espacio de alta dimensi√≥n se mapean neuronas cercanas en el mapa de baja dimensi√≥n.diferencia de otras redes neuronales que utilizan el aprendizaje por retropropagaci√≥n y descenso de gradiente (aprendizaje basado en el error), las SOM utilizan un proceso de aprendizaje competitivo.El funcionamiento de un SOM implica los siguientes pasos iterativos:Inicializaci√≥n: Se crea una cuadr√≠cula de ‚Äúneuronas‚Äù (tambi√©n llamadas unidades o nodos) en el espacio de baja dimensi√≥n (ej., una cuadr√≠cula 2D). cada neurona se le asigna un vector de pesos con la misma dimensionalidad que los datos de entrada. Estos vectores de pesos se inicializan aleatoriamente o de forma lineal.Competencia: Para cada vector de entrada (punto de datos) del conjunto de entrenamiento:\nSe calcula la distancia (com√∫nmente euclidiana) entre el vector de entrada y el vector de pesos de cada neurona en la cuadr√≠cula.\nLa neurona con el vector de pesos m√°s cercano al vector de entrada se denomina Unidad de Mejor Coincidencia (BMU - Best Matching Unit).\nSe calcula la distancia (com√∫nmente euclidiana) entre el vector de entrada y el vector de pesos de cada neurona en la cuadr√≠cula.La neurona con el vector de pesos m√°s cercano al vector de entrada se denomina Unidad de Mejor Coincidencia (BMU - Best Matching Unit).Cooperaci√≥n (Vecindad): La BMU y sus neuronas vecinas (dentro de un radio definido en la cuadr√≠cula) son identificadas. El tama√±o de este radio de vecindad disminuye con el tiempo medida que avanza el entrenamiento. La influencia del ajuste de los pesos disminuye con la distancia de la BMU dentro de esta vecindad (definido por una funci√≥n de vecindad, como una Gaussiana).Adaptaci√≥n: Los vectores de pesos de la BMU y sus neuronas vecinas se ajustan ligeramente para que se acerquen al vector de entrada original. La magnitud del ajuste est√° determinada por una tasa de aprendizaje, que tambi√©n disminuye con el tiempo. El ajuste es mayor para la BMU y menor para las neuronas m√°s alejadas dentro del radio de vecindad.Iteraci√≥n: Los pasos 2-4 se repiten para un gran n√∫mero de √©pocas (iteraciones) y para todos los vectores de entrada, hasta que los pesos de las neuronas convergen y la red se ‚Äúautoorganiza‚Äù.Al final del entrenamiento, las neuronas en el mapa se han organizado de tal manera que las neuronas cercanas representan datos de entrada similares, creando un ‚Äúmapa‚Äù donde las regiones con densidades de datos similares forman grupos o clusters.Aprendizaje Global vs.¬†Local:Una Self-Organizing Map (SOM) es un modelo que combina aspectos de aprendizaje global y local de una manera muy particular, que evoluciona lo largo del proceso de entrenamiento.Aspecto Global (Fases Iniciales del Entrenamiento): Al principio del entrenamiento, el radio de vecindad y la tasa de aprendizaje son grandes. Esto significa que cuando una BMU se ajusta, un gran n√∫mero de neuronas circundantes en el mapa tambi√©n se ajustan, incluso aquellas que est√°n relativamente lejos de la BMU. Este amplio ajuste permite que el mapa se ‚Äúorganice globalmente‚Äù para capturar la estructura general de los datos. La topolog√≠a general de la proyecci√≥n se establece en esta fase inicial. El mapa se estira y se contrae para abarcar la dispersi√≥n global de los datos, como si una ‚Äúregresi√≥n ponderada localmente‚Äù de gran escala estuviera adaptando el mapa entero.Aspecto Global (Fases Iniciales del Entrenamiento): Al principio del entrenamiento, el radio de vecindad y la tasa de aprendizaje son grandes. Esto significa que cuando una BMU se ajusta, un gran n√∫mero de neuronas circundantes en el mapa tambi√©n se ajustan, incluso aquellas que est√°n relativamente lejos de la BMU. Este amplio ajuste permite que el mapa se ‚Äúorganice globalmente‚Äù para capturar la estructura general de los datos. La topolog√≠a general de la proyecci√≥n se establece en esta fase inicial. El mapa se estira y se contrae para abarcar la dispersi√≥n global de los datos, como si una ‚Äúregresi√≥n ponderada localmente‚Äù de gran escala estuviera adaptando el mapa entero.Aspecto Local (Fases Posteriores del Entrenamiento): medida que el entrenamiento avanza, el radio de vecindad y la tasa de aprendizaje disminuyen gradualmente. Esto hace que los ajustes los pesos sean cada vez m√°s localizados. En las etapas finales, solo la BMU y sus vecinos m√°s cercanos (o incluso solo la BMU) se ajustan significativamente. Esta fase de ‚Äúafinamiento‚Äù permite que el mapa capture los detalles m√°s finos y las estructuras locales dentro de los datos, refinando las fronteras entre los grupos y asegurando que los puntos similares se agrupen con alta precisi√≥n.Aspecto Local (Fases Posteriores del Entrenamiento): medida que el entrenamiento avanza, el radio de vecindad y la tasa de aprendizaje disminuyen gradualmente. Esto hace que los ajustes los pesos sean cada vez m√°s localizados. En las etapas finales, solo la BMU y sus vecinos m√°s cercanos (o incluso solo la BMU) se ajustan significativamente. Esta fase de ‚Äúafinamiento‚Äù permite que el mapa capture los detalles m√°s finos y las estructuras locales dentro de los datos, refinando las fronteras entre los grupos y asegurando que los puntos similares se agrupen con alta precisi√≥n.","code":""},{"path":"clustering-aprendizaje-no-supervisado.html","id":"clustering-aprendizaje-no-supervisado","chapter":"üìè 9. Clustering (Aprendizaje No Supervisado)","heading":"üìè 9. Clustering (Aprendizaje No Supervisado)","text":"Ejemplos: K-Means, DBSCAN, Agrupamiento Jer√°rquico.Uso: Excelente para agrupar datos sin etiquetas previas, permiti√©ndote descubrir estructuras ocultas o identificar segmentos de mercado dentro de tus conjuntos de datos. Es una herramienta clave en la exploraci√≥n de datos.Ventajas: Es incre√≠blemente √∫til para la exploraci√≥n de datos y para reducir la complejidad al encontrar patrones inherentes.Limitaciones: Generalmente, necesitas elegir el n√∫mero de grupos de antemano (excepto en DBSCAN), lo cual puede ser un desaf√≠o. Adem√°s, algunos algoritmos pueden ser sensibles la escala de las caracter√≠sticas de tus datos.","code":""},{"path":"clustering-aprendizaje-no-supervisado.html","id":"density-based-spatial-clustering-of-applications-with-noise-dbscan","chapter":"üìè 9. Clustering (Aprendizaje No Supervisado)","heading":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","text":"DBSCAN (Density-Based Spatial Clustering Applications Noise) es un algoritmo de agrupamiento (clustering) supervisado que se distingue de los algoritmos basados en centroides (como k-Means) por su capacidad para encontrar clusters de formas arbitrarias y para identificar puntos de ruido (outliers). Su idea central es que los clusters son regiones densas de puntos en el espacio de caracter√≠sticas, separadas por regiones de baja densidad.DBSCAN define tres tipos de puntos:Punto N√∫cleo (Core Point): Un punto es un punto n√∫cleo si, dentro de un radio especificado (\\(\\epsilon\\) o eps), contiene un n√∫mero m√≠nimo de otros puntos ( MinPts).Punto Frontera (Border Point): Un punto es un punto frontera si est√° dentro del radio \\(\\epsilon\\) de un punto n√∫cleo, pero es un punto n√∫cleo en s√≠ mismo (tiene MinPts vecinos dentro de su propio radio \\(\\epsilon\\)).Punto de Ruido (Noise Point): Cualquier punto que es un punto n√∫cleo ni un punto frontera. Estos puntos son considerados outliers.El algoritmo de DBSCAN opera de la siguiente manera:Inicializaci√≥n: Selecciona un punto arbitrario del conjunto de datos que a√∫n ha sido visitado.Expansi√≥n de Cluster:\nSi el punto seleccionado es un punto n√∫cleo, se inicia un nuevo cluster. Todos sus vecinos dentro del radio \\(\\epsilon\\) se a√±aden al cluster.\nRecursivamente, se visitan y a√±aden los vecinos de esos nuevos puntos. Si un vecino es tambi√©n un punto n√∫cleo, sus propios vecinos tambi√©n se a√±aden al cluster. Este proceso contin√∫a hasta que se puedan a√±adir m√°s puntos al cluster (es decir, todos los puntos alcanzables por densidad han sido encontrados).\nSi el punto seleccionado es un punto n√∫cleo, se marca como ruido (o se deja para ser procesado m√°s tarde si es un punto frontera de otro cluster ya formado).\nSi el punto seleccionado es un punto n√∫cleo, se inicia un nuevo cluster. Todos sus vecinos dentro del radio \\(\\epsilon\\) se a√±aden al cluster.Recursivamente, se visitan y a√±aden los vecinos de esos nuevos puntos. Si un vecino es tambi√©n un punto n√∫cleo, sus propios vecinos tambi√©n se a√±aden al cluster. Este proceso contin√∫a hasta que se puedan a√±adir m√°s puntos al cluster (es decir, todos los puntos alcanzables por densidad han sido encontrados).Si el punto seleccionado es un punto n√∫cleo, se marca como ruido (o se deja para ser procesado m√°s tarde si es un punto frontera de otro cluster ya formado).Iteraci√≥n: El proceso se repite con otro punto visitado hasta que todos los puntos han sido procesados.DBSCAN es particularmente √∫til para encontrar clusters complejos en conjuntos de datos ruidosos y requiere que el usuario especifique el n√∫mero de clusters de antemano. Sus dos hiperpar√°metros clave son eps (el radio de b√∫squeda de vecindad) y MinPts (el n√∫mero m√≠nimo de puntos para formar un n√∫cleo).Aprendizaje Global vs.¬†Local:DBSCAN es un algoritmo de agrupamiento inherentemente local, aunque el resultado final es una partici√≥n global de los datos en clusters y ruido.Aspecto Local: El coraz√≥n de DBSCAN reside en la definici√≥n de densidad local y la conectividad. Las decisiones sobre si un punto es un n√∫cleo, un frontera o ruido, y si dos puntos pertenecen al mismo cl√∫ster, se basan exclusivamente en la densidad de puntos en un vecindario muy localizado definido por el radio \\(\\epsilon\\) y el MinPts. El algoritmo ‚Äúexpande‚Äù los cl√∫steres al moverse de un punto n√∫cleo sus vecinos, y de estos sus vecinos, y as√≠ sucesivamente. Esta capacidad de crecer y formar cl√∫steres org√°nicamente partir de las densidades locales es lo que permite DBSCAN descubrir formas arbitrarias y adaptarse la estructura local de los datos. hay una funci√≥n global o centroides predefinidos que gu√≠en la agrupaci√≥n; todo se deriva de las propiedades de densidad local.Aspecto Local: El coraz√≥n de DBSCAN reside en la definici√≥n de densidad local y la conectividad. Las decisiones sobre si un punto es un n√∫cleo, un frontera o ruido, y si dos puntos pertenecen al mismo cl√∫ster, se basan exclusivamente en la densidad de puntos en un vecindario muy localizado definido por el radio \\(\\epsilon\\) y el MinPts. El algoritmo ‚Äúexpande‚Äù los cl√∫steres al moverse de un punto n√∫cleo sus vecinos, y de estos sus vecinos, y as√≠ sucesivamente. Esta capacidad de crecer y formar cl√∫steres org√°nicamente partir de las densidades locales es lo que permite DBSCAN descubrir formas arbitrarias y adaptarse la estructura local de los datos. hay una funci√≥n global o centroides predefinidos que gu√≠en la agrupaci√≥n; todo se deriva de las propiedades de densidad local.Resultado Global (Partici√≥n): Aunque el proceso es local, el resultado final es una partici√≥n global del conjunto de datos en varios cl√∫steres y un conjunto de puntos de ruido. Una vez que todos los puntos han sido procesados y los cl√∫steres expandidos, se obtiene una vista global de la estructura de agrupamiento.Resultado Global (Partici√≥n): Aunque el proceso es local, el resultado final es una partici√≥n global del conjunto de datos en varios cl√∫steres y un conjunto de puntos de ruido. Una vez que todos los puntos han sido procesados y los cl√∫steres expandidos, se obtiene una vista global de la estructura de agrupamiento.","code":""},{"path":"clustering-aprendizaje-no-supervisado.html","id":"expectation-maximization-em","chapter":"üìè 9. Clustering (Aprendizaje No Supervisado)","heading":"Expectation Maximization (EM)","text":"El algoritmo Expectation-Maximization (EM) es un m√©todo iterativo utilizado en estad√≠stica para encontrar las estimaciones de m√°xima verosimilitud (MLE) o las estimaciones de m√°xima posteriori (MAP) de los par√°metros en modelos estad√≠sticos, especialmente cuando el modelo depende de variables latentes (observadas o ‚Äúocultas‚Äù) o cuando los datos est√°n ‚Äúincompletos‚Äù.EM es particularmente √∫til para modelos de mezcla, donde se asume que los datos observados son una mezcla de varias distribuciones subyacentes, y la pertenencia de cada punto de datos una distribuci√≥n espec√≠fica es la variable latente. El algoritmo consta de dos pasos principales que se alternan hasta la convergencia:Paso E (Expectation Step - Paso de Expectativa):\nEn este paso, dadas las estimaciones actuales de los par√°metros del modelo, se calculan las probabilidades esperadas (o ‚Äúresponsabilidades‚Äù) de que cada punto de datos observado pertenezca cada una de las componentes latentes (o de que las variables latentes tomen ciertos valores).\nEsencialmente, se est√° haciendo una ‚Äúsuposici√≥n‚Äù sobre los valores de las variables latentes bas√°ndose en los par√°metros actuales del modelo y los datos observados.\nEn este paso, dadas las estimaciones actuales de los par√°metros del modelo, se calculan las probabilidades esperadas (o ‚Äúresponsabilidades‚Äù) de que cada punto de datos observado pertenezca cada una de las componentes latentes (o de que las variables latentes tomen ciertos valores).Esencialmente, se est√° haciendo una ‚Äúsuposici√≥n‚Äù sobre los valores de las variables latentes bas√°ndose en los par√°metros actuales del modelo y los datos observados.Paso M (Maximization Step - Paso de Maximizaci√≥n):\nEn este paso, utilizando las ‚Äúresponsabilidades‚Äù calculadas en el Paso E (trat√°ndolas como si fueran observaciones completas), se re-estiman los par√°metros del modelo para maximizar la verosimilitud esperada.\nEsto es t√≠picamente un problema de optimizaci√≥n m√°s simple que el problema original de m√°xima verosimilitud con datos incompletos. Se ajustan los par√°metros (ej., medias, varianzas, pesos de mezcla) para que el modelo se ajuste mejor los datos, considerando las asignaciones ‚Äúblandas‚Äù las variables latentes.\nEn este paso, utilizando las ‚Äúresponsabilidades‚Äù calculadas en el Paso E (trat√°ndolas como si fueran observaciones completas), se re-estiman los par√°metros del modelo para maximizar la verosimilitud esperada.Esto es t√≠picamente un problema de optimizaci√≥n m√°s simple que el problema original de m√°xima verosimilitud con datos incompletos. Se ajustan los par√°metros (ej., medias, varianzas, pesos de mezcla) para que el modelo se ajuste mejor los datos, considerando las asignaciones ‚Äúblandas‚Äù las variables latentes.Los Pasos E y M se repiten iterativamente. La verosimilitud del modelo est√° garantizada para disminuir en cada iteraci√≥n, y el algoritmo converge un m√°ximo local de la funci√≥n de verosimilitud.Aplicaciones comunes:\n* Modelos de Mezcla Gaussiana (GMMs): Un uso protot√≠pico del EM para el clustering supervisado.\n* Modelos Ocultos de Markov (HMMs): Para problemas de reconocimiento de voz y bioinform√°tica.\n* Imputaci√≥n de datos faltantes: Para estimar valores faltantes en un conjunto de datos.\n* An√°lisis de componentes latentes.Aprendizaje Global vs.¬†Local:El algoritmo Expectation-Maximization (EM) es un m√©todo de aprendizaje global, pero es importante entender un matiz sobre su convergencia.Aspecto Global: EM tiene como objetivo encontrar los par√°metros de un modelo probabil√≠stico global (como un GMM completo que describe la distribuci√≥n de todo el conjunto de datos) que maximicen la verosimilitud de los datos observados. Los par√°metros que se estiman (medias, covarianzas, pesos de mezcla en un GMM) son v√°lidos para todo el espacio de caracter√≠sticas. El algoritmo itera sobre todo el conjunto de datos en cada paso E y M para actualizar estos par√°metros globales. La soluci√≥n que busca EM es una representaci√≥n unificada y global de las distribuciones subyacentes de los datos.Aspecto Global: EM tiene como objetivo encontrar los par√°metros de un modelo probabil√≠stico global (como un GMM completo que describe la distribuci√≥n de todo el conjunto de datos) que maximicen la verosimilitud de los datos observados. Los par√°metros que se estiman (medias, covarianzas, pesos de mezcla en un GMM) son v√°lidos para todo el espacio de caracter√≠sticas. El algoritmo itera sobre todo el conjunto de datos en cada paso E y M para actualizar estos par√°metros globales. La soluci√≥n que busca EM es una representaci√≥n unificada y global de las distribuciones subyacentes de los datos.Convergencia M√°ximos Locales: Aunque EM busca una soluci√≥n global, una limitaci√≥n cr√≠tica es que solo est√° garantizado para converger un m√°ximo local de la funci√≥n de verosimilitud, necesariamente al m√°ximo global. Esto significa que el resultado final puede depender de la inicializaci√≥n de los par√°metros del modelo. Si la funci√≥n de verosimilitud tiene m√∫ltiples ‚Äúpicos‚Äù (m√°ximos locales), EM puede quedar ‚Äúatrapado‚Äù en uno de ellos. Para mitigar esto, es una pr√°ctica com√∫n ejecutar EM varias veces con diferentes inicializaciones aleatorias y seleccionar el resultado con la verosimilitud m√°s alta.Convergencia M√°ximos Locales: Aunque EM busca una soluci√≥n global, una limitaci√≥n cr√≠tica es que solo est√° garantizado para converger un m√°ximo local de la funci√≥n de verosimilitud, necesariamente al m√°ximo global. Esto significa que el resultado final puede depender de la inicializaci√≥n de los par√°metros del modelo. Si la funci√≥n de verosimilitud tiene m√∫ltiples ‚Äúpicos‚Äù (m√°ximos locales), EM puede quedar ‚Äúatrapado‚Äù en uno de ellos. Para mitigar esto, es una pr√°ctica com√∫n ejecutar EM varias veces con diferentes inicializaciones aleatorias y seleccionar el resultado con la verosimilitud m√°s alta.Por lo tanto, mientras que el objetivo de EM es aprender un modelo global que abarque todo el espacio de datos, su m√©todo iterativo de optimizaci√≥n lo hace susceptible encontrar √≥ptimos locales en la funci√≥n de verosimilitud. La forma en que un modelo probabil√≠stico como un GMM puede modelar relaciones lineales en los datos es que, al combinar m√∫ltiples distribuciones gaussianas (lineales), el modelo resultante puede capturar formas y densidades complejas y lineales en el espacio de caracter√≠sticas. EM es el algoritmo que permite aprender estos componentes subyacentes.","code":""},{"path":"clustering-aprendizaje-no-supervisado.html","id":"hierarchical-clustering-hclust","chapter":"üìè 9. Clustering (Aprendizaje No Supervisado)","heading":"Hierarchical Clustering (hclust)","text":"El Agrupamiento Jer√°rquico (Hierarchical Clustering), menudo abreviado como hclust, es un m√©todo de agrupamiento (clustering) supervisado que construye una jerarqu√≠a de clusters en lugar de una partici√≥n plana de los datos (como k-Means). El resultado de un agrupamiento jer√°rquico se visualiza com√∫nmente como un dendrograma, un diagrama en forma de √°rbol que muestra la secuencia de fusiones o divisiones de los clusters.Existen dos tipos principales de agrupamiento jer√°rquico:Agrupamiento Aglomerativo (‚ÄúBottom-‚Äù): Es el tipo m√°s com√∫n.\nComienza tratando cada punto de datos como un cluster individual.\nEn cada paso, fusiona los dos clusters m√°s cercanos en un nuevo cluster.\nEste proceso contin√∫a hasta que todos los puntos de datos pertenecen un √∫nico cluster grande.\nLa ‚Äúcercan√≠a‚Äù entre clusters se define por una m√©trica de enlace (linkage). Las m√©tricas de enlace comunes incluyen:\nEnlace √önico (Single Linkage): Distancia m√≠nima entre dos puntos en diferentes clusters. Tiende formar clusters ‚Äúlargos‚Äù y ‚Äúdelgados‚Äù.\nEnlace Completo (Complete Linkage): Distancia m√°xima entre dos puntos en diferentes clusters. Tiende formar clusters compactos.\nEnlace Promedio (Average Linkage): Distancia promedio entre todos los pares de puntos en diferentes clusters.\nM√©todo de Ward: Minimiza la varianza total dentro de los clusters despu√©s de la fusi√≥n. Tiende formar clusters compactos de tama√±o similar.\n\nComienza tratando cada punto de datos como un cluster individual.En cada paso, fusiona los dos clusters m√°s cercanos en un nuevo cluster.Este proceso contin√∫a hasta que todos los puntos de datos pertenecen un √∫nico cluster grande.La ‚Äúcercan√≠a‚Äù entre clusters se define por una m√©trica de enlace (linkage). Las m√©tricas de enlace comunes incluyen:\nEnlace √önico (Single Linkage): Distancia m√≠nima entre dos puntos en diferentes clusters. Tiende formar clusters ‚Äúlargos‚Äù y ‚Äúdelgados‚Äù.\nEnlace Completo (Complete Linkage): Distancia m√°xima entre dos puntos en diferentes clusters. Tiende formar clusters compactos.\nEnlace Promedio (Average Linkage): Distancia promedio entre todos los pares de puntos en diferentes clusters.\nM√©todo de Ward: Minimiza la varianza total dentro de los clusters despu√©s de la fusi√≥n. Tiende formar clusters compactos de tama√±o similar.\nEnlace √önico (Single Linkage): Distancia m√≠nima entre dos puntos en diferentes clusters. Tiende formar clusters ‚Äúlargos‚Äù y ‚Äúdelgados‚Äù.Enlace Completo (Complete Linkage): Distancia m√°xima entre dos puntos en diferentes clusters. Tiende formar clusters compactos.Enlace Promedio (Average Linkage): Distancia promedio entre todos los pares de puntos en diferentes clusters.M√©todo de Ward: Minimiza la varianza total dentro de los clusters despu√©s de la fusi√≥n. Tiende formar clusters compactos de tama√±o similar.Agrupamiento Divisivo (‚ÄúTop-‚Äù):\nComienza con todos los puntos en un solo cluster grande.\nEn cada paso, divide el cluster actual en dos sub-clusters m√°s peque√±os.\nEste proceso contin√∫a hasta que cada punto de datos est√° en su propio cluster individual.\nEs menos com√∫n en la pr√°ctica debido su mayor complejidad computacional.\nComienza con todos los puntos en un solo cluster grande.En cada paso, divide el cluster actual en dos sub-clusters m√°s peque√±os.Este proceso contin√∫a hasta que cada punto de datos est√° en su propio cluster individual.Es menos com√∫n en la pr√°ctica debido su mayor complejidad computacional.La principal ventaja de hclust es que requiere especificar el n√∫mero de clusters de antemano; en cambio, el n√∫mero de clusters se puede determinar inspeccionando el dendrograma y ‚Äúcort√°ndolo‚Äù una altura apropiada. Tambi√©n es muy bueno para revelar la estructura anidada de los datos.Aprendizaje Global vs.¬†Local:El Agrupamiento Jer√°rquico (hclust) es un algoritmo que se puede clasificar como de aprendizaje local en su construcci√≥n incremental, pero que al final revela una estructura global de los datos.Aspecto Local (Proceso de Fusi√≥n/Divisi√≥n): En cada paso del agrupamiento aglomerativo, la decisi√≥n de qu√© clusters fusionar se basa exclusivamente en la distancia (o similitud) entre los clusters m√°s cercanos en ese momento. Esta es una decisi√≥n puramente local, ya que solo se consideran los pares de clusters m√°s pr√≥ximos. El algoritmo construye la jerarqu√≠a fusionando iterativamente los vecinos m√°s cercanos, lo que le permite adaptarse la forma y densidad local de los datos. Las fronteras de los cl√∫steres est√°n predefinidas por un modelo global; en cambio, emergen de las relaciones de proximidad locales. Esto permite hclust descubrir clusters de formas arbitrarias y relaciones lineales que podr√≠an ser detectadas por m√©todos que asumen formas espec√≠ficas de clusters (como k-Means con suposiciones esf√©ricas).Aspecto Local (Proceso de Fusi√≥n/Divisi√≥n): En cada paso del agrupamiento aglomerativo, la decisi√≥n de qu√© clusters fusionar se basa exclusivamente en la distancia (o similitud) entre los clusters m√°s cercanos en ese momento. Esta es una decisi√≥n puramente local, ya que solo se consideran los pares de clusters m√°s pr√≥ximos. El algoritmo construye la jerarqu√≠a fusionando iterativamente los vecinos m√°s cercanos, lo que le permite adaptarse la forma y densidad local de los datos. Las fronteras de los cl√∫steres est√°n predefinidas por un modelo global; en cambio, emergen de las relaciones de proximidad locales. Esto permite hclust descubrir clusters de formas arbitrarias y relaciones lineales que podr√≠an ser detectadas por m√©todos que asumen formas espec√≠ficas de clusters (como k-Means con suposiciones esf√©ricas).Aspecto Global (Dendrograma): Aunque las decisiones de fusi√≥n son locales, el resultado final (el dendrograma) es una representaci√≥n jer√°rquica global de las relaciones de todos los puntos de datos. Proporciona una visi√≥n completa de c√≥mo todos los puntos se agrupan en diferentes niveles de granularidad, desde clusters individuales hasta un solo cluster grande. Esta estructura global revela patrones de anidamiento y relaciones diferentes escalas.Aspecto Global (Dendrograma): Aunque las decisiones de fusi√≥n son locales, el resultado final (el dendrograma) es una representaci√≥n jer√°rquica global de las relaciones de todos los puntos de datos. Proporciona una visi√≥n completa de c√≥mo todos los puntos se agrupan en diferentes niveles de granularidad, desde clusters individuales hasta un solo cluster grande. Esta estructura global revela patrones de anidamiento y relaciones diferentes escalas.","code":""},{"path":"clustering-aprendizaje-no-supervisado.html","id":"k-means","chapter":"üìè 9. Clustering (Aprendizaje No Supervisado)","heading":"k-Means","text":"k-Means es uno de los algoritmos de agrupamiento (clustering) supervisado m√°s populares y ampliamente utilizados. Su objetivo es particionar un conjunto de \\(n\\) observaciones en \\(k\\) grupos o ‚Äúclusters‚Äù, donde cada observaci√≥n pertenece al cluster cuyo centroide (media) es el m√°s cercano.El algoritmo k-Means opera de la siguiente manera:Inicializaci√≥n:\nSe elige un n√∫mero predefinido de clusters, \\(k\\). Este es un hiperpar√°metro que debe ser especificado por el usuario.\nSe inicializan \\(k\\) centroides (puntos centrales de los clusters). Esto se puede hacer de forma aleatoria seleccionando \\(k\\) puntos de datos al azar como centroides iniciales, o utilizando m√©todos m√°s sofisticados como k-Means++.\nSe elige un n√∫mero predefinido de clusters, \\(k\\). Este es un hiperpar√°metro que debe ser especificado por el usuario.Se inicializan \\(k\\) centroides (puntos centrales de los clusters). Esto se puede hacer de forma aleatoria seleccionando \\(k\\) puntos de datos al azar como centroides iniciales, o utilizando m√©todos m√°s sofisticados como k-Means++.Paso de Asignaci√≥n (Expectation / E-step):\nPara cada punto de datos en el conjunto, se calcula su distancia (com√∫nmente euclidiana) cada uno de los \\(k\\) centroides.\nCada punto de datos se asigna al cluster cuyo centroide es el m√°s cercano.\nPara cada punto de datos en el conjunto, se calcula su distancia (com√∫nmente euclidiana) cada uno de los \\(k\\) centroides.Cada punto de datos se asigna al cluster cuyo centroide es el m√°s cercano.Paso de Actualizaci√≥n (Maximization / M-step):\nPara cada uno de los \\(k\\) clusters, se recalcula la posici√≥n del centroide como la media (promedio) de todos los puntos de datos que han sido asignados ese cluster.\nPara cada uno de los \\(k\\) clusters, se recalcula la posici√≥n del centroide como la media (promedio) de todos los puntos de datos que han sido asignados ese cluster.Iteraci√≥n:\nLos pasos de Asignaci√≥n y Actualizaci√≥n se repiten iterativamente.\nEl algoritmo converge cuando las asignaciones de los puntos los clusters ya cambian, o cuando las posiciones de los centroides cambian significativamente entre iteraciones.\nLos pasos de Asignaci√≥n y Actualizaci√≥n se repiten iterativamente.El algoritmo converge cuando las asignaciones de los puntos los clusters ya cambian, o cuando las posiciones de los centroides cambian significativamente entre iteraciones.El objetivo del algoritmo es minimizar la suma de los cuadrados de las distancias de cada punto su centroide asignado (tambi√©n conocida como la inercia del cluster o la suma de cuadrados dentro del cluster - WCSS).Ventajas: Es simple de implementar, computacionalmente eficiente y escalable para grandes conjuntos de datos.\nLimitaciones: Requiere que el n√∫mero de clusters \\(k\\) sea especificado de antemano, es sensible la inicializaci√≥n de los centroides, y tiende formar clusters esf√©ricos de tama√±o similar, lo que puede ser una desventaja si los clusters tienen formas arbitrarias o densidades muy diferentes. Tambi√©n es sensible los outliers.Aprendizaje Global vs.¬†Local:k-Means es un modelo de aprendizaje global.Aspecto Global: k-Means busca una partici√≥n global de todo el conjunto de datos en \\(k\\) clusters. El objetivo de la optimizaci√≥n (minimizar la suma de los cuadrados de las distancias los centroides) se calcula sobre todos los puntos de datos y todos los clusters simult√°neamente. Los centroides, una vez convergidos, representan los ‚Äúcentros‚Äù de los clusters en el espacio de caracter√≠sticas, y estos se utilizan para asignar cualquier nuevo punto su cluster correspondiente. La soluci√≥n final es una asignaci√≥n de cada punto un cluster que se aplica nivel global.Aspecto Global: k-Means busca una partici√≥n global de todo el conjunto de datos en \\(k\\) clusters. El objetivo de la optimizaci√≥n (minimizar la suma de los cuadrados de las distancias los centroides) se calcula sobre todos los puntos de datos y todos los clusters simult√°neamente. Los centroides, una vez convergidos, representan los ‚Äúcentros‚Äù de los clusters en el espacio de caracter√≠sticas, y estos se utilizan para asignar cualquier nuevo punto su cluster correspondiente. La soluci√≥n final es una asignaci√≥n de cada punto un cluster que se aplica nivel global.Asignaciones Locales dentro de una Optimizaci√≥n Global: Aunque en cada iteraci√≥n los puntos se asignan su centroide ‚Äúlocal‚Äù m√°s cercano, esta asignaci√≥n es parte de un proceso iterativo que busca optimizar un criterio global (la inercia total del cluster). Los centroides mismos son influenciados por todos los puntos asignados su cluster, y la reubicaci√≥n de los centroides afecta las asignaciones de todos los puntos en la siguiente iteraci√≥n. El resultado son fronteras de decisi√≥n lineales (hiperplanos) entre los clusters (cuyas combinaciones pueden formar pol√≠gonos de Voronoi), que son una caracter√≠stica de un modelo global que divide el espacio. Si los datos se distribuyen linealmente y los clusters tienen formas esf√©ricas o densidades muy diferentes, k-Means puede tener dificultades para descubrirlos, precisamente por su naturaleza global de optimizaci√≥n de la distancia euclidiana un centroide.Asignaciones Locales dentro de una Optimizaci√≥n Global: Aunque en cada iteraci√≥n los puntos se asignan su centroide ‚Äúlocal‚Äù m√°s cercano, esta asignaci√≥n es parte de un proceso iterativo que busca optimizar un criterio global (la inercia total del cluster). Los centroides mismos son influenciados por todos los puntos asignados su cluster, y la reubicaci√≥n de los centroides afecta las asignaciones de todos los puntos en la siguiente iteraci√≥n. El resultado son fronteras de decisi√≥n lineales (hiperplanos) entre los clusters (cuyas combinaciones pueden formar pol√≠gonos de Voronoi), que son una caracter√≠stica de un modelo global que divide el espacio. Si los datos se distribuyen linealmente y los clusters tienen formas esf√©ricas o densidades muy diferentes, k-Means puede tener dificultades para descubrirlos, precisamente por su naturaleza global de optimizaci√≥n de la distancia euclidiana un centroide.","code":""},{"path":"clustering-aprendizaje-no-supervisado.html","id":"k-medians","chapter":"üìè 9. Clustering (Aprendizaje No Supervisado)","heading":"k-Medians","text":"k-Medians es un algoritmo de agrupamiento (clustering) supervisado que es una variante de k-Means. Al igual que k-Means, su objetivo es particionar un conjunto de \\(n\\) observaciones en \\(k\\) grupos o ‚Äúclusters‚Äù. La principal diferencia radica en c√≥mo se calcula el ‚Äúcentro‚Äù de cada cluster y la m√©trica de distancia utilizada en su funci√≥n de costo.Mientras que k-Means utiliza la media (mean) de los puntos de un cluster como su centroide y minimiza la suma de los cuadrados de las distancias euclidianas (norma L2), k-Medians utiliza la mediana (median) de los puntos de un cluster como su ‚Äúcentro‚Äù y minimiza la suma de las distancias absolutas (norma L1 o distancia de Manhattan).El algoritmo k-Medians opera de manera muy similar k-Means:Inicializaci√≥n:\nSe elige un n√∫mero predefinido de clusters, \\(k\\).\nSe inicializan \\(k\\) medianas (puntos centrales de los clusters), menudo de forma aleatoria.\nSe elige un n√∫mero predefinido de clusters, \\(k\\).Se inicializan \\(k\\) medianas (puntos centrales de los clusters), menudo de forma aleatoria.Paso de Asignaci√≥n:\nPara cada punto de datos en el conjunto, se calcula su distancia de Manhattan (L1) cada una de las \\(k\\) medianas.\nCada punto de datos se asigna al cluster cuya mediana es la m√°s cercana.\nPara cada punto de datos en el conjunto, se calcula su distancia de Manhattan (L1) cada una de las \\(k\\) medianas.Cada punto de datos se asigna al cluster cuya mediana es la m√°s cercana.Paso de Actualizaci√≥n:\nPara cada uno de los \\(k\\) clusters, se recalcula la posici√≥n de la mediana como la mediana multivariada (componente por componente) de todos los puntos de datos que han sido asignados ese cluster.\nPara cada uno de los \\(k\\) clusters, se recalcula la posici√≥n de la mediana como la mediana multivariada (componente por componente) de todos los puntos de datos que han sido asignados ese cluster.Iteraci√≥n:\nLos pasos de Asignaci√≥n y Actualizaci√≥n se repiten iterativamente.\nEl algoritmo converge cuando las asignaciones de los puntos los clusters ya cambian, o cuando las posiciones de las medianas cambian significativamente.\nLos pasos de Asignaci√≥n y Actualizaci√≥n se repiten iterativamente.El algoritmo converge cuando las asignaciones de los puntos los clusters ya cambian, o cuando las posiciones de las medianas cambian significativamente.Ventajas clave de k-Medians sobre k-Means:Robustez Outliers: Al usar la mediana en lugar de la media, k-Medians es significativamente m√°s robusto los valores at√≠picos (outliers). Los outliers influyen fuertemente en la media (tirando de ella), pero tienen un impacto mucho menor en la mediana.M√©trica de Distancia: La distancia L1 es veces m√°s apropiada que la L2 cuando las diferencias entre las caracter√≠sticas son m√°s importantes que sus valores al cuadrado, o cuando los datos son necesariamente continuos o gaussianos.Limitaciones:\n* Requiere que el n√∫mero de clusters \\(k\\) sea especificado de antemano.\n* La mediana multivariada puede ser m√°s compleja de calcular que la media.\n* Puede ser m√°s lento que k-Means en algunos escenarios.Aprendizaje Global vs.¬†Local:Al igual que k-Means, k-Medians es un modelo de aprendizaje global.Aspecto Global: k-Medians busca una partici√≥n global de todo el conjunto de datos en \\(k\\) clusters. El objetivo de la optimizaci√≥n (minimizar la suma de las distancias L1 las medianas) se calcula sobre todos los puntos de datos y todos los clusters simult√°neamente. Las medianas, una vez convergidas, representan los ‚Äúcentros‚Äù robustos de los clusters en el espacio de caracter√≠sticas, y estos se utilizan para asignar cualquier nuevo punto su cluster correspondiente. La soluci√≥n final es una asignaci√≥n de cada punto un cluster que se aplica nivel global.Aspecto Global: k-Medians busca una partici√≥n global de todo el conjunto de datos en \\(k\\) clusters. El objetivo de la optimizaci√≥n (minimizar la suma de las distancias L1 las medianas) se calcula sobre todos los puntos de datos y todos los clusters simult√°neamente. Las medianas, una vez convergidas, representan los ‚Äúcentros‚Äù robustos de los clusters en el espacio de caracter√≠sticas, y estos se utilizan para asignar cualquier nuevo punto su cluster correspondiente. La soluci√≥n final es una asignaci√≥n de cada punto un cluster que se aplica nivel global.Asignaciones Locales dentro de una Optimizaci√≥n Global: Si bien en cada iteraci√≥n los puntos se asignan su mediana ‚Äúlocal‚Äù m√°s cercana, esta asignaci√≥n es parte de un proceso iterativo que busca optimizar un criterio global (la suma total de distancias L1). Las medianas mismas son influenciadas por todos los puntos asignados su cluster, y la reubicaci√≥n de las medianas afecta las asignaciones de todos los puntos en la siguiente iteraci√≥n. El resultado son fronteras de decisi√≥n lineales (debido al uso de la distancia L1, similar las fronteras de Voronoi), que son una caracter√≠stica de un modelo global que divide el espacio. Aunque es m√°s robusto outliers, k-Medians todav√≠a tiende encontrar clusters que son m√°s o menos ‚Äúesf√©ricos‚Äù o convexos en la m√©trica L1, y puede tener dificultades con clusters de formas muy arbitrarias o lineales.Asignaciones Locales dentro de una Optimizaci√≥n Global: Si bien en cada iteraci√≥n los puntos se asignan su mediana ‚Äúlocal‚Äù m√°s cercana, esta asignaci√≥n es parte de un proceso iterativo que busca optimizar un criterio global (la suma total de distancias L1). Las medianas mismas son influenciadas por todos los puntos asignados su cluster, y la reubicaci√≥n de las medianas afecta las asignaciones de todos los puntos en la siguiente iteraci√≥n. El resultado son fronteras de decisi√≥n lineales (debido al uso de la distancia L1, similar las fronteras de Voronoi), que son una caracter√≠stica de un modelo global que divide el espacio. Aunque es m√°s robusto outliers, k-Medians todav√≠a tiende encontrar clusters que son m√°s o menos ‚Äúesf√©ricos‚Äù o convexos en la m√©trica L1, y puede tener dificultades con clusters de formas muy arbitrarias o lineales.","code":""},{"path":"sistemas-basados-en-reglas.html","id":"sistemas-basados-en-reglas","chapter":"üìê 10. Sistemas Basados en Reglas","heading":"üìê 10. Sistemas Basados en Reglas","text":"Ejemplos: RuleFit, √Årboles de Decisi√≥n con reglas, l√≥gica difusa.Uso: Estos sistemas son ideales cuando la interpretabilidad es absolutamente crucial, como en decisiones legales o m√©dicas donde entender el ‚Äúporqu√©‚Äù es tan importante como el ‚Äúqu√©‚Äù. Tambi√©n son perfectos para incorporar conocimiento experto humano directamente en el modelo.Ventajas: Son notablemente f√°ciles de entender y auditar, lo que los hace transparentes y confiables en entornos regulados.Limitaciones: Su principal desventaja es que suelen ser tan precisos como otros m√©todos m√°s complejos cuando se enfrentan datos muy intrincados o patrones lineales.","code":""},{"path":"sistemas-basados-en-reglas.html","id":"cubist","chapter":"üìê 10. Sistemas Basados en Reglas","heading":"Cubist","text":"Cubist es un algoritmo de Machine Learning desarrollado por RuleQuest Research (autores de C4.5 y See5/C5.0), principalmente para tareas de regresi√≥n. Es una extensi√≥n de los modelos de √°rboles de decisi√≥n que combina la simplicidad de las reglas con la precisi√≥n de los modelos locales, lo que lo hace muy potente para datos complejos con muchas caracter√≠sticas.En esencia, Cubist construye un modelo de reglas con un modelo lineal adjunto cada regla. Opera en dos fases principales:Construcci√≥n del √Årbol de Reglas:\nSimilar un √°rbol de decisi√≥n, Cubist construye una estructura de √°rbol dividiendo los datos en subconjuntos basados en los valores de las caracter√≠sticas.\nSin embargo, en lugar de hojas que contienen un valor constante (como en los √°rboles de regresi√≥n tradicionales), cada hoja de este √°rbol se transforma en un conjunto de reglas.\ncada regla se le asocia un modelo lineal multivariado local (o un ‚Äúmodelo de comit√©‚Äù de reglas, donde varias reglas contribuyen la predicci√≥n). Este modelo lineal se entrena solo con los datos que satisfacen las condiciones de esa regla.\nSimilar un √°rbol de decisi√≥n, Cubist construye una estructura de √°rbol dividiendo los datos en subconjuntos basados en los valores de las caracter√≠sticas.Sin embargo, en lugar de hojas que contienen un valor constante (como en los √°rboles de regresi√≥n tradicionales), cada hoja de este √°rbol se transforma en un conjunto de reglas.cada regla se le asocia un modelo lineal multivariado local (o un ‚Äúmodelo de comit√©‚Äù de reglas, donde varias reglas contribuyen la predicci√≥n). Este modelo lineal se entrena solo con los datos que satisfacen las condiciones de esa regla.Ajuste del Modelo de Reglas y Predicci√≥n:\nPara cada nueva instancia de predicci√≥n, Cubist identifica las reglas que se aplican esa instancia.\nLa predicci√≥n final se calcula combinando las predicciones de los modelos lineales de las reglas que se aplican, y luego se ajusta un poco esa predicci√≥n mediante un ‚Äúcomit√©‚Äù de vecinos (ajustes locales adicionales basados en ejemplos similares), si est√° configurado para ello. Esta etapa de ajuste lo hace a√∫n m√°s robusto.\nPara cada nueva instancia de predicci√≥n, Cubist identifica las reglas que se aplican esa instancia.La predicci√≥n final se calcula combinando las predicciones de los modelos lineales de las reglas que se aplican, y luego se ajusta un poco esa predicci√≥n mediante un ‚Äúcomit√©‚Äù de vecinos (ajustes locales adicionales basados en ejemplos similares), si est√° configurado para ello. Esta etapa de ajuste lo hace a√∫n m√°s robusto.Cubist es valorado por su capacidad para manejar relaciones complejas y lineales en los datos. Proporciona un modelo que es m√°s interpretable que una ‚Äúcaja negra‚Äù (como una red neuronal profunda) debido su base en reglas, pero mucho m√°s preciso que los modelos lineales o los √°rboles de regresi√≥n simples, gracias sus modelos lineales locales y ajustes.Aprendizaje Global vs.¬†Local:Cubist es un algoritmo que combina de manera muy efectiva aspectos de aprendizaje global y local.Aspecto Global (Estructura de Reglas): La fase de construcci√≥n del √°rbol y la derivaci√≥n de las reglas crean una estructura global que divide el espacio de caracter√≠sticas. Este conjunto de reglas abarca todo el dominio de los datos y determina qu√© modelo local se aplicar√° una instancia. Es una forma de particionar el espacio de caracter√≠sticas de manera jer√°rquica para establecer un marco de predicci√≥n general.Aspecto Global (Estructura de Reglas): La fase de construcci√≥n del √°rbol y la derivaci√≥n de las reglas crean una estructura global que divide el espacio de caracter√≠sticas. Este conjunto de reglas abarca todo el dominio de los datos y determina qu√© modelo local se aplicar√° una instancia. Es una forma de particionar el espacio de caracter√≠sticas de manera jer√°rquica para establecer un marco de predicci√≥n general.Aspecto Local (Modelos Lineales y Ajustes): Aqu√≠ es donde Cubist brilla en su capacidad de aprendizaje local:\nModelos Lineales Locales: Cada regla tiene asociado un modelo lineal que se entrena solo con los datos que caen dentro de esa regla. Esto permite Cubist capturar relaciones locales y lineales de manera precisa. En lugar de una √∫nica relaci√≥n lineal global, el modelo se adapta las particularidades de diferentes subregiones de los datos.\nAjuste Basado en Vecinos: Si se activa la opci√≥n de ‚Äúcomit√©‚Äù o el ajuste basado en vecinos (conocido como committees o neighbors), el modelo refina a√∫n m√°s su predicci√≥n incorporando la informaci√≥n de los ejemplos de entrenamiento m√°s cercanos al punto de consulta. Esto es una forma de ‚Äúregresi√≥n ponderada localmente‚Äù, donde la predicci√≥n final se ajusta en funci√≥n de los patrones observados en el vecindario inmediato del punto de inter√©s.\nAspecto Local (Modelos Lineales y Ajustes): Aqu√≠ es donde Cubist brilla en su capacidad de aprendizaje local:Modelos Lineales Locales: Cada regla tiene asociado un modelo lineal que se entrena solo con los datos que caen dentro de esa regla. Esto permite Cubist capturar relaciones locales y lineales de manera precisa. En lugar de una √∫nica relaci√≥n lineal global, el modelo se adapta las particularidades de diferentes subregiones de los datos.Ajuste Basado en Vecinos: Si se activa la opci√≥n de ‚Äúcomit√©‚Äù o el ajuste basado en vecinos (conocido como committees o neighbors), el modelo refina a√∫n m√°s su predicci√≥n incorporando la informaci√≥n de los ejemplos de entrenamiento m√°s cercanos al punto de consulta. Esto es una forma de ‚Äúregresi√≥n ponderada localmente‚Äù, donde la predicci√≥n final se ajusta en funci√≥n de los patrones observados en el vecindario inmediato del punto de inter√©s.","code":""},{"path":"sistemas-basados-en-reglas.html","id":"decision-rules","chapter":"üìê 10. Sistemas Basados en Reglas","heading":"Decision Rules","text":"Las Reglas de Decisi√≥n son un algoritmo de Machine Learning en s√≠ mismas, sino una forma de representar un modelo predictivo que es altamente interpretable y f√°cil de entender. Son una de las formas m√°s intuitivas de expresar el conocimiento extra√≠do de los datos. Una regla de decisi√≥n t√≠picamente toma la forma de una declaraci√≥n ‚ÄúSI-ENTONCES‚Äù (-), donde la parte ‚ÄúSI‚Äù (antecedente) describe las condiciones que deben cumplirse y la parte ‚ÄúENTONCES‚Äù (consecuente) especifica la predicci√≥n o la acci√≥n tomar.Estructura de una Regla de Decisi√≥n:Una regla de decisi√≥n b√°sica tiene la siguiente forma:SI condici√≥n 1 Y condici√≥n 2 Y ‚Ä¶ Y condici√≥n N ENTONCES predicci√≥n / clase / valorEjemplos:Para Clasificaci√≥n:\nSI Edad > 30 Y Ingreso < 50,000 ENTONCES Clase: Riesgo Bajo\nSI Clima = Soleado Y Humedad > 70% ENTONCES Acci√≥n: Jugar Tenis\nSI Edad > 30 Y Ingreso < 50,000 ENTONCES Clase: Riesgo BajoSI Clima = Soleado Y Humedad > 70% ENTONCES Acci√≥n: Jugar TenisPara Regresi√≥n:\nSI Tama√±o_Casa > 150 m¬≤ Y Num_Habitaciones = 3 ENTONCES Precio_Estimado: $300,000\nSI Tama√±o_Casa > 150 m¬≤ Y Num_Habitaciones = 3 ENTONCES Precio_Estimado: $300,000Caracter√≠sticas Clave:Interpretabilidad: Son inherentemente f√°ciles de entender por los humanos, incluso por aquellos sin conocimientos t√©cnicos profundos.Modularidad: Un modelo completo puede estar compuesto por un conjunto de reglas. Cada regla es independiente y f√°cil de examinar.Linealidad: Aunque cada regla es una declaraci√≥n l√≥gica simple, un conjunto de reglas puede modelar relaciones lineales complejas en los datos, ya que cada regla cubre una regi√≥n diferente del espacio de caracter√≠sticas.Selecci√≥n de Caracter√≠sticas Impl√≠cita: Al construir reglas, solo las caracter√≠sticas relevantes para la condici√≥n se incluyen, lo que realiza una selecci√≥n impl√≠cita de caracter√≠sticas.Robustez: menudo son bastante robustas los outliers y los datos ruidosos si las reglas se derivan y podan correctamente.Algoritmos que Generan Reglas de Decisi√≥n:Si bien las reglas de decisi√≥n son la forma de representaci√≥n, varios algoritmos de Machine Learning se especializan en aprender estas reglas partir de los datos:√Årboles de Decisi√≥n: Cada ruta desde la ra√≠z hasta una hoja en un √°rbol de decisi√≥n se puede traducir directamente en una regla de decisi√≥n.Algoritmos Basados en Reglas:\nOneR: Genera una √∫nica regla basada en el atributo m√°s predictivo.\nRIPPER: Produce conjuntos de reglas optimizados para la clasificaci√≥n, con √©nfasis en la poda y la simplicidad.\nRuleFit: Combina reglas extra√≠das de ensamblajes de √°rboles con caracter√≠sticas originales en un modelo lineal regularizado.\nOneR: Genera una √∫nica regla basada en el atributo m√°s predictivo.RIPPER: Produce conjuntos de reglas optimizados para la clasificaci√≥n, con √©nfasis en la poda y la simplicidad.RuleFit: Combina reglas extra√≠das de ensamblajes de √°rboles con caracter√≠sticas originales en un modelo lineal regularizado.Sistemas de L√≥gica Difusa: Utilizan reglas difusas para manejar la incertidumbre y la imprecisi√≥n.Aprendizaje Global vs.¬†Local:Los modelos basados en Reglas de Decisi√≥n combinan de manera muy efectiva aspectos de aprendizaje global y local.Aspecto Local (Cada Regla Individual):\nCada regla de decisi√≥n es intr√≠nsecamente local. Define una regi√≥n espec√≠fica (un subespacio, menudo un hiperrect√°ngulo) en el espacio de caracter√≠sticas. Dentro de esta regi√≥n, la regla hace una predicci√≥n particular. Por ejemplo, la regla ‚ÄúSI Edad > 30 Y Ingreso < 50,000‚Äù solo se aplica un subconjunto espec√≠fico de instancias.\nLa naturaleza ‚Äúlocal‚Äù de cada regla permite al modelo adaptarse relaciones lineales y complejas. Diferentes reglas pueden activarse en distintas partes del espacio de datos, capturando patrones que var√≠an significativamente de una regi√≥n otra, similar una ‚Äúregresi√≥n (o clasificaci√≥n) ponderada localmente‚Äù donde cada regla representa un modelo simple para su regi√≥n.\nCada regla de decisi√≥n es intr√≠nsecamente local. Define una regi√≥n espec√≠fica (un subespacio, menudo un hiperrect√°ngulo) en el espacio de caracter√≠sticas. Dentro de esta regi√≥n, la regla hace una predicci√≥n particular. Por ejemplo, la regla ‚ÄúSI Edad > 30 Y Ingreso < 50,000‚Äù solo se aplica un subconjunto espec√≠fico de instancias.La naturaleza ‚Äúlocal‚Äù de cada regla permite al modelo adaptarse relaciones lineales y complejas. Diferentes reglas pueden activarse en distintas partes del espacio de datos, capturando patrones que var√≠an significativamente de una regi√≥n otra, similar una ‚Äúregresi√≥n (o clasificaci√≥n) ponderada localmente‚Äù donde cada regla representa un modelo simple para su regi√≥n.Aspecto Global (El Conjunto de Reglas):\nAunque las reglas individuales son locales, el conjunto completo de reglas que conforma el modelo se aplica para cubrir todo el espacio de caracter√≠sticas relevante. Este conjunto de reglas forma un modelo predictivo global que puede clasificar o predecir un valor para cualquier nueva instancia.\nLos algoritmos que generan estos conjuntos de reglas (como RIPPER) menudo optimizan la colecci√≥n de reglas para un rendimiento global, buscando un equilibrio entre la precisi√≥n y la complejidad del modelo en su conjunto.\nAunque las reglas individuales son locales, el conjunto completo de reglas que conforma el modelo se aplica para cubrir todo el espacio de caracter√≠sticas relevante. Este conjunto de reglas forma un modelo predictivo global que puede clasificar o predecir un valor para cualquier nueva instancia.Los algoritmos que generan estos conjuntos de reglas (como RIPPER) menudo optimizan la colecci√≥n de reglas para un rendimiento global, buscando un equilibrio entre la precisi√≥n y la complejidad del modelo en su conjunto.","code":""},{"path":"sistemas-basados-en-reglas.html","id":"l√≥gica-difusa-fuzzy-logic","chapter":"üìê 10. Sistemas Basados en Reglas","heading":"L√≥gica Difusa (Fuzzy Logic)","text":"La L√≥gica Difusa (Fuzzy Logic) es un algoritmo de Machine Learning en s√≠ mismo, sino un paradigma de computaci√≥n basado en la noci√≥n de ‚Äúgrado de verdad‚Äù en lugar de los valores binarios ‚Äúverdadero o falso‚Äù (1 o 0) de la l√≥gica booleana cl√°sica. Permite modelar el razonamiento humano, que menudo involucra informaci√≥n imprecisa, ambigua o vaga. Es un marco para representar y manipular el conocimiento que es inherentemente incierto o subjetivo.La idea central de la l√≥gica difusa es que un elemento puede pertenecer un conjunto en un cierto grado (entre 0 y 1), en lugar de pertenecer completamente o pertenecer en absoluto. Por ejemplo, una persona puede ser ‚Äúalta‚Äù en un grado de 0.8 y ‚Äúmediana‚Äù en un grado de 0.2, en lugar de ser estrictamente alta o estrictamente mediana.Los componentes clave de un sistema de l√≥gica difusa suelen incluir:Conjuntos Difusos (Fuzzy Sets): Definen el grado de pertenencia de un elemento una categor√≠a. Por ejemplo, un conjunto difuso para ‚Äútemperatura alta‚Äù podr√≠a tener una funci√≥n de pertenencia que asigne un valor de 0 10 grados, 0.5 20 grados, y 1 30 grados.Variables Ling√º√≠sticas: Son variables cuyos valores son palabras o oraciones del lenguaje natural (ej., ‚Äútemperatura‚Äù, cuyos valores pueden ser ‚Äúfr√≠o‚Äù, ‚Äútibio‚Äù, ‚Äúcaliente‚Äù).Funciones de Pertenencia (Membership Functions): Gr√°ficos que definen matem√°ticamente el grado de pertenencia de un elemento un conjunto difuso.Reglas Difusas (Fuzzy Rules): Reglas de tipo ‚ÄúSI-ENTONCES‚Äù que utilizan variables ling√º√≠sticas y conjuntos difusos. Por ejemplo: ‚ÄúSI la temperatura es caliente Y la humedad es alta ENTONCES la velocidad del ventilador es r√°pida‚Äù.Fuzificaci√≥n: Proceso de convertir valores de entrada n√≠tidos (crisp inputs) en grados de pertenencia conjuntos difusos.Motor de Inferencia: Aplica las reglas difusas para producir una salida difusa.Defuzificaci√≥n: Proceso de convertir la salida difusa en un valor de salida n√≠tido (crisp output) que pueda ser utilizado en el mundo real.La l√≥gica difusa es ampliamente utilizada en sistemas de control (ej., lavadoras, sistemas de frenos ABS, c√°maras de video), sistemas expertos y en el procesamiento de informaci√≥n imprecisa.Aprendizaje Global vs.¬†Local:La L√≥gica Difusa, como paradigma, tiene la capacidad de integrar aspectos de modelado global y local, dependiendo de c√≥mo se implemente y se ‚Äúentrene‚Äù (o sintonice).Aspecto Local (Granularidad de las Reglas y Conjuntos Difusos):\nLas reglas difusas operan sobre condiciones locales (ej., ‚ÄúSI la temperatura es caliente‚Äù). Cada regla cubre una porci√≥n espec√≠fica del espacio de entrada/salida. Los conjuntos difusos y sus funciones de pertenencia particionan el espacio de caracter√≠sticas en regiones ‚Äúborrosas‚Äù o traslapadas, lo que permite que el modelo se adapte las caracter√≠sticas de los datos en vecindarios espec√≠ficos. Es decir, la respuesta del sistema se construye partir de la activaci√≥n ponderada de varias reglas locales, cada una representando un comportamiento en una regi√≥n del espacio de entrada. Esto es muy similar una ‚Äúregresi√≥n ponderada localmente‚Äù, donde la contribuci√≥n de cada regla (o modelo impl√≠cito) se pondera por el grado en que la entrada actual pertenece la regi√≥n de esa regla. Esta granularidad y superposici√≥n le permiten manejar relaciones lineales y complejas al aproximarlas con una combinaci√≥n de estas contribuciones locales.\nLas reglas difusas operan sobre condiciones locales (ej., ‚ÄúSI la temperatura es caliente‚Äù). Cada regla cubre una porci√≥n espec√≠fica del espacio de entrada/salida. Los conjuntos difusos y sus funciones de pertenencia particionan el espacio de caracter√≠sticas en regiones ‚Äúborrosas‚Äù o traslapadas, lo que permite que el modelo se adapte las caracter√≠sticas de los datos en vecindarios espec√≠ficos. Es decir, la respuesta del sistema se construye partir de la activaci√≥n ponderada de varias reglas locales, cada una representando un comportamiento en una regi√≥n del espacio de entrada. Esto es muy similar una ‚Äúregresi√≥n ponderada localmente‚Äù, donde la contribuci√≥n de cada regla (o modelo impl√≠cito) se pondera por el grado en que la entrada actual pertenece la regi√≥n de esa regla. Esta granularidad y superposici√≥n le permiten manejar relaciones lineales y complejas al aproximarlas con una combinaci√≥n de estas contribuciones locales.Aspecto Global (Coherencia del Sistema y Cobertura):\nAunque las reglas son locales, un sistema de l√≥gica difusa bien dise√±ado cubre todo el espacio de entrada relevante y proporciona una respuesta global coherente. El conjunto de todas las reglas y funciones de pertenencia, junto con el motor de inferencia, forma un sistema global que puede mapear cualquier entrada una salida. La defuzificaci√≥n final produce un valor n√≠tido que es el resultado de la combinaci√≥n de todas las activaciones de las reglas.\nAunque las reglas son locales, un sistema de l√≥gica difusa bien dise√±ado cubre todo el espacio de entrada relevante y proporciona una respuesta global coherente. El conjunto de todas las reglas y funciones de pertenencia, junto con el motor de inferencia, forma un sistema global que puede mapear cualquier entrada una salida. La defuzificaci√≥n final produce un valor n√≠tido que es el resultado de la combinaci√≥n de todas las activaciones de las reglas.Aprendizaje y Sintonizaci√≥n: Cuando se combinan con t√©cnicas de Machine Learning (como redes neuronales o algoritmos gen√©ticos), los sistemas difusos pueden ‚Äúaprender‚Äù o ‚Äúsintonizar‚Äù sus funciones de pertenencia y reglas. Este proceso de aprendizaje puede optimizar el rendimiento del sistema nivel global (minimizando un error general), pero los ajustes siguen afectando las propiedades locales de las reglas y conjuntos difusos.","code":""},{"path":"sistemas-basados-en-reglas.html","id":"one-rule-oner","chapter":"üìê 10. Sistemas Basados en Reglas","heading":"One Rule (OneR)","text":"One Rule (OneR) es un algoritmo de clasificaci√≥n supervisada notable por su simplicidad y alta interpretabilidad. Fue propuesto por Robert Holte en 1993 y, pesar de su sencillez, menudo logra una precisi√≥n sorprendentemente buena en comparaci√≥n con algoritmos mucho m√°s complejos, sirviendo como una excelente l√≠nea base (benchmark) para el rendimiento del modelo.La idea central de OneR es construir un clasificador que se base en una √∫nica regla para tomar decisiones. Esta regla se deriva de un solo atributo (caracter√≠stica) del conjunto de datos que es el m√°s predictivo de la clase de salida.El funcionamiento del algoritmo OneR es el siguiente:Iterar Trav√©s de Cada Atributo: Para cada atributo en el conjunto de datos de entrenamiento (se asume que los atributos son categ√≥ricos; si son continuos, primero deben discretizarse):\nCrear una Regla para Cada Valor: Para cada valor √∫nico que puede tomar ese atributo, se construye una regla.\nEncontrar la Clase M√°s Frecuente: Para cada una de estas reglas, se cuenta cu√°ntas veces aparece cada clase de destino cuando el atributo toma ese valor. La clase que ocurre con mayor frecuencia se convierte en la predicci√≥n para esa regla.\nCalcular el Error de la Regla: Se calcula el n√∫mero de errores que comete esta regla (es decir, el n√∫mero de instancias para las cuales la clase predicha coincide con la clase real).\nCrear una Regla para Cada Valor: Para cada valor √∫nico que puede tomar ese atributo, se construye una regla.Encontrar la Clase M√°s Frecuente: Para cada una de estas reglas, se cuenta cu√°ntas veces aparece cada clase de destino cuando el atributo toma ese valor. La clase que ocurre con mayor frecuencia se convierte en la predicci√≥n para esa regla.Calcular el Error de la Regla: Se calcula el n√∫mero de errores que comete esta regla (es decir, el n√∫mero de instancias para las cuales la clase predicha coincide con la clase real).Seleccionar el Mejor Atributo: Una vez que se han generado reglas y calculado los errores para todos los atributos, OneR selecciona el atributo (y su conjunto de reglas asociadas) que tiene el menor error total. Si hay un empate entre varios atributos, se puede elegir el primero o usar un criterio secundario (como el test de chi-cuadrado).El Modelo Final: El conjunto de reglas derivado de este atributo seleccionado se convierte en el modelo final de clasificaci√≥n.Por ejemplo, si tenemos un atributo ‚ÄúClima‚Äù con valores ‚ÄúSoleado‚Äù, ‚ÄúNublado‚Äù, ‚ÄúLluvioso‚Äù y una clase ‚ÄúJugar al Golf‚Äù (S√≠/):\n* Si Clima = Soleado: La mayor√≠a juega golf (S√≠). Error: 2 (de 5)\n* Si Clima = Nublado: La mayor√≠a juega golf (S√≠). Error: 0 (de 4)\n* Si Clima = Lluvioso: La mayor√≠a juega golf (). Error: 1 (de 5)\n* Error total para ‚ÄúClima‚Äù = 2 + 0 + 1 = 3.Este proceso se repetir√≠a para otros atributos como ‚ÄúTemperatura‚Äù, ‚ÄúHumedad‚Äù, etc., y el atributo con el menor error total ser√≠a el elegido.Aprendizaje Global vs.¬†Local:One Rule (OneR) es un modelo de aprendizaje fundamentalmente global, aunque la regla que aprende implica una partici√≥n del espacio de caracter√≠sticas.Aspecto Global: OneR eval√∫a todos los atributos en su totalidad y selecciona el √∫nico atributo que es globalmente el m√°s predictivo para la tarea de clasificaci√≥n sobre todo el conjunto de datos. La regla elegida y sus condiciones se aplican uniformemente cualquier nueva instancia en el espacio de caracter√≠sticas. se construyen modelos separados o locales para diferentes regiones del espacio de caracter√≠sticas. El algoritmo busca la mejor regla √∫nica que resuma el patr√≥n m√°s fuerte en todos los datos.Aspecto Global: OneR eval√∫a todos los atributos en su totalidad y selecciona el √∫nico atributo que es globalmente el m√°s predictivo para la tarea de clasificaci√≥n sobre todo el conjunto de datos. La regla elegida y sus condiciones se aplican uniformemente cualquier nueva instancia en el espacio de caracter√≠sticas. se construyen modelos separados o locales para diferentes regiones del espacio de caracter√≠sticas. El algoritmo busca la mejor regla √∫nica que resuma el patr√≥n m√°s fuerte en todos los datos.Partici√≥n del Espacio (Reglas): Aunque el modelo es global, la ‚Äúregla‚Äù que genera s√≠ que particiona el espacio de caracter√≠sticas. Por ejemplo, si el atributo seleccionado es ‚ÄúColor‚Äù y tiene valores ‚ÄúRojo‚Äù, ‚ÄúAzul‚Äù, ‚ÄúVerde‚Äù, el modelo crea una regla para cada uno de estos valores. Esto crea ‚Äúregiones‚Äù en el espacio de datos (instancias donde Color=Rojo, donde Color=Azul, etc.). Sin embargo, la predicci√≥n dentro de cada una de estas regiones es simplemente la clase mayoritaria observada en esa regi√≥n, y el modelo en su conjunto es una √∫nica estructura de decisi√≥n global basada en ese √∫nico atributo. es un ajuste din√°mico o ponderado localmente de par√°metros como en otros modelos de aprendizaje local.Partici√≥n del Espacio (Reglas): Aunque el modelo es global, la ‚Äúregla‚Äù que genera s√≠ que particiona el espacio de caracter√≠sticas. Por ejemplo, si el atributo seleccionado es ‚ÄúColor‚Äù y tiene valores ‚ÄúRojo‚Äù, ‚ÄúAzul‚Äù, ‚ÄúVerde‚Äù, el modelo crea una regla para cada uno de estos valores. Esto crea ‚Äúregiones‚Äù en el espacio de datos (instancias donde Color=Rojo, donde Color=Azul, etc.). Sin embargo, la predicci√≥n dentro de cada una de estas regiones es simplemente la clase mayoritaria observada en esa regi√≥n, y el modelo en su conjunto es una √∫nica estructura de decisi√≥n global basada en ese √∫nico atributo. es un ajuste din√°mico o ponderado localmente de par√°metros como en otros modelos de aprendizaje local.","code":""},{"path":"sistemas-basados-en-reglas.html","id":"repeated-incremental-pruning-to-produce-error-reduction-ripper","chapter":"üìê 10. Sistemas Basados en Reglas","heading":"Repeated Incremental Pruning to Produce Error Reduction (RIPPER)","text":"RIPPER (Repeated Incremental Pruning Produce Error Reduction) es un algoritmo de clasificaci√≥n supervisada muy conocido, desarrollado por William W. Cohen. Es una extensi√≥n del algoritmo de reglas IREP y es especialmente valorado por su capacidad para generar conjuntos de reglas de clasificaci√≥n precisos y de alta calidad que son menudo m√°s simples e interpretables que los modelos de √°rbol de decisi√≥n complejos, al tiempo que es muy eficiente en t√©rminos computacionales, incluso con grandes conjuntos de datos.RIPPER construye un conjunto de reglas -para cada clase de forma secuencial. Opera con un enfoque de ‚Äúdivide y vencer√°s‚Äù, pero con un fuerte √©nfasis en la poda (pruning) para evitar el sobreajuste.El proceso general de RIPPER para construir reglas para una clase espec√≠fica es el siguiente:Generaci√≥n de Reglas (Growing):\nComienza con una regla vac√≠a.\nA√±ade t√©rminos (condiciones) la regla que maximicen alguna m√©trica de calidad (por ejemplo, el ratio de ganancia de informaci√≥n) hasta que la regla cubre un cierto n√∫mero de ejemplos positivos (ejemplos de la clase actual) y pocos ejemplos negativos.\nComienza con una regla vac√≠a.A√±ade t√©rminos (condiciones) la regla que maximicen alguna m√©trica de calidad (por ejemplo, el ratio de ganancia de informaci√≥n) hasta que la regla cubre un cierto n√∫mero de ejemplos positivos (ejemplos de la clase actual) y pocos ejemplos negativos.Poda de Reglas (Pruning):\nUna vez que una regla ha sido generada, se somete un proceso de poda incremental. Se eliminan t√©rminos de la regla que mejoran significativamente el error de la regla en un conjunto de validaci√≥n separado (el ‚Äúconjunto de poda‚Äù). Esto ayuda generalizar la regla y evitar el sobreajuste.\nUna vez que una regla ha sido generada, se somete un proceso de poda incremental. Se eliminan t√©rminos de la regla que mejoran significativamente el error de la regla en un conjunto de validaci√≥n separado (el ‚Äúconjunto de poda‚Äù). Esto ayuda generalizar la regla y evitar el sobreajuste.Adici√≥n de Reglas:\nDespu√©s de podar una regla, se a√±ade al conjunto de reglas para la clase actual.\nLos ejemplos cubiertos por esta nueva regla se eliminan del conjunto de entrenamiento.\nSe repiten los pasos 1-3 para construir nuevas reglas para la misma clase hasta que queden suficientes ejemplos de la clase o se puedan generar m√°s reglas que cumplan ciertos criterios.\nDespu√©s de podar una regla, se a√±ade al conjunto de reglas para la clase actual.Los ejemplos cubiertos por esta nueva regla se eliminan del conjunto de entrenamiento.Se repiten los pasos 1-3 para construir nuevas reglas para la misma clase hasta que queden suficientes ejemplos de la clase o se puedan generar m√°s reglas que cumplan ciertos criterios.Optimizaci√≥n Global y Re-poda:\nUna vez que se ha generado un conjunto inicial de reglas para una clase, RIPPER realiza varias pasadas de optimizaci√≥n.\nEn cada pasada, se intenta reemplazar o modificar reglas para reducir a√∫n m√°s el error total del conjunto de reglas. Esto incluye estrategias como la sustituci√≥n de reglas (reemplazar una regla existente por una mejor), la reversi√≥n de reglas (eliminar una regla), y la combinaci√≥n de reglas.\nSe utiliza una m√©trica como la descripci√≥n m√≠nima de la longitud (MDL - Minimum Description Length) para penalizar la complejidad del modelo.\nUna vez que se ha generado un conjunto inicial de reglas para una clase, RIPPER realiza varias pasadas de optimizaci√≥n.En cada pasada, se intenta reemplazar o modificar reglas para reducir a√∫n m√°s el error total del conjunto de reglas. Esto incluye estrategias como la sustituci√≥n de reglas (reemplazar una regla existente por una mejor), la reversi√≥n de reglas (eliminar una regla), y la combinaci√≥n de reglas.Se utiliza una m√©trica como la descripci√≥n m√≠nima de la longitud (MDL - Minimum Description Length) para penalizar la complejidad del modelo.El proceso se repite para todas las clases, y las reglas se organizan en un orden de prioridad.Aprendizaje Global vs.¬†Local:RIPPER es un algoritmo que combina de manera muy efectiva aspectos de aprendizaje global y local, pero con un fuerte √©nfasis en la generaci√≥n de reglas locales que se combinan en un modelo global.Aspecto Local (Generaci√≥n de Reglas Individuales): Cada regla que RIPPER aprende es esencialmente un modelo local que cubre una regi√≥n espec√≠fica del espacio de caracter√≠sticas. Las condiciones de la regla (B Class X) definen un hiperrect√°ngulo (o una regi√≥n m√°s compleja) en el espacio de caracter√≠sticas. La regla se aprende para predecir correctamente los puntos dentro de esa regi√≥n. La poda de reglas, en particular, se enfoca en optimizar el rendimiento de la regla en su ‚Äúvecindario‚Äù de datos cubiertos, evitando el sobreajuste puntos de entrenamiento individuales. Las reglas se ajustan patrones y relaciones locales dentro de los datos.Aspecto Local (Generaci√≥n de Reglas Individuales): Cada regla que RIPPER aprende es esencialmente un modelo local que cubre una regi√≥n espec√≠fica del espacio de caracter√≠sticas. Las condiciones de la regla (B Class X) definen un hiperrect√°ngulo (o una regi√≥n m√°s compleja) en el espacio de caracter√≠sticas. La regla se aprende para predecir correctamente los puntos dentro de esa regi√≥n. La poda de reglas, en particular, se enfoca en optimizar el rendimiento de la regla en su ‚Äúvecindario‚Äù de datos cubiertos, evitando el sobreajuste puntos de entrenamiento individuales. Las reglas se ajustan patrones y relaciones locales dentro de los datos.Aspecto Global (Conjunto de Reglas y Priorizaci√≥n): Aunque las reglas individuales son locales, el conjunto final de reglas para todas las clases, y su orden de prioridad, forman un modelo de clasificaci√≥n global que cubre todo el espacio de caracter√≠sticas. Cuando una nueva instancia necesita ser clasificada, se eval√∫a contra todas las reglas en orden hasta que una se activa, y esa regla dicta la predicci√≥n. La optimizaci√≥n global del conjunto de reglas, mediante la repoda y las fases de reemplazo de reglas, asegura que el modelo final sea coherente y preciso nivel de todo el conjunto de datos.Aspecto Global (Conjunto de Reglas y Priorizaci√≥n): Aunque las reglas individuales son locales, el conjunto final de reglas para todas las clases, y su orden de prioridad, forman un modelo de clasificaci√≥n global que cubre todo el espacio de caracter√≠sticas. Cuando una nueva instancia necesita ser clasificada, se eval√∫a contra todas las reglas en orden hasta que una se activa, y esa regla dicta la predicci√≥n. La optimizaci√≥n global del conjunto de reglas, mediante la repoda y las fases de reemplazo de reglas, asegura que el modelo final sea coherente y preciso nivel de todo el conjunto de datos.","code":""},{"path":"sistemas-basados-en-reglas.html","id":"rule-fit","chapter":"üìê 10. Sistemas Basados en Reglas","heading":"Rule Fit","text":"RuleFit es un potente y, al mismo tiempo, interpretable algoritmo de aprendizaje autom√°tico desarrollado por Jerome H. Friedman y Bogdan Popescu. Est√° dise√±ado para combinar la precisi√≥n de los m√©todos de ensamblaje (como el gradient boosting o los random forests) con la interpretabilidad de los modelos lineales y las reglas de decisi√≥n. RuleFit es particularmente √∫til cuando necesita un modelo que funcione bien y que le permita comprender el ‚Äúporqu√©‚Äù detr√°s de sus predicciones.La idea central de RuleFit es aprender un modelo lineal disperso que utiliza tanto las caracter√≠sticas de entrada originales como un conjunto de ‚Äúcaracter√≠sticas de regla‚Äù reci√©n generadas como predictores. Estas caracter√≠sticas de regla se derivan de un ensamblaje de √°rboles de decisi√≥n.As√≠ es como funciona RuleFit:Generaci√≥n del Ensamblaje de √Årboles:\nPrimero, RuleFit entrena un ensamblaje de √°rboles de decisi√≥n poco profundos en el conjunto de datos. Esto se puede hacer utilizando algoritmos como Gradient Boosting Machines (GBM) o Random Forests. Los √°rboles suelen mantenerse poco profundos (por ejemplo, una profundidad m√°xima de 3-5) para producir reglas m√°s simples e interpretables.\nEstos √°rboles se entrenan para predecir la variable objetivo, lo que significa que sus divisiones son significativas para la tarea.\nPrimero, RuleFit entrena un ensamblaje de √°rboles de decisi√≥n poco profundos en el conjunto de datos. Esto se puede hacer utilizando algoritmos como Gradient Boosting Machines (GBM) o Random Forests. Los √°rboles suelen mantenerse poco profundos (por ejemplo, una profundidad m√°xima de 3-5) para producir reglas m√°s simples e interpretables.Estos √°rboles se entrenan para predecir la variable objetivo, lo que significa que sus divisiones son significativas para la tarea.Extracci√≥n de Reglas:\nCada ruta desde la ra√≠z hasta un nodo hoja en cualquiera de los √°rboles de decisi√≥n generados se extrae y se convierte en una regla de decisi√≥n binaria.\nPor ejemplo, si una ruta en un √°rbol es ‚Äúsi (Caracter√≠stica1 > 10) Y (Caracter√≠stica2 < 5)‚Äù, esto se convierte en una regla.\nCada regla se trata entonces como una nueva caracter√≠stica binaria para cada instancia de datos: toma un valor de 1 si la instancia satisface todas las condiciones de la regla, y 0 en caso contrario.\nCada ruta desde la ra√≠z hasta un nodo hoja en cualquiera de los √°rboles de decisi√≥n generados se extrae y se convierte en una regla de decisi√≥n binaria.Por ejemplo, si una ruta en un √°rbol es ‚Äúsi (Caracter√≠stica1 > 10) Y (Caracter√≠stica2 < 5)‚Äù, esto se convierte en una regla.Cada regla se trata entonces como una nueva caracter√≠stica binaria para cada instancia de datos: toma un valor de 1 si la instancia satisface todas las condiciones de la regla, y 0 en caso contrario.Ajuste del Modelo Lineal con Regularizaci√≥n:\nLas caracter√≠sticas originales del conjunto de datos se combinan con estas caracter√≠sticas de regla binarias reci√©n creadas.\nLuego, se ajusta un modelo lineal disperso (normalmente una regresi√≥n Lasso, que utiliza regularizaci√≥n L1) este conjunto de caracter√≠sticas expandido.\nLa regularizaci√≥n Lasso realiza autom√°ticamente la selecci√≥n de caracter√≠sticas, estableciendo los coeficientes de las caracter√≠sticas originales y de las caracter√≠sticas de regla menos importantes en cero. Esto da como resultado un modelo final m√°s simple e interpretable que solo incluye los t√©rminos m√°s relevantes.\nLas caracter√≠sticas originales del conjunto de datos se combinan con estas caracter√≠sticas de regla binarias reci√©n creadas.Luego, se ajusta un modelo lineal disperso (normalmente una regresi√≥n Lasso, que utiliza regularizaci√≥n L1) este conjunto de caracter√≠sticas expandido.La regularizaci√≥n Lasso realiza autom√°ticamente la selecci√≥n de caracter√≠sticas, estableciendo los coeficientes de las caracter√≠sticas originales y de las caracter√≠sticas de regla menos importantes en cero. Esto da como resultado un modelo final m√°s simple e interpretable que solo incluye los t√©rminos m√°s relevantes.El modelo RuleFit final es una ecuaci√≥n lineal:\n\\(\\text{predicci√≥n} = \\beta_0 + \\sum_{j=1}^{p} \\beta_j X_j + \\sum_{k=1}^{R} \\alpha_k r_k(X)\\)Donde:\n* \\(\\beta_0\\) es el intercepto.\n* \\(\\beta_j X_j\\) son los t√©rminos para las caracter√≠sticas lineales originales \\(X_j\\).\n* \\(\\alpha_k r_k(X)\\) son los t√©rminos para las caracter√≠sticas de regla binarias \\(r_k(X)\\).Los coeficientes (\\(\\beta_j\\) y \\(\\alpha_k\\)) indican la importancia y la direcci√≥n del efecto de cada caracter√≠stica original y de cada regla en la predicci√≥n.Aprendizaje Global vs.¬†Local:RuleFit es un excelente ejemplo de un algoritmo que combina perfectamente las caracter√≠sticas de aprendizaje global y local.Aspecto Global (Modelo Lineal Final y Estructura General):\nLa etapa final de RuleFit consiste en ajustar un √∫nico modelo lineal global (con regularizaci√≥n Lasso). Este modelo lineal es un predictor global que combina las caracter√≠sticas originales y todas las caracter√≠sticas de regla generadas. Los coeficientes en este modelo lineal global definen la relaci√≥n general entre las caracter√≠sticas de entrada (originales y basadas en reglas) y la variable objetivo en todo el conjunto de datos.\nEste modelo lineal proporciona una comprensi√≥n global de la importancia de las caracter√≠sticas y de c√≥mo contribuyen colectivamente la predicci√≥n.\nLa etapa final de RuleFit consiste en ajustar un √∫nico modelo lineal global (con regularizaci√≥n Lasso). Este modelo lineal es un predictor global que combina las caracter√≠sticas originales y todas las caracter√≠sticas de regla generadas. Los coeficientes en este modelo lineal global definen la relaci√≥n general entre las caracter√≠sticas de entrada (originales y basadas en reglas) y la variable objetivo en todo el conjunto de datos.Este modelo lineal proporciona una comprensi√≥n global de la importancia de las caracter√≠sticas y de c√≥mo contribuyen colectivamente la predicci√≥n.Aspecto Local (Caracter√≠sticas de Regla y Efectos de Interacci√≥n):\nEl poder de RuleFit para manejar relaciones lineales e interacciones proviene de su aspecto local: las reglas de decisi√≥n. Cada regla, extra√≠da de una ruta en un √°rbol de decisi√≥n, define una subregi√≥n espec√≠fica o ‚Äúvecindario‚Äù del espacio de caracter√≠sticas. Por ejemplo, una regla ‚ÄúSI la edad es > 30 Y el ingreso es < 50k‚Äù captura una condici√≥n local muy espec√≠fica.\nAl incluir estas caracter√≠sticas de regla binarias, el modelo lineal puede aprender efectivamente diferentes relaciones lineales dentro de diferentes regiones locales definidas por las reglas. Estas reglas capturan expl√≠citamente los efectos de interacci√≥n entre caracter√≠sticas que un modelo lineal est√°ndar pasar√≠a por alto.\nEsto es similar tener un modelo local (impl√≠citamente, una constante o un modelo lineal simple dentro de la regi√≥n de la regla) que se activa cuando se cumplen sus condiciones, lo que permite que el modelo lineal global adapte sus predicciones bas√°ndose en estos patrones locales.\nEl poder de RuleFit para manejar relaciones lineales e interacciones proviene de su aspecto local: las reglas de decisi√≥n. Cada regla, extra√≠da de una ruta en un √°rbol de decisi√≥n, define una subregi√≥n espec√≠fica o ‚Äúvecindario‚Äù del espacio de caracter√≠sticas. Por ejemplo, una regla ‚ÄúSI la edad es > 30 Y el ingreso es < 50k‚Äù captura una condici√≥n local muy espec√≠fica.Al incluir estas caracter√≠sticas de regla binarias, el modelo lineal puede aprender efectivamente diferentes relaciones lineales dentro de diferentes regiones locales definidas por las reglas. Estas reglas capturan expl√≠citamente los efectos de interacci√≥n entre caracter√≠sticas que un modelo lineal est√°ndar pasar√≠a por alto.Esto es similar tener un modelo local (impl√≠citamente, una constante o un modelo lineal simple dentro de la regi√≥n de la regla) que se activa cuando se cumplen sus condiciones, lo que permite que el modelo lineal global adapte sus predicciones bas√°ndose en estos patrones locales.","code":""},{"path":"sistemas-basados-en-reglas.html","id":"zero-rule-zeror","chapter":"üìê 10. Sistemas Basados en Reglas","heading":"Zero Rule (ZeroR)","text":"Zero Rule (ZeroR) es el algoritmo de clasificaci√≥n supervisada m√°s simple imaginable. utiliza ninguna de las caracter√≠sticas predictoras en el conjunto de datos para hacer sus predicciones. En su lugar, simplemente predice la clase m√°s frecuente (mayoritaria) que se observa en el conjunto de datos de entrenamiento.C√≥mo funciona ZeroR:Conteo de Frecuencias: El algoritmo cuenta las ocurrencias de cada clase en el conjunto de datos de entrenamiento.Identificaci√≥n de la Clase Mayoritaria: Identifica la clase que tiene la mayor frecuencia (es decir, la clase que aparece m√°s veces).Predicci√≥n Universal: Para cualquier nueva instancia, ZeroR simplemente predice esta clase mayoritaria.Ejemplo: Si en un conjunto de datos para predecir si un cliente ‚Äúcomprar√°‚Äù o ‚Äúcomprar√°‚Äù un producto, el 70% de los clientes en el conjunto de entrenamiento ‚Äúcompraron‚Äù y el 30% ‚Äúcompraron‚Äù, ZeroR predecir√° ‚Äúcomprar√°‚Äù para todos los nuevos clientes. Su precisi√≥n en el conjunto de entrenamiento ser√≠a del 70%.¬øPor qu√© es importante ZeroR?Aunque ZeroR tiene ning√∫n poder predictivo real en el sentido de aprender patrones complejos de los datos, es fundamentalmente importante en Machine Learning como una l√≠nea base (benchmark).Punto de Referencia: Cualquier algoritmo de clasificaci√≥n m√°s sofisticado debe superar la precisi√≥n de ZeroR para ser considerado √∫til. Si un modelo complejo tiene una precisi√≥n inferior la de ZeroR, significa que el modelo est√° aprendiendo nada significativo de los datos, o incluso est√° aprendiendo patrones incorrectos.Detecci√≥n de Sesgos de Clase: En conjuntos de datos desequilibrados (donde una clase es mucho m√°s frecuente que otras), ZeroR puede lograr una precisi√≥n aparentemente alta. Esto resalta la importancia de usar m√©tricas de evaluaci√≥n m√°s all√° de la simple precisi√≥n en esos casos (como precisi√≥n, recall, F1-score, o AUC-ROC), ya que una alta precisi√≥n de ZeroR podr√≠a ser enga√±osa.Simplicidad Extrema: Sirve como el punto de partida m√°s b√°sico para entender c√≥mo los algoritmos de clasificaci√≥n intentan mejorar sobre una suposici√≥n trivial.Aprendizaje Global vs.¬†Local:ZeroR es un modelo de aprendizaje puramente global.Aspecto Global: ZeroR calcula una √∫nica estad√≠stica (la clase mayoritaria) partir de todo el conjunto de datos de entrenamiento y aplica esta predicci√≥n uniformemente todas las instancias, sin importar sus caracter√≠sticas individuales o su ubicaci√≥n en el espacio de datos. hay ninguna adaptaci√≥n local o consideraci√≥n de subregiones del espacio de caracter√≠sticas. El modelo es una √∫nica regla global e inmutable.Aspecto Global: ZeroR calcula una √∫nica estad√≠stica (la clase mayoritaria) partir de todo el conjunto de datos de entrenamiento y aplica esta predicci√≥n uniformemente todas las instancias, sin importar sus caracter√≠sticas individuales o su ubicaci√≥n en el espacio de datos. hay ninguna adaptaci√≥n local o consideraci√≥n de subregiones del espacio de caracter√≠sticas. El modelo es una √∫nica regla global e inmutable.Sin Modelado de Relaciones: Al ignorar todas las caracter√≠sticas de entrada, ZeroR modela ninguna relaci√≥n, lineal o lineal, entre los predictores y la variable objetivo. Su conocimiento se limita la distribuci√≥n marginal de la clase de salida.Sin Modelado de Relaciones: Al ignorar todas las caracter√≠sticas de entrada, ZeroR modela ninguna relaci√≥n, lineal o lineal, entre los predictores y la variable objetivo. Su conocimiento se limita la distribuci√≥n marginal de la clase de salida.En resumen, ZeroR es el clasificador m√°s simple y sirve como un punto de referencia crucial para evaluar el rendimiento de modelos de Machine Learning m√°s avanzados. Su naturaleza es inherentemente global, ya que aplica una √∫nica decisi√≥n derivada del patr√≥n m√°s frecuente en todo el conjunto de datos.","code":""},{"path":"deep-learning.html","id":"deep-learning","chapter":"ü§ñ 4. Deep Learning","heading":"ü§ñ 4. Deep Learning","text":"Ejemplos: CNN, RNN, Transformers.Uso: Ideal para im√°genes, texto y series temporales, especialmente con grandes datos estructurados.Ventajas: Poderoso para datos complejos.Limitaciones: Exige mucha data y computaci√≥n; poca interpretabilidad.","code":""},{"path":"deep-learning.html","id":"deep-boltzman-machine-dbm","chapter":"ü§ñ 4. Deep Learning","heading":"Deep Boltzman Machine (DBM)","text":"El modelo de Deep Boltzman Machine (DBM) es un tipo de red neuronal profunda generativa que pertenece la familia de los modelos gr√°ficos probabil√≠sticos. Se construye apilando m√∫ltiples M√°quinas de Boltzmann Restringidas (RBMs), lo que le permite aprender representaciones jer√°rquicas y abstractas de los datos de entrada. Su principal objetivo es modelar la distribuci√≥n de probabilidad conjunta entre un conjunto de variables observables y m√∫ltiples capas de variables latentes (ocultas).Las DBMs son modelos dirigidos (las conexiones entre las neuronas son sim√©tricas y tienen una direcci√≥n espec√≠fica) y est√°n compuestas por capas de unidades visibles (los datos de entrada) y varias capas de unidades ocultas. diferencia de las RBMs simples que tienen una sola capa oculta, las DBMs tienen m√∫ltiples capas ocultas, lo que les permite capturar dependencias m√°s complejas y caracter√≠sticas de alto nivel en los datos. El proceso de aprendizaje en una DBM busca ajustar los pesos de las conexiones de manera que la red asigne una alta probabilidad los datos de entrenamiento y una baja probabilidad los datos que son de entrenamiento.Las caracter√≠sticas clave de las DBMs incluyen:Representaci√≥n Jer√°rquica: Cada capa oculta aprende representaciones progresivamente m√°s abstractas de los datos. Las primeras capas pueden capturar caracter√≠sticas de bajo nivel (ej., bordes en im√°genes), mientras que las capas superiores combinan estas para formar representaciones de alto nivel (ej., partes de objetos o conceptos).Aprendizaje Supervisado: Las DBMs se entrenan t√≠picamente de forma supervisada, lo que significa que requieren etiquetas para el entrenamiento. Esto las hace valiosas para el pre-entrenamiento de modelos profundos en conjuntos de datos grandes y sin etiquetar, donde pueden aprender caracter√≠sticas √∫tiles que luego pueden ser utilizadas en tareas de aprendizaje supervisado (como la clasificaci√≥n).Inferencia y Generaci√≥n: Una vez entrenadas, las DBMs pueden ser utilizadas tanto para inferencia (estimar las representaciones ocultas dadas las entradas visibles) como para generaci√≥n (muestrear nuevas instancias de datos partir de la distribuci√≥n aprendida del modelo).Debido su complejidad computacional en el entrenamiento exacto, las DBMs menudo se entrenan utilizando un enfoque de aprendizaje codicioso por capas (entrenando RBMs individuales y apil√°ndolas) seguido de un ajuste fino de todo el modelo utilizando algoritmos como el Contraste Divergente Aproximado (ACD).Aprendizaje Global vs.¬†Local:El modelo de M√°quina de Boltzmann Profunda (DBM) es un modelo de aprendizaje global.Aspecto Global: Las DBMs construyen un modelo probabil√≠stico unificado y global de la distribuci√≥n de los datos. Los pesos de conexi√≥n en todas las capas de la red se ajustan para representar las dependencias y correlaciones en todo el espacio de entrada. se crean modelos espec√≠ficos para subconjuntos locales de datos; en cambio, el modelo aprende una representaci√≥n coherente y jer√°rquica que se aplica todos los puntos de datos. La funci√≥n de energ√≠a (o funci√≥n de coste) de la DBM se define sobre el espacio completo de variables visibles y ocultas, y el entrenamiento busca minimizar esta energ√≠a globalmente para que los datos de entrenamiento tengan una energ√≠a baja.Aspecto Global: Las DBMs construyen un modelo probabil√≠stico unificado y global de la distribuci√≥n de los datos. Los pesos de conexi√≥n en todas las capas de la red se ajustan para representar las dependencias y correlaciones en todo el espacio de entrada. se crean modelos espec√≠ficos para subconjuntos locales de datos; en cambio, el modelo aprende una representaci√≥n coherente y jer√°rquica que se aplica todos los puntos de datos. La funci√≥n de energ√≠a (o funci√≥n de coste) de la DBM se define sobre el espacio completo de variables visibles y ocultas, y el entrenamiento busca minimizar esta energ√≠a globalmente para que los datos de entrenamiento tengan una energ√≠a baja.Impacto de la Estructura Jer√°rquica: Aunque la DBM aprende representaciones en diferentes niveles de abstracci√≥n (jerarqu√≠as), estas representaciones contribuyen un entendimiento cohesivo y global de los datos. La interacci√≥n entre las capas y las unidades es parte de una estructura probabil√≠stica interconectada que busca modelar la distribuci√≥n general de los datos. El proceso de inferencia y generaci√≥n, aunque implica pasar informaci√≥n trav√©s de las capas, se basa en los par√°metros globales de la red para producir resultados consistentes y representativos de la distribuci√≥n aprendida. Esto contrasta con modelos locales que podr√≠an segmentar el espacio de entrada y construir modelos independientes para cada segmento.Impacto de la Estructura Jer√°rquica: Aunque la DBM aprende representaciones en diferentes niveles de abstracci√≥n (jerarqu√≠as), estas representaciones contribuyen un entendimiento cohesivo y global de los datos. La interacci√≥n entre las capas y las unidades es parte de una estructura probabil√≠stica interconectada que busca modelar la distribuci√≥n general de los datos. El proceso de inferencia y generaci√≥n, aunque implica pasar informaci√≥n trav√©s de las capas, se basa en los par√°metros globales de la red para producir resultados consistentes y representativos de la distribuci√≥n aprendida. Esto contrasta con modelos locales que podr√≠an segmentar el espacio de entrada y construir modelos independientes para cada segmento.","code":""},{"path":"deep-learning.html","id":"deep-belief-networks-dbnet","chapter":"ü§ñ 4. Deep Learning","heading":"Deep Belief Networks (DBNet)","text":"El Deep Belief Network (DBN) es un modelo de red neuronal profunda generativa que se construye apilando m√∫ltiples M√°quinas de Boltzmann Restringidas (RBMs). Fue un avance significativo en el campo del aprendizaje profundo, particularmente en la superaci√≥n de los desaf√≠os de entrenamiento de redes neuronales con muchas capas ocultas. Las DBNs son modelos probabil√≠sticos que buscan aprender una distribuci√≥n de probabilidad conjunta sobre los datos de entrada y sus representaciones latentes (ocultas).La arquitectura de una DBN es una jerarqu√≠a de capas, donde cada capa es una RBM. La capa inferior es la capa visible (o de entrada), que recibe los datos. Las capas subsiguientes son capas ocultas, y la caracter√≠stica clave es que el resultado de la capa oculta de una RBM se convierte en la capa visible para la siguiente RBM en la pila. La conexi√≥n entre la capa superior m√°s alta (que es una RBM) es dirigida y bidireccional, mientras que las conexiones entre las capas inferiores suelen ser dirigidas (de arriba hacia abajo) en la fase generativa despu√©s del entrenamiento.Las DBNs se caracterizan por:Construcci√≥n por Capas: Se construyen apilando RBMs, donde cada RBM se entrena de forma independiente y supervisada para aprender una representaci√≥n de su entrada.Pre-entrenamiento Codicioso por Capas: La innovaci√≥n clave de las DBNs fue el algoritmo de pre-entrenamiento codicioso por capas. En lugar de intentar entrenar toda la red la vez (lo que era dif√≠cil debido problemas como los gradientes desvanecientes/explosivos y los m√≠nimos locales), cada RBM se entrena individualmente para aprender caracter√≠sticas √∫tiles de la entrada que recibe. La salida de la capa oculta de una RBM entrenada se utiliza como entrada para la capa visible de la siguiente RBM. Este proceso contin√∫a hasta que se entrenan todas las capas.Aprendizaje Supervisado para Extracci√≥n de Caracter√≠sticas: La fase de pre-entrenamiento es completamente supervisada. Las RBMs aprenden reconstruir sus entradas, lo que les permite extraer caracter√≠sticas relevantes y de alto nivel de los datos sin necesidad de etiquetas. Esto es especialmente valioso para conjuntos de datos grandes y etiquetados.Ajuste Fino (Fine-tuning) Supervisado: Despu√©s del pre-entrenamiento supervisado, la DBN puede ser ‚Äúdesenrollada‚Äù y tratada como una red neuronal feed-forward para tareas supervisadas como la clasificaci√≥n. Se a√±ade una capa de salida (ej., softmax) en la parte superior, y toda la red se ajusta utilizando algoritmos de aprendizaje supervisado como la retropropagaci√≥n. El pre-entrenamiento act√∫a como una buena inicializaci√≥n de los pesos, ayudando que el entrenamiento supervisado converja m√°s r√°pido y alcance mejores m√≠nimos.Generaci√≥n de Datos: Dado que son modelos generativos, las DBNs pueden aprender la distribuci√≥n subyacente de los datos y, por lo tanto, pueden generar nuevas muestras de datos similares las de entrenamiento.Las DBNs fueron fundamentales para demostrar la viabilidad del entrenamiento de redes profundas y abrieron el camino para el resurgimiento del aprendizaje profundo.Aprendizaje Global vs.¬†Local:El modelo Deep Belief Network (DBN) emplea un enfoque h√≠brido, pero en su fase de aprendizaje de caracter√≠sticas, se inclina hacia un aprendizaje global trav√©s de una estrategia local y progresiva.Aspecto Global (Objetivo Final y Representaci√≥n): El objetivo general de una DBN es construir un modelo probabil√≠stico jer√°rquico global de los datos. Aunque el entrenamiento se realiza capa por capa, la intenci√≥n es que cada capa capture caracter√≠sticas que contribuyan una comprensi√≥n m√°s abstracta y completa de la distribuci√≥n de los datos de entrada en su conjunto. Las caracter√≠sticas de bajo nivel aprendidas por las primeras RBMs se combinan en las capas superiores para formar representaciones m√°s complejas y de alto nivel, que son intr√≠nsecas la estructura global de los datos. El modelo final, una vez que todas las RBMs est√°n entrenadas y se aplica el ajuste fino, opera como una red unificada que mapea entradas salidas basadas en un entendimiento global de las relaciones en los datos.Aspecto Global (Objetivo Final y Representaci√≥n): El objetivo general de una DBN es construir un modelo probabil√≠stico jer√°rquico global de los datos. Aunque el entrenamiento se realiza capa por capa, la intenci√≥n es que cada capa capture caracter√≠sticas que contribuyan una comprensi√≥n m√°s abstracta y completa de la distribuci√≥n de los datos de entrada en su conjunto. Las caracter√≠sticas de bajo nivel aprendidas por las primeras RBMs se combinan en las capas superiores para formar representaciones m√°s complejas y de alto nivel, que son intr√≠nsecas la estructura global de los datos. El modelo final, una vez que todas las RBMs est√°n entrenadas y se aplica el ajuste fino, opera como una red unificada que mapea entradas salidas basadas en un entendimiento global de las relaciones en los datos.Aspecto Local (Estrategia de Entrenamiento): La fase de pre-entrenamiento codicioso por capas de las DBNs tiene un fuerte componente local. Cada RBM individual se entrena de manera local, optimizando sus propios pesos para modelar la relaci√≥n entre su capa visible y su capa oculta, sin considerar expl√≠citamente las capas m√°s all√° de s√≠ misma en ese momento. La entrada para cada RBM superior proviene de la activaci√≥n de la capa oculta de la RBM inferior ya entrenada. Este entrenamiento local y secuencial es lo que permite que las DBNs escalen redes profundas y eviten problemas de optimizaci√≥n de modelos globales complejos desde cero. Sin embargo, esta ‚Äúlocalidad‚Äù es solo en la etapa de entrenamiento por partes; el efecto acumulativo de estas optimizaciones locales es la construcci√≥n de una representaci√≥n jer√°rquica que eventualmente se une en un modelo global cuando se realiza el ajuste fino de toda la red.Aspecto Local (Estrategia de Entrenamiento): La fase de pre-entrenamiento codicioso por capas de las DBNs tiene un fuerte componente local. Cada RBM individual se entrena de manera local, optimizando sus propios pesos para modelar la relaci√≥n entre su capa visible y su capa oculta, sin considerar expl√≠citamente las capas m√°s all√° de s√≠ misma en ese momento. La entrada para cada RBM superior proviene de la activaci√≥n de la capa oculta de la RBM inferior ya entrenada. Este entrenamiento local y secuencial es lo que permite que las DBNs escalen redes profundas y eviten problemas de optimizaci√≥n de modelos globales complejos desde cero. Sin embargo, esta ‚Äúlocalidad‚Äù es solo en la etapa de entrenamiento por partes; el efecto acumulativo de estas optimizaciones locales es la construcci√≥n de una representaci√≥n jer√°rquica que eventualmente se une en un modelo global cuando se realiza el ajuste fino de toda la red.","code":""},{"path":"deep-learning.html","id":"stacked-auto-enconders","chapter":"ü§ñ 4. Deep Learning","heading":"Stacked Auto-Enconders","text":"Un Autoencoder Apilado (Stacked Autoencoder - SAE) es un tipo de red neuronal profunda que se construye apilando m√∫ltiples autoencoders (AE) simples. Al igual que los Autoencoders individuales, su prop√≥sito principal es el aprendizaje de caracter√≠sticas supervisado y la reducci√≥n de dimensionalidad. La idea central es aprender representaciones compactas y de baja dimensionalidad (codificaciones) de los datos de entrada, que capturen las caracter√≠sticas m√°s importantes.La arquitectura de un SAE se organiza en capas, donde cada capa es un autoencoder. Un autoencoder b√°sico consta de dos partes: un codificador (encoder) que mapea la entrada una representaci√≥n de menor dimensi√≥n (el ‚Äúc√≥digo‚Äù o ‚Äúbottleneck‚Äù), y un decodificador (decoder) que reconstruye la entrada original partir de esta representaci√≥n. En un autoencoder apilado:Codificador y Decodificador: Cada autoencoder en la pila tiene su propio codificador y decodificador.Formaci√≥n de Capas: La salida de la capa codificadora de un autoencoder se convierte en la entrada para la siguiente capa (el autoencoder superior). De esta manera, las capas progresivas aprenden representaciones de caracter√≠sticas cada vez m√°s abstractas y de alto nivel.Las caracter√≠sticas clave de los Stacked Autoencoders incluyen:Pre-entrenamiento Codicioso por Capas: Similar las DBNs, los SAEs se entrenan utilizando un enfoque de pre-entrenamiento codicioso por capas.\nPrimero, se entrena un autoencoder para aprender una representaci√≥n de la capa de entrada original.\nUna vez entrenado, la capa del codificador de este AE se ‚Äúcongela‚Äù y sus salidas (las caracter√≠sticas aprendidas) se utilizan como entrada para el entrenamiento del siguiente autoencoder en la pila.\nEste proceso se repite, entrenando un nuevo autoencoder sobre las representaciones aprendidas por el autoencoder anterior, construyendo as√≠ una jerarqu√≠a de caracter√≠sticas.\nPrimero, se entrena un autoencoder para aprender una representaci√≥n de la capa de entrada original.Una vez entrenado, la capa del codificador de este AE se ‚Äúcongela‚Äù y sus salidas (las caracter√≠sticas aprendidas) se utilizan como entrada para el entrenamiento del siguiente autoencoder en la pila.Este proceso se repite, entrenando un nuevo autoencoder sobre las representaciones aprendidas por el autoencoder anterior, construyendo as√≠ una jerarqu√≠a de caracter√≠sticas.Aprendizaje Supervisado: Toda la fase de pre-entrenamiento es supervisada, lo que significa que los SAEs pueden aprender representaciones poderosas de datos sin necesidad de etiquetas. Esto los hace muy √∫tiles en escenarios donde los datos etiquetados son escasos.Reducci√≥n de Dimensionalidad y Extracci√≥n de Caracter√≠sticas: El objetivo de cada autoencoder es encontrar una representaci√≥n de baja dimensionalidad que permita una buena reconstrucci√≥n de la entrada. Al apilar estos, el SAE aprende una jerarqu√≠a de caracter√≠sticas donde las capas m√°s profundas capturan abstracciones m√°s complejas y significativas de los datos.Ajuste Fino (Fine-tuning) Supervisado: Despu√©s del pre-entrenamiento supervisado, el decodificador de cada autoencoder suele descartarse. Se toma la pila de codificadores como una red de extracci√≥n de caracter√≠sticas. esta red se le a√±ade una capa de salida (ej., una capa softmax para clasificaci√≥n) y todo el modelo se ajusta finamente utilizando un algoritmo de aprendizaje supervisado (como retropropagaci√≥n con gradiente descendente) en una tarea espec√≠fica. El pre-entrenamiento act√∫a como una excelente inicializaci√≥n de los pesos, lo que ayuda evitar m√≠nimos locales pobres y acelerar la convergencia.Los Stacked Autoencoders fueron un modelo popular antes del auge de las Redes Convolucionales y Recurrentes m√°s especializadas, y demostraron la efectividad del pre-entrenamiento supervisado para inicializar redes profundas.Aprendizaje Global vs.¬†Local:El modelo de Autoencoder Apilado (Stacked Autoencoder - SAE) es un modelo de aprendizaje global que se construye trav√©s de una estrategia de entrenamiento local y secuencial.Aspecto Global (Objetivo Final y Representaci√≥n): El objetivo final de un SAE es aprender una representaci√≥n global y jer√°rquica de los datos. Cada capa codificadora en la pila extrae caracter√≠sticas de un nivel de abstracci√≥n creciente, contribuyendo una comprensi√≥n m√°s profunda y compacta de toda la distribuci√≥n de los datos de entrada. La codificaci√≥n final producida por el SAE es una representaci√≥n de baja dimensionalidad que intenta encapsular la informaci√≥n m√°s relevante de los datos en su conjunto, permitiendo su reconstrucci√≥n. Cuando se utiliza para tareas posteriores (como clasificaci√≥n) despu√©s del ajuste fino, la red opera como un modelo unificado que aplica las caracter√≠sticas globales aprendidas nuevas entradas.Aspecto Global (Objetivo Final y Representaci√≥n): El objetivo final de un SAE es aprender una representaci√≥n global y jer√°rquica de los datos. Cada capa codificadora en la pila extrae caracter√≠sticas de un nivel de abstracci√≥n creciente, contribuyendo una comprensi√≥n m√°s profunda y compacta de toda la distribuci√≥n de los datos de entrada. La codificaci√≥n final producida por el SAE es una representaci√≥n de baja dimensionalidad que intenta encapsular la informaci√≥n m√°s relevante de los datos en su conjunto, permitiendo su reconstrucci√≥n. Cuando se utiliza para tareas posteriores (como clasificaci√≥n) despu√©s del ajuste fino, la red opera como un modelo unificado que aplica las caracter√≠sticas globales aprendidas nuevas entradas.Aspecto Local (Estrategia de Entrenamiento por Capas): La fase de pre-entrenamiento codicioso por capas de los SAEs tiene un componente fuertemente local. Cada autoencoder individual en la pila se entrena de forma independiente para aprender una codificaci√≥n √≥ptima y una reconstrucci√≥n de su propia entrada. Esto significa que los pesos de cada autoencoder se optimizan localmente, en un momento dado, sin considerar directamente la optimizaci√≥n simult√°nea de toda la red. La entrada cada autoencoder subsiguiente es la representaci√≥n codificada aprendida por el autoencoder anterior. Esta estrategia de entrenamiento ‚Äúpor partes‚Äù permite que las redes profundas sean entrenadas de manera m√°s eficiente y eficaz, ya que descompone un problema de optimizaci√≥n complejo en subproblemas m√°s manejables. Sin embargo, el resultado acumulado de estas optimizaciones locales es la construcci√≥n de una jerarqu√≠a de caracter√≠sticas que, en √∫ltima instancia, forma parte de un modelo global y unificado de los datos.Aspecto Local (Estrategia de Entrenamiento por Capas): La fase de pre-entrenamiento codicioso por capas de los SAEs tiene un componente fuertemente local. Cada autoencoder individual en la pila se entrena de forma independiente para aprender una codificaci√≥n √≥ptima y una reconstrucci√≥n de su propia entrada. Esto significa que los pesos de cada autoencoder se optimizan localmente, en un momento dado, sin considerar directamente la optimizaci√≥n simult√°nea de toda la red. La entrada cada autoencoder subsiguiente es la representaci√≥n codificada aprendida por el autoencoder anterior. Esta estrategia de entrenamiento ‚Äúpor partes‚Äù permite que las redes profundas sean entrenadas de manera m√°s eficiente y eficaz, ya que descompone un problema de optimizaci√≥n complejo en subproblemas m√°s manejables. Sin embargo, el resultado acumulado de estas optimizaciones locales es la construcci√≥n de una jerarqu√≠a de caracter√≠sticas que, en √∫ltima instancia, forma parte de un modelo global y unificado de los datos.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"Sagi, S. (2019). ML Algorithms: One SD (œÉ). obvious questions ask ‚Ä¶ | Sagi Shaier | Medium. https://medium.com/@Shaier/ml-algorithms-one-sd-%CF%83-74bcb28fafb6Kuhn, M. (2019). caret Package. https://topepo.github.io/caret/index.html","code":""}]
