# üå≤ **2. √Årboles de Decisi√≥n y Derivados** {-}  

**Ejemplos:** Decision Tree, Random Forest, Gradient Boosting  
**Cu√°ndo usarlo:**  

* Problemas tabulares con relaciones no lineales y variables categ√≥ricas o num√©ricas.
* Cuando interpretabilidad es importante.

**Ventajas:** Manejan datos heterog√©neos, f√°ciles de interpretar (√°rboles simples).   
**Limitaciones:** Sobreajuste en √°rboles simples; menor desempe√±o en datos muy ruidosos sin ensambles.

---

## Classification and Regression Tree (CART) 

```{r, echo =FALSE}

criterios <- c(
  "Tipo de modelo",
  "Variable respuesta",
  "Variables predictoras",
  "Relaci√≥n entre variables",
  "Normalidad de residuos",
  "Independencia de errores",
  "Homoscedasticidad",
  "Sensible a outliers",
  "Multicolinealidad entre predictores",
  "Interpretabilidad",
  "Velocidad y eficiencia",
  "Validaci√≥n cruzada",
  "No funciona bien si..."
)

aplica <- c(
  "‚úÖ Supervisado",
  "‚úÖ Categ√≥rica o Continua",
  "‚úÖ Num√©ricas y Categ√≥ricas",
  "‚úÖ No lineal y con interacciones",
  "‚ùå No requiere",
  "‚ö†Ô∏è Puede verse afectado",
  "‚ö†Ô∏è No necesario pero deseable",
  "‚ö†Ô∏è S√≠, en puntos de corte",
  "‚úÖ No se ve afectado",
  "‚úÖ Alta (gr√°fico del √°rbol)",
  "‚úÖ R√°pido en datasets medianos",
  "‚úÖ Muy usado para poda y ajuste",
  "‚ùå Muy profundo (overfitting), datos muy ruidosos"
)

detalles <- c(
  "Algoritmo basado en divisiones binarias",
  "Puede predecir clases o valores continuos",
  "Acepta todo tipo de variables predictoras",
  "Captura relaciones complejas y no lineales",
  "No requiere distribuci√≥n normal",
  "Idealmente los errores deben ser independientes",
  "La varianza constante mejora resultados",
  "Puede generar divisiones extremas por valores at√≠picos",
  "No necesita preocuparse por colinealidad",
  "F√°cil de entender, especialmente con √°rboles peque√±os",
  "Escalable pero no √≥ptimo en grandes vol√∫menes sin poda",
  "Usa poda y validaci√≥n cruzada para evitar sobreajuste",
  "Tiende al sobreajuste si no se poda o se regulariza"
)

tabla_cart <- data.frame(Criterio = criterios, Aplica = aplica, Detalles = detalles)  

require(gt) 

tabla_cart %>%
 gt() %>%
  tab_header(title = "Gu√≠a r√°pida para elegir CART",
             subtitle = "Classification and Regression Tree (CART)") %>%
   tab_footnote(footnote = "Fuente: Elaboraci√≥n propia") %>%
     tab_options(heading.title.font.size = 14, 
                 heading.subtitle.font.size = 12,
                 table.font.names = "Century Gothic",
                 table.font.size = 10,
                 data_row.padding = px(1)) %>%
      tab_style(style = list(cell_text(align = "left",
                                       weight = 'bold')),
                locations = list(cells_title(groups = c("title")))) %>%
       tab_style(style = list(cell_text(align = "left")),
                 locations = list(cells_title(groups = c("subtitle")))) %>%
        cols_width(starts_with("Detalles") ~ px(500),
                   everything() ~ px(200)) %>%
         as_raw_html() 
```


## Support Vector Machines (SVMs)  

```{r, echo = FALSE}

```


## Iterative Dichotomiser 3 (ID3)

## C4.5

## C5.0

## Chi-squared Automatic Interaction Detection (CHAID) 

## Decision Stump

## Conditional Decision Trees

## M5

