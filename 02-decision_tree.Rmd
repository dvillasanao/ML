# 游 **2. 츼rboles de Decisi칩n y Derivados** {-}  

**Ejemplos:** Decision Tree, Random Forest, Gradient Boosting  
**Cu치ndo usarlo:**  

* Problemas tabulares con relaciones no lineales y variables categ칩ricas o num칠ricas.
* Cuando interpretabilidad es importante.

**Ventajas:** Manejan datos heterog칠neos, f치ciles de interpretar (치rboles simples).   
**Limitaciones:** Sobreajuste en 치rboles simples; menor desempe침o en datos muy ruidosos sin ensambles.

---

Classification and Regression Tree (CART) 

츼rbol de Clasificaci칩n y Regresi칩n (CART): CART es el acr칩nimo del t칠rmino 치rbol de decisi칩n. En general, la implementaci칩n de CART es muy similar a la implementaci칩n del C4.5 mencionado anteriormente. La 칰nica diferencia radica en que CART construye 치rboles bas치ndose en un criterio de divisi칩n num칠rica aplicado recursivamente a los datos, mientras que el C4.5 incluye el paso intermedio de construir conjuntos de reglas.  

Dicotomizador Iterativo 3 (ID3): construye un 치rbol descendente. Comienza en la ra칤z y selecciona un atributo que se probar치 en cada nodo. Cada atributo se eval칰a mediante m칠todos estad칤sticos para detectar cu치l divide mejor el conjunto de datos. El mejor atributo se convierte en la ra칤z, y sus valores se ramifican. El proceso contin칰a con el resto de los atributos. Una vez seleccionado un atributo, no es posible retroceder.

C4.5 y C5.0 (diferentes versiones de un enfoque potente): C4.5, la siguiente iteraci칩n de Quinlan, es una versi칩n m치s reciente de ID3. Las nuevas caracter칤sticas (en comparaci칩n con ID3) son: (i) acepta caracter칤sticas continuas y discretas; (ii) maneja puntos de datos incompletos; (iii) resuelve el problema del sobreajuste mediante una t칠cnica ascendente, generalmente conocida como "poda"; y (iv) se pueden aplicar diferentes ponderaciones a las caracter칤sticas que componen los datos de entrenamiento. C5.0, la iteraci칩n m치s reciente de Quinlan. Esta implementaci칩n est치 protegida por patente y, probablemente por ello, rara vez se implementa (fuera de paquetes de software comerciales).

Detecci칩n Autom치tica de Interacci칩n Chi-cuadrado (CHAID): algoritmo utilizado para descubrir relaciones entre una variable de respuesta categ칩rica y otras variables predictoras categ칩ricas. Crea todas las tabulaciones cruzadas posibles para cada predictor categ칩rico hasta obtener el mejor resultado y no se pueden realizar m치s divisiones. CHAID construye un modelo predictivo, o 치rbol, para determinar la mejor manera de combinar las variables y explicar el resultado de la variable dependiente dada. En el an치lisis CHAID, se pueden utilizar datos nominales, ordinales y continuos, donde los predictores continuos se dividen en categor칤as con un n칰mero aproximadamente igual de observaciones. Resulta 칰til para buscar patrones en conjuntos de datos con muchas variables categ칩ricas y es una forma pr치ctica de resumir los datos, ya que las relaciones se visualizan f치cilmente.

츼rbol de decisi칩n : un modelo de aprendizaje autom치tico que consta de un 치rbol de decisi칩n de un nivel; un 치rbol con un nodo interno (la ra칤z) conectado a los nodos terminales (sus hojas). Este modelo realiza una predicci칩n bas치ndose en el valor de una sola caracter칤stica de entrada.

M5 : M5 combina un 치rbol de decisi칩n convencional con la posibilidad de usar funciones de regresi칩n lineal en los nodos. Adem치s de la precisi칩n, admite tareas con dimensiones muy altas, con hasta cientos de atributos. El 치rbol de modelo M5 es un aprendiz de 치rbol de decisi칩n para tareas de regresi칩n, lo que significa que se utiliza para predecir valores de la variable de respuesta num칠rica Y. Si bien el 치rbol M5 utiliza el mismo enfoque que el 치rbol CART para elegir el error cuadr치tico medio como funci칩n de impureza, no asigna una constante al nodo hoja, sino que se ajusta a un modelo de regresi칩n lineal multivariante.